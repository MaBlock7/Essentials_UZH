{
 "cells": [
  {
   "cell_type": "code",
   "id": "67ab1ae5-218c-49f6-b80f-303aa10f2312",
   "metadata": {
    "id": "67ab1ae5-218c-49f6-b80f-303aa10f2312",
    "ExecuteTime": {
     "end_time": "2024-11-06T18:16:28.379294Z",
     "start_time": "2024-11-06T18:16:28.375836Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (confusion_matrix,\n",
    "                             classification_report,\n",
    "                             accuracy_score,\n",
    "                             f1_score,\n",
    "                             ConfusionMatrixDisplay)\n",
    "\n",
    "from sklearn.model_selection import (train_test_split,\n",
    "                                     GridSearchCV)\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "nltk.download('punkt')\n",
    "glove_filepath = 'glove.6B.300d.txt'"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kevinbrundler/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "kpGX2ejdKzK5",
   "metadata": {
    "id": "kpGX2ejdKzK5",
    "ExecuteTime": {
     "end_time": "2024-11-06T18:16:39.847539Z",
     "start_time": "2024-11-06T18:16:28.460414Z"
    }
   },
   "source": [
    "def load_glove_embeddings(filepath):\n",
    "    \"\"\"\n",
    "    Loads GloVe embeddings from a file and returns them as a dictionary.\n",
    "\n",
    "    The function reads the GloVe pre-trained embeddings from the specified file.\n",
    "    Each line in the GloVe file contains a word followed by its corresponding\n",
    "    vector of floating point numbers representing the word's embedding. The\n",
    "    function processes each line, extracts the word and its vector, and stores\n",
    "    them in a dictionary where the key is the word and the value is the corresponding\n",
    "    embedding vector.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The path to the GloVe embeddings file. Each line of the file should\n",
    "                        contain a word followed by its vector of embedding values.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are words (str) and values are their corresponding\n",
    "              embedding vectors (numpy.ndarray).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    embedding_dict = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embedding_dict[word] = vector\n",
    "    return embedding_dict\n",
    "\n",
    "\n",
    "embedding_dict = load_glove_embeddings(r\"glove/glove.6B.300d.txt\")"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "cb468562-0171-4a15-8001-6cbed6fe6d5f",
   "metadata": {
    "id": "cb468562-0171-4a15-8001-6cbed6fe6d5f",
    "ExecuteTime": {
     "end_time": "2024-11-06T18:16:40.116553Z",
     "start_time": "2024-11-06T18:16:40.112304Z"
    }
   },
   "source": [
    "def split_data(\n",
    "    df: pd.DataFrame,\n",
    "    label_col: str = 'label',\n",
    "    test_size: float = 0.3,\n",
    "    random_state: int = None\n",
    ") -> tuple[pd.DataFrame]:\n",
    "\n",
    "    def ensure_all_labels(original_df, train_df, test_df, label_col):\n",
    "        original_labels = set(original_df[label_col])\n",
    "        train_labels = set(train_df[label_col])\n",
    "        missing_labels = original_labels - train_labels\n",
    "\n",
    "        if missing_labels:\n",
    "            for label in missing_labels:\n",
    "                missing_sample = test_df[test_df[label_col] == label].sample(n=1)\n",
    "                test_df = test_df[~(test_df[label_col].isin(missing_sample.labels))]\n",
    "                train_df = pd.concat([train_df, missing_sample])\n",
    "        return train_df, test_df\n",
    "\n",
    "    try:\n",
    "        train_df, test_df = train_test_split(\n",
    "            df,\n",
    "            test_size=test_size,\n",
    "            stratify=df[label_col],\n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "        train_df, test_df = ensure_all_labels(df, train_df, test_df, label_col)\n",
    "\n",
    "    except ValueError as e:\n",
    "        warnings.warn(\n",
    "            f\"{e} --- Falling back to random split. Consider reviewing extremely small classes.\"\n",
    "        )\n",
    "\n",
    "        # Fallback to random split if stratified split fails\n",
    "        train_df, test_df = train_test_split(\n",
    "            df,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "        train_df, test_df = ensure_all_labels(df, train_df, test_df, label_col)\n",
    "\n",
    "    return train_df, test_df"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "97eae70d-b535-42b2-8a56-e2594e723296",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97eae70d-b535-42b2-8a56-e2594e723296",
    "outputId": "faba62f8-9c2f-44b8-8836-e5fbccaad91a",
    "ExecuteTime": {
     "end_time": "2024-11-06T18:16:40.378632Z",
     "start_time": "2024-11-06T18:16:40.375471Z"
    }
   },
   "source": [
    "def get_sentence_embedding(sentence, embedding_dict, embedding_dim=300):\n",
    "    \"\"\"\n",
    "    Converts a sentence into a fixed-size embedding by averaging the word embeddings.\n",
    "\n",
    "    This function takes a sentence, tokenizes it, and looks up each token's embedding\n",
    "    in the provided `embedding_dict`. If a word is not found in the embedding dictionary,\n",
    "    it assigns a random vector of the specified `embedding_dim`. The resulting sentence\n",
    "    embedding is the average of the word embeddings.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence to be converted into an embedding.\n",
    "        embedding_dict (dict): A dictionary where the keys are words and the values are\n",
    "                               their corresponding embedding vectors (typically from GloVe).\n",
    "        embedding_dim (int): The dimensionality of the embeddings (default is 300).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 1D NumPy array representing the averaged embedding of the input sentence.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = word_tokenize(sentence.lower())\n",
    "    embeddings = []\n",
    "    for token in tokens:\n",
    "        if token in embedding_dict:\n",
    "            embeddings.append(embedding_dict[token])\n",
    "        else:\n",
    "            embeddings.append(np.random.randn(embedding_dim))\n",
    "    return np.mean(embeddings, axis=0)\n"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "d2662879-9e49-476f-860f-044ea9e666a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2662879-9e49-476f-860f-044ea9e666a9",
    "outputId": "02f3d048-5415-485e-a806-0b55fd84341c",
    "ExecuteTime": {
     "end_time": "2024-11-06T18:16:42.708406Z",
     "start_time": "2024-11-06T18:16:40.647740Z"
    }
   },
   "source": [
    "df = pd.read_csv(r'data/internal/training_data/training_data_no_duplicates_per_channel.csv')\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.array([get_sentence_embedding(str(message), embedding_dict) for message in train_df.message])\n",
    "y_train = np.array(train_df.label)\n",
    "\n",
    "X_test = np.array([get_sentence_embedding(str(message), embedding_dict) for message in test_df.message])\n",
    "y_test = np.array([test_df.label])"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "02d6d6cd-a00b-4d3c-bffb-23230f38120e",
   "metadata": {
    "id": "02d6d6cd-a00b-4d3c-bffb-23230f38120e",
    "ExecuteTime": {
     "end_time": "2024-11-06T18:16:42.975224Z",
     "start_time": "2024-11-06T18:16:42.972498Z"
    }
   },
   "source": [
    "def get_device():\n",
    "    \"\"\"\n",
    "    Determines the best available hardware device (MPS, CUDA, or CPU) to run PyTorch operations.\n",
    "\n",
    "    This function checks for the availability of hardware acceleration on the system and returns\n",
    "    the appropriate device for computation. It first checks for Metal Performance Shaders (MPS) on\n",
    "    Apple devices, then for CUDA (NVIDIA GPUs), and finally defaults to the CPU if no GPU is available.\n",
    "\n",
    "    Returns:\n",
    "        torch.device: The best available device ('mps', 'cuda', or 'cpu') for PyTorch computations.\n",
    "    \"\"\"\n",
    "\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"MPS device found, using MPS backend.\\n\")\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        print(f\"CUDA device found, using CUDA backend. Device: {torch.cuda.get_device_name(0)}\\n\")\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"Neither MPS nor CUDA found, using CPU.\\n\")\n",
    "        return torch.device(\"cpu\")"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "ySDJGFTRNYdO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ySDJGFTRNYdO",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c24c36ce-0362-49e5-d681-0368330f25e9",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-06T18:29:58.231491Z",
     "start_time": "2024-11-06T18:16:43.429624Z"
    }
   },
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim, dropout_rate=0.5):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, hidden_dim1)\n",
    "        self.fc4 = nn.Linear(hidden_dim1, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # Xavier Initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.leaky_relu(self.bn1(self.fc1(x)))\n",
    "        x1 = self.dropout(x1)\n",
    "\n",
    "        x2 = self.leaky_relu(self.bn2(self.fc2(x1)))\n",
    "        x2 = self.dropout(x2)\n",
    "\n",
    "        x_residual = self.fc3(x2) + x1\n",
    "\n",
    "        x_out = self.fc4(x_residual)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "#############\n",
    "# Grid Search\n",
    "#############\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_train_np, X_valid_np, y_train_np, y_valid_np = train_test_split(\n",
    "    X_train.numpy(), y_train.numpy(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    Classifier,\n",
    "    module__input_dim=X_train.shape[1],\n",
    "    module__output_dim=6,\n",
    "    max_epochs=10,\n",
    "    lr=5e-4,\n",
    "    optimizer=optim.Adam,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    batch_size=64,\n",
    "    device=get_device(),\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'lr': [1e-3, 1e-4],\n",
    "    'module__hidden_dim1': [128, 256, 512],\n",
    "    'module__hidden_dim2': [64, 128, 256],\n",
    "    'module__dropout_rate': [0.4, 0.5],\n",
    "    'batch_size': [32, 64]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(net, param_grid, refit=True, cv=3, scoring='f1_weighted', verbose=2)\n",
    "gs.fit(X_train_np, y_train_np)\n",
    "\n",
    "print(f\"Best parameters: {gs.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {gs.best_score_:.4f}\")\n",
    "\n",
    "best_net = gs.best_estimator_\n",
    "val_accuracy = best_net.score(X_valid_np, y_valid_np)\n",
    "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device found, using MPS backend.\n",
      "\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5491\u001B[0m       \u001B[32m0.6479\u001B[0m        \u001B[35m1.0753\u001B[0m  0.9805\n",
      "      2        \u001B[36m0.9858\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.9168\u001B[0m  0.4678\n",
      "      3        \u001B[36m0.8156\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.8252\u001B[0m  0.4512\n",
      "      4        \u001B[36m0.7263\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.7980\u001B[0m  0.5048\n",
      "      5        \u001B[36m0.6265\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.7772\u001B[0m  0.5352\n",
      "      6        \u001B[36m0.5741\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7409\u001B[0m  0.5260\n",
      "      7        \u001B[36m0.5195\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7245\u001B[0m  0.5556\n",
      "      8        \u001B[36m0.5027\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7237\u001B[0m  0.4816\n",
      "      9        \u001B[36m0.4559\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7226\u001B[0m  0.4513\n",
      "     10        \u001B[36m0.4096\u001B[0m       \u001B[32m0.7917\u001B[0m        0.7246  0.4428\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   5.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5735\u001B[0m       \u001B[32m0.6446\u001B[0m        \u001B[35m1.0694\u001B[0m  0.5856\n",
      "      2        \u001B[36m1.0342\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m0.9136\u001B[0m  0.5122\n",
      "      3        \u001B[36m0.8078\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.8118\u001B[0m  0.4912\n",
      "      4        \u001B[36m0.7345\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7609\u001B[0m  0.4769\n",
      "      5        \u001B[36m0.6528\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.7235\u001B[0m  0.5038\n",
      "      6        \u001B[36m0.5849\u001B[0m       0.7884        \u001B[35m0.6982\u001B[0m  0.5158\n",
      "      7        \u001B[36m0.5293\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6924\u001B[0m  0.5147\n",
      "      8        \u001B[36m0.4805\u001B[0m       \u001B[32m0.8099\u001B[0m        \u001B[35m0.6725\u001B[0m  0.4934\n",
      "      9        \u001B[36m0.4489\u001B[0m       \u001B[32m0.8149\u001B[0m        0.6727  0.4645\n",
      "     10        \u001B[36m0.4008\u001B[0m       0.7950        0.6897  0.4940\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   5.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5128\u001B[0m       \u001B[32m0.6264\u001B[0m        \u001B[35m1.0582\u001B[0m  0.4964\n",
      "      2        \u001B[36m0.9934\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.9068\u001B[0m  0.4828\n",
      "      3        \u001B[36m0.7952\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.8345\u001B[0m  0.5111\n",
      "      4        \u001B[36m0.6907\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7909\u001B[0m  0.5500\n",
      "      5        \u001B[36m0.5928\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7528\u001B[0m  0.4961\n",
      "      6        \u001B[36m0.5590\u001B[0m       0.7719        0.7694  0.4783\n",
      "      7        \u001B[36m0.5128\u001B[0m       \u001B[32m0.7868\u001B[0m        0.7541  0.4669\n",
      "      8        \u001B[36m0.4523\u001B[0m       0.7868        \u001B[35m0.7449\u001B[0m  0.4507\n",
      "      9        \u001B[36m0.4147\u001B[0m       0.7818        0.7507  0.4524\n",
      "     10        \u001B[36m0.3861\u001B[0m       0.7868        0.7811  0.4725\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   5.0s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4857\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m0.9646\u001B[0m  0.4967\n",
      "      2        \u001B[36m0.9852\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.8223\u001B[0m  0.4494\n",
      "      3        \u001B[36m0.7928\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.7816\u001B[0m  0.4690\n",
      "      4        \u001B[36m0.6912\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.7530\u001B[0m  0.4747\n",
      "      5        \u001B[36m0.6003\u001B[0m       0.7521        0.7585  0.4485\n",
      "      6        \u001B[36m0.5691\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7359\u001B[0m  0.4765\n",
      "      7        \u001B[36m0.5125\u001B[0m       0.7537        0.7566  0.5507\n",
      "      8        \u001B[36m0.4749\u001B[0m       0.7669        0.7450  0.4857\n",
      "      9        \u001B[36m0.4301\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.7294\u001B[0m  0.5197\n",
      "     10        \u001B[36m0.3974\u001B[0m       0.7537        0.7769  0.5322\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   5.1s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6126\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.1412\u001B[0m  0.5136\n",
      "      2        \u001B[36m1.0271\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.9516\u001B[0m  0.5319\n",
      "      3        \u001B[36m0.8657\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.8510\u001B[0m  0.4964\n",
      "      4        \u001B[36m0.7066\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.8051\u001B[0m  0.5343\n",
      "      5        \u001B[36m0.6276\u001B[0m       0.7785        \u001B[35m0.7716\u001B[0m  0.4628\n",
      "      6        \u001B[36m0.5723\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7650\u001B[0m  0.4624\n",
      "      7        \u001B[36m0.5168\u001B[0m       0.7719        \u001B[35m0.7608\u001B[0m  0.4417\n",
      "      8        \u001B[36m0.4808\u001B[0m       0.7785        0.7694  0.4362\n",
      "      9        \u001B[36m0.4455\u001B[0m       0.7851        \u001B[35m0.7490\u001B[0m  0.4319\n",
      "     10        \u001B[36m0.4108\u001B[0m       0.7851        0.7612  0.4335\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6265\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.0438\u001B[0m  0.4715\n",
      "      2        \u001B[36m1.0183\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.8999\u001B[0m  0.5401\n",
      "      3        \u001B[36m0.8254\u001B[0m       0.7157        \u001B[35m0.8180\u001B[0m  0.4872\n",
      "      4        \u001B[36m0.7410\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.7672\u001B[0m  0.4451\n",
      "      5        \u001B[36m0.6342\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.7298\u001B[0m  0.4574\n",
      "      6        \u001B[36m0.5781\u001B[0m       \u001B[32m0.7488\u001B[0m        0.7419  0.4763\n",
      "      7        \u001B[36m0.5222\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.6927\u001B[0m  0.4676\n",
      "      8        \u001B[36m0.4644\u001B[0m       0.7554        0.7064  0.4539\n",
      "      9        \u001B[36m0.4155\u001B[0m       0.7455        0.7077  0.4877\n",
      "     10        \u001B[36m0.3888\u001B[0m       0.7554        0.7261  0.4913\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5712\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.9767\u001B[0m  0.6396\n",
      "      2        \u001B[36m1.0625\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8015\u001B[0m  0.4842\n",
      "      3        \u001B[36m0.8852\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.7476\u001B[0m  0.4669\n",
      "      4        \u001B[36m0.7486\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7315\u001B[0m  0.4782\n",
      "      5        \u001B[36m0.6447\u001B[0m       0.7702        0.7621  0.5340\n",
      "      6        \u001B[36m0.6060\u001B[0m       0.7719        \u001B[35m0.7157\u001B[0m  0.4503\n",
      "      7        \u001B[36m0.5722\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7122\u001B[0m  0.4453\n",
      "      8        \u001B[36m0.4922\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.7035\u001B[0m  0.4774\n",
      "      9        \u001B[36m0.4368\u001B[0m       0.7950        0.7525  0.5023\n",
      "     10        \u001B[36m0.4309\u001B[0m       0.7983        \u001B[35m0.6971\u001B[0m  0.5487\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   5.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6312\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.0769\u001B[0m  0.4899\n",
      "      2        \u001B[36m1.0628\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9016\u001B[0m  0.4487\n",
      "      3        \u001B[36m0.8667\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8158\u001B[0m  0.4547\n",
      "      4        \u001B[36m0.7266\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.7768\u001B[0m  0.5094\n",
      "      5        \u001B[36m0.6528\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.7261\u001B[0m  0.5152\n",
      "      6        \u001B[36m0.5792\u001B[0m       \u001B[32m0.7686\u001B[0m        0.7346  0.4830\n",
      "      7        \u001B[36m0.5124\u001B[0m       0.7603        0.7460  0.4652\n",
      "      8        \u001B[36m0.4455\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7203\u001B[0m  0.4796\n",
      "      9        \u001B[36m0.4348\u001B[0m       0.7719        \u001B[35m0.7019\u001B[0m  0.7231\n",
      "     10        \u001B[36m0.4022\u001B[0m       0.7736        0.7557  0.7038\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   5.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5063\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m0.9697\u001B[0m  0.4809\n",
      "      2        \u001B[36m1.0257\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m0.8766\u001B[0m  0.5538\n",
      "      3        \u001B[36m0.8325\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.8358\u001B[0m  0.5524\n",
      "      4        \u001B[36m0.7112\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.7753\u001B[0m  0.5532\n",
      "      5        \u001B[36m0.6296\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.7342\u001B[0m  0.5249\n",
      "      6        \u001B[36m0.5526\u001B[0m       0.7554        0.7669  0.5062\n",
      "      7        \u001B[36m0.5065\u001B[0m       \u001B[32m0.7719\u001B[0m        0.7408  0.4984\n",
      "      8        \u001B[36m0.4580\u001B[0m       0.7455        0.8068  0.5037\n",
      "      9        \u001B[36m0.4285\u001B[0m       0.7438        0.8536  0.5536\n",
      "     10        \u001B[36m0.4006\u001B[0m       0.7471        0.8005  0.4851\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   5.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3768\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.8872\u001B[0m  0.6383\n",
      "      2        \u001B[36m0.8180\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.7825\u001B[0m  0.4363\n",
      "      3        \u001B[36m0.6623\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.7465\u001B[0m  0.4481\n",
      "      4        \u001B[36m0.5753\u001B[0m       0.7603        \u001B[35m0.7422\u001B[0m  0.4826\n",
      "      5        \u001B[36m0.4858\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7180\u001B[0m  0.4815\n",
      "      6        \u001B[36m0.4190\u001B[0m       0.7785        0.7329  0.5375\n",
      "      7        \u001B[36m0.3842\u001B[0m       \u001B[32m0.7917\u001B[0m        0.7402  0.4809\n",
      "      8        \u001B[36m0.3354\u001B[0m       \u001B[32m0.7950\u001B[0m        0.7469  0.4983\n",
      "      9        \u001B[36m0.3078\u001B[0m       0.7868        0.7575  0.9798\n",
      "     10        \u001B[36m0.2679\u001B[0m       0.7934        0.7354  0.5833\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   5.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4242\u001B[0m       \u001B[32m0.6512\u001B[0m        \u001B[35m0.9452\u001B[0m  0.5825\n",
      "      2        \u001B[36m0.8664\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.8384\u001B[0m  0.5193\n",
      "      3        \u001B[36m0.6646\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7325\u001B[0m  0.4550\n",
      "      4        \u001B[36m0.5752\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.7024\u001B[0m  0.4586\n",
      "      5        \u001B[36m0.4769\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6885\u001B[0m  0.4565\n",
      "      6        \u001B[36m0.4363\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6844\u001B[0m  0.4386\n",
      "      7        \u001B[36m0.3831\u001B[0m       0.7934        0.7058  0.4428\n",
      "      8        \u001B[36m0.3281\u001B[0m       0.7884        0.7338  0.4396\n",
      "      9        \u001B[36m0.3182\u001B[0m       0.7835        0.7429  0.4493\n",
      "     10        \u001B[36m0.2915\u001B[0m       0.7983        0.7026  0.5419\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   5.0s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3668\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.8631\u001B[0m  0.5337\n",
      "      2        \u001B[36m0.8098\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7613\u001B[0m  0.5146\n",
      "      3        \u001B[36m0.6293\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.7184\u001B[0m  0.5617\n",
      "      4        \u001B[36m0.5442\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7000\u001B[0m  0.4978\n",
      "      5        \u001B[36m0.4777\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6535\u001B[0m  0.5304\n",
      "      6        \u001B[36m0.4058\u001B[0m       0.7884        0.7077  0.5844\n",
      "      7        \u001B[36m0.3603\u001B[0m       0.7752        0.7495  0.5314\n",
      "      8        \u001B[36m0.3361\u001B[0m       0.7967        0.7140  0.5005\n",
      "      9        \u001B[36m0.2864\u001B[0m       0.7769        0.7212  0.5390\n",
      "     10        \u001B[36m0.2580\u001B[0m       0.7835        0.7658  0.5684\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   5.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3847\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.9413\u001B[0m  0.5163\n",
      "      2        \u001B[36m0.8613\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.7665\u001B[0m  0.5028\n",
      "      3        \u001B[36m0.6909\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.7259\u001B[0m  0.9792\n",
      "      4        \u001B[36m0.5866\u001B[0m       \u001B[32m0.7901\u001B[0m        0.7296  0.5219\n",
      "      5        \u001B[36m0.4920\u001B[0m       0.7835        0.7265  0.5859\n",
      "      6        \u001B[36m0.4449\u001B[0m       0.7868        \u001B[35m0.7013\u001B[0m  0.5749\n",
      "      7        \u001B[36m0.4113\u001B[0m       \u001B[32m0.8000\u001B[0m        0.7466  0.5722\n",
      "      8        \u001B[36m0.3490\u001B[0m       0.7785        0.8283  0.5161\n",
      "      9        \u001B[36m0.3460\u001B[0m       0.7950        0.7772  0.4907\n",
      "     10        \u001B[36m0.2664\u001B[0m       \u001B[32m0.8033\u001B[0m        0.7637  0.4922\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   5.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4600\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m0.9395\u001B[0m  0.4842\n",
      "      2        \u001B[36m0.8726\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.7855\u001B[0m  0.4984\n",
      "      3        \u001B[36m0.6766\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7207\u001B[0m  0.5695\n",
      "      4        \u001B[36m0.5672\u001B[0m       0.7802        \u001B[35m0.6906\u001B[0m  0.5037\n",
      "      5        \u001B[36m0.5095\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.6678\u001B[0m  0.4867\n",
      "      6        \u001B[36m0.4453\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.6498\u001B[0m  0.4833\n",
      "      7        \u001B[36m0.3804\u001B[0m       0.7802        0.7030  0.4944\n",
      "      8        \u001B[36m0.3529\u001B[0m       \u001B[32m0.7967\u001B[0m        0.6738  0.5037\n",
      "      9        \u001B[36m0.2944\u001B[0m       \u001B[32m0.7983\u001B[0m        0.6890  0.5041\n",
      "     10        \u001B[36m0.2789\u001B[0m       0.7851        0.7571  0.5712\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   5.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3512\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8725\u001B[0m  0.5159\n",
      "      2        \u001B[36m0.8457\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7544\u001B[0m  0.5475\n",
      "      3        \u001B[36m0.6800\u001B[0m       0.7736        \u001B[35m0.7536\u001B[0m  0.5297\n",
      "      4        \u001B[36m0.5734\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6975\u001B[0m  0.5149\n",
      "      5        \u001B[36m0.4894\u001B[0m       0.7686        0.7434  0.5918\n",
      "      6        \u001B[36m0.4249\u001B[0m       0.7835        0.7182  0.5693\n",
      "      7        \u001B[36m0.3838\u001B[0m       0.7868        0.7293  0.5119\n",
      "      8        \u001B[36m0.3443\u001B[0m       0.7785        0.7544  0.5049\n",
      "      9        \u001B[36m0.2961\u001B[0m       \u001B[32m0.8182\u001B[0m        0.7116  0.4996\n",
      "     10        \u001B[36m0.2618\u001B[0m       0.7917        0.7650  0.5008\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   5.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4817\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.8915\u001B[0m  0.5385\n",
      "      2        \u001B[36m0.8820\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8023\u001B[0m  0.4999\n",
      "      3        \u001B[36m0.7066\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7648\u001B[0m  0.4466\n",
      "      4        \u001B[36m0.5850\u001B[0m       \u001B[32m0.7769\u001B[0m        0.7730  0.4809\n",
      "      5        \u001B[36m0.5241\u001B[0m       0.7620        \u001B[35m0.7353\u001B[0m  0.4623\n",
      "      6        \u001B[36m0.4491\u001B[0m       0.7736        0.7457  0.4436\n",
      "      7        \u001B[36m0.4076\u001B[0m       \u001B[32m0.7802\u001B[0m        0.7536  0.4596\n",
      "      8        \u001B[36m0.3445\u001B[0m       \u001B[32m0.7851\u001B[0m        0.7822  0.4539\n",
      "      9        0.3570       \u001B[32m0.7967\u001B[0m        0.8529  0.4505\n",
      "     10        \u001B[36m0.3012\u001B[0m       \u001B[32m0.8017\u001B[0m        0.8780  0.4721\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4487\u001B[0m       \u001B[32m0.7008\u001B[0m        \u001B[35m0.8826\u001B[0m  0.5380\n",
      "      2        \u001B[36m0.8765\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.7559\u001B[0m  0.4882\n",
      "      3        \u001B[36m0.7119\u001B[0m       0.7537        0.7827  0.5145\n",
      "      4        \u001B[36m0.6081\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.6783\u001B[0m  0.4775\n",
      "      5        \u001B[36m0.4871\u001B[0m       0.7669        0.7161  0.4506\n",
      "      6        \u001B[36m0.4522\u001B[0m       \u001B[32m0.7983\u001B[0m        0.6790  0.4393\n",
      "      7        \u001B[36m0.4127\u001B[0m       0.7653        0.7306  0.4367\n",
      "      8        \u001B[36m0.3536\u001B[0m       0.7769        0.7267  0.4824\n",
      "      9        \u001B[36m0.3171\u001B[0m       0.7868        0.6994  0.4591\n",
      "     10        \u001B[36m0.2898\u001B[0m       0.7851        0.7644  0.4679\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3626\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9209\u001B[0m  0.4646\n",
      "      2        \u001B[36m0.8429\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.8231\u001B[0m  0.4672\n",
      "      3        \u001B[36m0.6801\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8108\u001B[0m  0.4400\n",
      "      4        \u001B[36m0.5847\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.7939\u001B[0m  0.4572\n",
      "      5        \u001B[36m0.4790\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7690\u001B[0m  0.4399\n",
      "      6        \u001B[36m0.4268\u001B[0m       0.7421        0.8419  0.4390\n",
      "      7        \u001B[36m0.3958\u001B[0m       \u001B[32m0.7752\u001B[0m        0.8103  0.4592\n",
      "      8        \u001B[36m0.3333\u001B[0m       0.7570        0.8161  0.4660\n",
      "      9        \u001B[36m0.3158\u001B[0m       0.7537        0.8883  0.4597\n",
      "     10        \u001B[36m0.2729\u001B[0m       0.7669        0.8671  0.4357\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.2543\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.8023\u001B[0m  0.5756\n",
      "      2        \u001B[36m0.6971\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.7414\u001B[0m  0.4416\n",
      "      3        \u001B[36m0.5379\u001B[0m       0.7603        \u001B[35m0.7134\u001B[0m  0.4384\n",
      "      4        \u001B[36m0.4465\u001B[0m       \u001B[32m0.7917\u001B[0m        0.7258  0.4274\n",
      "      5        \u001B[36m0.3625\u001B[0m       0.7818        0.8099  0.4321\n",
      "      6        \u001B[36m0.3208\u001B[0m       \u001B[32m0.8033\u001B[0m        0.7632  0.4350\n",
      "      7        \u001B[36m0.2732\u001B[0m       0.7917        0.7442  0.4889\n",
      "      8        \u001B[36m0.2290\u001B[0m       0.8033        0.7750  0.5134\n",
      "      9        \u001B[36m0.1930\u001B[0m       0.7950        0.8022  0.4751\n",
      "     10        \u001B[36m0.1808\u001B[0m       \u001B[32m0.8050\u001B[0m        0.7580  0.5230\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.2255\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.7726\u001B[0m  0.5852\n",
      "      2        \u001B[36m0.7081\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.6885\u001B[0m  0.5123\n",
      "      3        \u001B[36m0.5418\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6476\u001B[0m  0.4967\n",
      "      4        \u001B[36m0.4211\u001B[0m       0.7950        \u001B[35m0.6346\u001B[0m  0.4431\n",
      "      5        \u001B[36m0.3731\u001B[0m       0.7884        0.6714  0.4327\n",
      "      6        \u001B[36m0.3031\u001B[0m       0.7934        \u001B[35m0.6314\u001B[0m  0.4434\n",
      "      7        \u001B[36m0.2856\u001B[0m       0.7967        0.6860  0.4536\n",
      "      8        \u001B[36m0.2322\u001B[0m       \u001B[32m0.8215\u001B[0m        0.6645  0.4377\n",
      "      9        \u001B[36m0.2000\u001B[0m       0.7967        0.7178  0.4358\n",
      "     10        \u001B[36m0.1969\u001B[0m       0.8033        0.7526  0.4543\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.2534\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.8232\u001B[0m  0.4554\n",
      "      2        \u001B[36m0.6702\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.7315\u001B[0m  0.4339\n",
      "      3        \u001B[36m0.5073\u001B[0m       0.7686        \u001B[35m0.7214\u001B[0m  0.4337\n",
      "      4        \u001B[36m0.4134\u001B[0m       0.7736        \u001B[35m0.7121\u001B[0m  0.4488\n",
      "      5        \u001B[36m0.3571\u001B[0m       0.7868        0.7131  0.4269\n",
      "      6        \u001B[36m0.2863\u001B[0m       0.7686        0.7982  0.4275\n",
      "      7        \u001B[36m0.2347\u001B[0m       0.7802        0.7471  0.4281\n",
      "      8        \u001B[36m0.2106\u001B[0m       0.7603        0.8167  0.4293\n",
      "      9        \u001B[36m0.1721\u001B[0m       0.7901        0.8339  0.4501\n",
      "     10        \u001B[36m0.1626\u001B[0m       \u001B[32m0.8149\u001B[0m        0.8112  0.4562\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.2330\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.8625\u001B[0m  0.5751\n",
      "      2        \u001B[36m0.7319\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.7763\u001B[0m  0.4653\n",
      "      3        \u001B[36m0.5689\u001B[0m       0.7702        \u001B[35m0.7693\u001B[0m  0.4331\n",
      "      4        \u001B[36m0.4565\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7637\u001B[0m  0.4337\n",
      "      5        \u001B[36m0.3809\u001B[0m       0.7653        0.8594  0.4311\n",
      "      6        \u001B[36m0.3194\u001B[0m       \u001B[32m0.7901\u001B[0m        0.8168  0.4348\n",
      "      7        \u001B[36m0.2874\u001B[0m       \u001B[32m0.7967\u001B[0m        0.8293  0.4488\n",
      "      8        \u001B[36m0.2534\u001B[0m       0.7818        0.8209  0.4598\n",
      "      9        \u001B[36m0.2129\u001B[0m       \u001B[32m0.8033\u001B[0m        0.8027  0.4368\n",
      "     10        0.2130       0.7983        0.8416  0.5176\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.2694\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.8675\u001B[0m  0.5360\n",
      "      2        \u001B[36m0.7527\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.7458\u001B[0m  0.4714\n",
      "      3        \u001B[36m0.5490\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7301\u001B[0m  0.4414\n",
      "      4        \u001B[36m0.4645\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6894\u001B[0m  0.4481\n",
      "      5        \u001B[36m0.3976\u001B[0m       0.7934        \u001B[35m0.6729\u001B[0m  0.4346\n",
      "      6        \u001B[36m0.3194\u001B[0m       0.7785        0.7384  0.4344\n",
      "      7        \u001B[36m0.2532\u001B[0m       0.7653        0.7941  0.4316\n",
      "      8        \u001B[36m0.2443\u001B[0m       0.7901        0.7598  0.4348\n",
      "      9        \u001B[36m0.1998\u001B[0m       0.8033        0.7463  0.4376\n",
      "     10        0.2195       0.7901        0.7772  0.5007\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.2911\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.9078\u001B[0m  0.4489\n",
      "      2        \u001B[36m0.7319\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8351\u001B[0m  0.4512\n",
      "      3        \u001B[36m0.5561\u001B[0m       \u001B[32m0.7587\u001B[0m        \u001B[35m0.8049\u001B[0m  0.4349\n",
      "      4        \u001B[36m0.4555\u001B[0m       0.7587        \u001B[35m0.8043\u001B[0m  0.4357\n",
      "      5        \u001B[36m0.3882\u001B[0m       0.7554        0.8594  0.4444\n",
      "      6        \u001B[36m0.3197\u001B[0m       0.7504        0.8564  0.4519\n",
      "      7        \u001B[36m0.2537\u001B[0m       0.7554        0.8911  0.4450\n",
      "      8        \u001B[36m0.2245\u001B[0m       0.7488        0.9748  0.4438\n",
      "      9        \u001B[36m0.2201\u001B[0m       \u001B[32m0.7769\u001B[0m        0.8213  0.4484\n",
      "     10        \u001B[36m0.1777\u001B[0m       0.7587        1.0143  0.4474\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3431\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.8797\u001B[0m  0.5129\n",
      "      2        \u001B[36m0.7922\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8399\u001B[0m  0.4485\n",
      "      3        \u001B[36m0.6420\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7450\u001B[0m  0.4498\n",
      "      4        \u001B[36m0.5054\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7353\u001B[0m  0.4689\n",
      "      5        \u001B[36m0.4304\u001B[0m       0.7702        0.7760  0.4736\n",
      "      6        \u001B[36m0.3671\u001B[0m       \u001B[32m0.7917\u001B[0m        0.7564  0.4843\n",
      "      7        \u001B[36m0.3251\u001B[0m       0.7917        0.7609  0.4565\n",
      "      8        \u001B[36m0.2842\u001B[0m       \u001B[32m0.7983\u001B[0m        0.7957  0.4520\n",
      "      9        \u001B[36m0.2474\u001B[0m       0.7934        0.8344  0.4632\n",
      "     10        \u001B[36m0.2247\u001B[0m       0.7967        0.8774  0.4406\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3713\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.8529\u001B[0m  0.4600\n",
      "      2        \u001B[36m0.7939\u001B[0m       \u001B[32m0.7488\u001B[0m        0.8530  0.4503\n",
      "      3        \u001B[36m0.6436\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7451\u001B[0m  0.4508\n",
      "      4        \u001B[36m0.5067\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.7150\u001B[0m  0.4490\n",
      "      5        \u001B[36m0.4279\u001B[0m       0.7669        0.7595  0.4493\n",
      "      6        \u001B[36m0.3584\u001B[0m       0.7785        0.8153  0.4548\n",
      "      7        \u001B[36m0.3154\u001B[0m       \u001B[32m0.8000\u001B[0m        0.7990  0.4549\n",
      "      8        \u001B[36m0.2584\u001B[0m       0.7736        0.8995  0.4596\n",
      "      9        \u001B[36m0.2493\u001B[0m       0.7868        0.8588  0.4629\n",
      "     10        \u001B[36m0.2198\u001B[0m       0.7603        0.9420  0.4574\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3297\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8355\u001B[0m  0.4341\n",
      "      2        \u001B[36m0.8223\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7480\u001B[0m  0.4305\n",
      "      3        \u001B[36m0.5851\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.7449\u001B[0m  0.4291\n",
      "      4        \u001B[36m0.4777\u001B[0m       0.7851        \u001B[35m0.7313\u001B[0m  0.4358\n",
      "      5        \u001B[36m0.3488\u001B[0m       0.7736        0.7537  0.4627\n",
      "      6        \u001B[36m0.3299\u001B[0m       0.7736        0.7621  0.4548\n",
      "      7        \u001B[36m0.2837\u001B[0m       0.7554        0.8240  0.4497\n",
      "      8        \u001B[36m0.2664\u001B[0m       0.7620        0.8837  0.4726\n",
      "      9        \u001B[36m0.2406\u001B[0m       0.7719        0.8758  0.4461\n",
      "     10        \u001B[36m0.2056\u001B[0m       0.7752        1.1128  0.4452\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6587\u001B[0m       \u001B[32m0.6298\u001B[0m        \u001B[35m1.0632\u001B[0m  0.4486\n",
      "      2        \u001B[36m1.1055\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.9262\u001B[0m  0.4448\n",
      "      3        \u001B[36m0.9398\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8300\u001B[0m  0.4377\n",
      "      4        \u001B[36m0.8064\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7791\u001B[0m  0.4585\n",
      "      5        \u001B[36m0.7576\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7560\u001B[0m  0.4448\n",
      "      6        \u001B[36m0.6671\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.7304\u001B[0m  0.4393\n",
      "      7        \u001B[36m0.6261\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.6976\u001B[0m  0.4350\n",
      "      8        \u001B[36m0.5836\u001B[0m       \u001B[32m0.7934\u001B[0m        0.7057  0.4551\n",
      "      9        \u001B[36m0.5425\u001B[0m       \u001B[32m0.7967\u001B[0m        0.7350  0.5372\n",
      "     10        \u001B[36m0.5028\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6818\u001B[0m  0.4737\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6664\u001B[0m       \u001B[32m0.6397\u001B[0m        \u001B[35m1.0881\u001B[0m  0.4643\n",
      "      2        \u001B[36m1.0802\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9228\u001B[0m  0.5093\n",
      "      3        \u001B[36m0.9271\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8531\u001B[0m  0.4750\n",
      "      4        \u001B[36m0.7967\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.7938\u001B[0m  0.4587\n",
      "      5        \u001B[36m0.7513\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7566\u001B[0m  0.4634\n",
      "      6        \u001B[36m0.6899\u001B[0m       0.7868        \u001B[35m0.7175\u001B[0m  0.5036\n",
      "      7        \u001B[36m0.6156\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.7159\u001B[0m  0.5321\n",
      "      8        \u001B[36m0.5667\u001B[0m       0.7901        \u001B[35m0.7040\u001B[0m  0.4715\n",
      "      9        \u001B[36m0.5243\u001B[0m       0.7884        0.7113  0.4541\n",
      "     10        \u001B[36m0.4916\u001B[0m       0.7967        \u001B[35m0.7012\u001B[0m  0.4491\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5896\u001B[0m       \u001B[32m0.6661\u001B[0m        \u001B[35m1.0872\u001B[0m  0.4511\n",
      "      2        \u001B[36m1.0923\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.9255\u001B[0m  0.4473\n",
      "      3        \u001B[36m0.9162\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.8584\u001B[0m  0.4330\n",
      "      4        \u001B[36m0.8247\u001B[0m       0.7455        \u001B[35m0.8108\u001B[0m  0.4384\n",
      "      5        \u001B[36m0.7059\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7550\u001B[0m  0.4528\n",
      "      6        \u001B[36m0.6485\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7390\u001B[0m  0.4486\n",
      "      7        \u001B[36m0.6116\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.7120\u001B[0m  0.4647\n",
      "      8        \u001B[36m0.5724\u001B[0m       0.7785        \u001B[35m0.7083\u001B[0m  0.4558\n",
      "      9        \u001B[36m0.5235\u001B[0m       0.7785        \u001B[35m0.7081\u001B[0m  0.4386\n",
      "     10        \u001B[36m0.4902\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6937\u001B[0m  0.4408\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6939\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.0664\u001B[0m  0.4380\n",
      "      2        \u001B[36m1.1447\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m0.9403\u001B[0m  0.4328\n",
      "      3        \u001B[36m0.9618\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.8732\u001B[0m  0.4365\n",
      "      4        \u001B[36m0.8817\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.8182\u001B[0m  0.4994\n",
      "      5        \u001B[36m0.7717\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7520\u001B[0m  0.4652\n",
      "      6        \u001B[36m0.6999\u001B[0m       \u001B[32m0.7669\u001B[0m        0.7521  0.4902\n",
      "      7        \u001B[36m0.6338\u001B[0m       0.7653        \u001B[35m0.7473\u001B[0m  0.4707\n",
      "      8        \u001B[36m0.5837\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.7096\u001B[0m  0.4762\n",
      "      9        \u001B[36m0.5632\u001B[0m       0.7769        0.7302  0.4639\n",
      "     10        \u001B[36m0.5225\u001B[0m       \u001B[32m0.7983\u001B[0m        0.7354  0.4850\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7251\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.0363\u001B[0m  0.4720\n",
      "      2        \u001B[36m1.1302\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.8911\u001B[0m  0.4752\n",
      "      3        \u001B[36m0.9320\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8121\u001B[0m  0.4778\n",
      "      4        \u001B[36m0.8160\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7716\u001B[0m  0.4723\n",
      "      5        \u001B[36m0.7310\u001B[0m       0.7702        \u001B[35m0.7256\u001B[0m  0.4782\n",
      "      6        \u001B[36m0.6737\u001B[0m       0.7669        \u001B[35m0.7074\u001B[0m  0.4861\n",
      "      7        \u001B[36m0.6288\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.7027\u001B[0m  0.4866\n",
      "      8        \u001B[36m0.5701\u001B[0m       0.7851        \u001B[35m0.7016\u001B[0m  0.4555\n",
      "      9        \u001B[36m0.5295\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.6802\u001B[0m  0.4654\n",
      "     10        \u001B[36m0.5150\u001B[0m       0.7835        0.6812  0.4799\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6806\u001B[0m       \u001B[32m0.6562\u001B[0m        \u001B[35m1.0917\u001B[0m  0.4637\n",
      "      2        \u001B[36m1.0891\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.9109\u001B[0m  0.4634\n",
      "      3        \u001B[36m0.9563\u001B[0m       0.7289        \u001B[35m0.8371\u001B[0m  0.4685\n",
      "      4        \u001B[36m0.8446\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.7993\u001B[0m  0.4825\n",
      "      5        \u001B[36m0.7542\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7710\u001B[0m  0.4630\n",
      "      6        \u001B[36m0.6895\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.7454\u001B[0m  0.4690\n",
      "      7        \u001B[36m0.6181\u001B[0m       0.7669        \u001B[35m0.7352\u001B[0m  0.4796\n",
      "      8        \u001B[36m0.5758\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7267\u001B[0m  0.4497\n",
      "      9        \u001B[36m0.5245\u001B[0m       0.7769        0.7283  0.4955\n",
      "     10        \u001B[36m0.5153\u001B[0m       0.7719        0.7480  0.5058\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7599\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0978\u001B[0m  0.4657\n",
      "      2        \u001B[36m1.2072\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9271\u001B[0m  0.4825\n",
      "      3        \u001B[36m0.9847\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.8421\u001B[0m  0.4750\n",
      "      4        \u001B[36m0.8576\u001B[0m       0.7570        \u001B[35m0.8271\u001B[0m  0.4528\n",
      "      5        \u001B[36m0.7776\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7877\u001B[0m  0.4627\n",
      "      6        \u001B[36m0.7105\u001B[0m       0.7653        \u001B[35m0.7771\u001B[0m  0.4569\n",
      "      7        \u001B[36m0.6793\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7295\u001B[0m  0.4793\n",
      "      8        \u001B[36m0.6005\u001B[0m       0.7653        0.7674  0.4679\n",
      "      9        \u001B[36m0.5709\u001B[0m       0.7868        0.7403  0.4744\n",
      "     10        \u001B[36m0.5336\u001B[0m       0.7950        \u001B[35m0.7218\u001B[0m  0.4639\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6651\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.0501\u001B[0m  0.4706\n",
      "      2        \u001B[36m1.1091\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.8764\u001B[0m  0.4659\n",
      "      3        \u001B[36m0.9447\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.8363\u001B[0m  0.4499\n",
      "      4        \u001B[36m0.8385\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.7745\u001B[0m  0.4741\n",
      "      5        \u001B[36m0.7367\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.7625\u001B[0m  0.5005\n",
      "      6        \u001B[36m0.6999\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7070\u001B[0m  0.4824\n",
      "      7        \u001B[36m0.6027\u001B[0m       0.7669        0.7151  0.4706\n",
      "      8        0.6107       0.7603        \u001B[35m0.7062\u001B[0m  0.4482\n",
      "      9        \u001B[36m0.5353\u001B[0m       0.7620        0.7070  0.5120\n",
      "     10        \u001B[36m0.5140\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.6886\u001B[0m  0.4631\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7385\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m1.0014\u001B[0m  0.4562\n",
      "      2        \u001B[36m1.1576\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.8689\u001B[0m  0.4700\n",
      "      3        \u001B[36m0.9872\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.7956\u001B[0m  0.4904\n",
      "      4        \u001B[36m0.8547\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.7670\u001B[0m  0.5070\n",
      "      5        \u001B[36m0.7563\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7293\u001B[0m  0.5216\n",
      "      6        \u001B[36m0.6910\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.6849\u001B[0m  0.4927\n",
      "      7        \u001B[36m0.6424\u001B[0m       0.7719        0.7031  0.4956\n",
      "      8        \u001B[36m0.5900\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.6655\u001B[0m  0.4754\n",
      "      9        \u001B[36m0.5281\u001B[0m       0.7818        0.6792  0.4593\n",
      "     10        \u001B[36m0.5010\u001B[0m       0.7669        0.6985  0.4524\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   5.0s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5822\u001B[0m       \u001B[32m0.6760\u001B[0m        \u001B[35m0.9778\u001B[0m  0.4507\n",
      "      2        \u001B[36m0.9345\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8498\u001B[0m  0.4868\n",
      "      3        \u001B[36m0.7797\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.8010\u001B[0m  0.5015\n",
      "      4        \u001B[36m0.6856\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7522\u001B[0m  0.4915\n",
      "      5        \u001B[36m0.5912\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7450\u001B[0m  0.4569\n",
      "      6        \u001B[36m0.5340\u001B[0m       \u001B[32m0.7884\u001B[0m        0.7620  0.4601\n",
      "      7        \u001B[36m0.4824\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.7432\u001B[0m  0.4654\n",
      "      8        \u001B[36m0.4366\u001B[0m       0.7884        0.7620  0.4536\n",
      "      9        \u001B[36m0.4107\u001B[0m       0.7901        0.7644  0.4669\n",
      "     10        \u001B[36m0.3768\u001B[0m       0.7901        0.7869  0.4562\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5666\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m0.9783\u001B[0m  0.4374\n",
      "      2        \u001B[36m0.9741\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8388\u001B[0m  0.4419\n",
      "      3        \u001B[36m0.7744\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.7834\u001B[0m  0.4483\n",
      "      4        \u001B[36m0.6898\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.7191\u001B[0m  0.4616\n",
      "      5        \u001B[36m0.5840\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7034\u001B[0m  0.4469\n",
      "      6        \u001B[36m0.5292\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.7011\u001B[0m  0.4538\n",
      "      7        \u001B[36m0.4898\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6763\u001B[0m  0.4469\n",
      "      8        \u001B[36m0.4167\u001B[0m       0.7884        0.6793  0.5389\n",
      "      9        \u001B[36m0.4006\u001B[0m       0.7934        0.6906  0.4822\n",
      "     10        \u001B[36m0.3792\u001B[0m       0.7818        0.7033  0.4741\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5139\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m0.9772\u001B[0m  0.4486\n",
      "      2        \u001B[36m0.9295\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.8741\u001B[0m  0.4944\n",
      "      3        \u001B[36m0.7749\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8357\u001B[0m  0.4794\n",
      "      4        \u001B[36m0.6366\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8003\u001B[0m  0.4800\n",
      "      5        \u001B[36m0.5595\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.7718\u001B[0m  0.4954\n",
      "      6        \u001B[36m0.5081\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7477\u001B[0m  0.4757\n",
      "      7        \u001B[36m0.4587\u001B[0m       0.7769        \u001B[35m0.7341\u001B[0m  0.4906\n",
      "      8        \u001B[36m0.4138\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7225\u001B[0m  0.4718\n",
      "      9        \u001B[36m0.3726\u001B[0m       0.7752        0.7434  0.4683\n",
      "     10        \u001B[36m0.3556\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.7210\u001B[0m  0.4823\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6667\u001B[0m       \u001B[32m0.6661\u001B[0m        \u001B[35m0.9678\u001B[0m  0.4442\n",
      "      2        \u001B[36m1.0054\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8179\u001B[0m  0.4803\n",
      "      3        \u001B[36m0.8239\u001B[0m       \u001B[32m0.7587\u001B[0m        \u001B[35m0.7856\u001B[0m  0.4680\n",
      "      4        \u001B[36m0.7245\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7634\u001B[0m  0.4434\n",
      "      5        \u001B[36m0.6351\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.7359\u001B[0m  0.4615\n",
      "      6        \u001B[36m0.5575\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7293\u001B[0m  0.4613\n",
      "      7        \u001B[36m0.5024\u001B[0m       0.7818        \u001B[35m0.7157\u001B[0m  0.4518\n",
      "      8        \u001B[36m0.4806\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.7067\u001B[0m  0.4479\n",
      "      9        \u001B[36m0.4459\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6856\u001B[0m  0.4426\n",
      "     10        \u001B[36m0.3772\u001B[0m       \u001B[32m0.8017\u001B[0m        0.7140  0.4372\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5753\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m0.9999\u001B[0m  0.4392\n",
      "      2        \u001B[36m0.9976\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.8351\u001B[0m  0.4453\n",
      "      3        \u001B[36m0.8200\u001B[0m       0.7719        \u001B[35m0.7909\u001B[0m  0.4362\n",
      "      4        \u001B[36m0.7043\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7101\u001B[0m  0.4999\n",
      "      5        \u001B[36m0.6241\u001B[0m       0.7802        \u001B[35m0.7080\u001B[0m  0.4563\n",
      "      6        \u001B[36m0.5362\u001B[0m       \u001B[32m0.8165\u001B[0m        \u001B[35m0.6794\u001B[0m  0.4708\n",
      "      7        0.5366       0.8033        0.6898  0.4639\n",
      "      8        \u001B[36m0.4788\u001B[0m       0.7950        0.7107  0.4753\n",
      "      9        \u001B[36m0.4339\u001B[0m       0.8132        \u001B[35m0.6788\u001B[0m  0.4774\n",
      "     10        \u001B[36m0.3952\u001B[0m       0.8033        0.6845  0.4609\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5907\u001B[0m       \u001B[32m0.6744\u001B[0m        \u001B[35m1.0309\u001B[0m  0.4791\n",
      "      2        \u001B[36m0.9824\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.8660\u001B[0m  0.4943\n",
      "      3        \u001B[36m0.7936\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7920\u001B[0m  0.4882\n",
      "      4        \u001B[36m0.7123\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7462\u001B[0m  0.4513\n",
      "      5        \u001B[36m0.5894\u001B[0m       0.7785        \u001B[35m0.6944\u001B[0m  0.4629\n",
      "      6        \u001B[36m0.5445\u001B[0m       0.7702        0.6988  0.4576\n",
      "      7        \u001B[36m0.4954\u001B[0m       0.7752        0.7155  0.4615\n",
      "      8        \u001B[36m0.4358\u001B[0m       0.7769        0.7105  0.4661\n",
      "      9        \u001B[36m0.4126\u001B[0m       0.7653        0.7260  0.4598\n",
      "     10        \u001B[36m0.3842\u001B[0m       \u001B[32m0.7835\u001B[0m        0.7329  0.4737\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5817\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m0.9293\u001B[0m  0.4293\n",
      "      2        \u001B[36m1.0445\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.7755\u001B[0m  0.4324\n",
      "      3        \u001B[36m0.8397\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7190\u001B[0m  0.4472\n",
      "      4        \u001B[36m0.6891\u001B[0m       \u001B[32m0.7901\u001B[0m        0.7296  0.4697\n",
      "      5        \u001B[36m0.6293\u001B[0m       \u001B[32m0.7917\u001B[0m        0.7314  0.4543\n",
      "      6        \u001B[36m0.5741\u001B[0m       \u001B[32m0.8099\u001B[0m        \u001B[35m0.7146\u001B[0m  0.4435\n",
      "      7        \u001B[36m0.4979\u001B[0m       0.7851        0.7448  0.4676\n",
      "      8        \u001B[36m0.4651\u001B[0m       0.7983        0.7585  0.4432\n",
      "      9        \u001B[36m0.4122\u001B[0m       0.7967        0.7396  0.4328\n",
      "     10        \u001B[36m0.4048\u001B[0m       0.7868        0.7702  0.4367\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6435\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m0.9588\u001B[0m  0.4383\n",
      "      2        \u001B[36m1.0392\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.8512\u001B[0m  0.4320\n",
      "      3        \u001B[36m0.8281\u001B[0m       0.7372        \u001B[35m0.7886\u001B[0m  0.4368\n",
      "      4        \u001B[36m0.7445\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7421\u001B[0m  0.4329\n",
      "      5        \u001B[36m0.6497\u001B[0m       0.7521        0.7708  0.4342\n",
      "      6        \u001B[36m0.5742\u001B[0m       0.7736        \u001B[35m0.7295\u001B[0m  0.4766\n",
      "      7        \u001B[36m0.5537\u001B[0m       0.7686        0.7328  0.4507\n",
      "      8        \u001B[36m0.4791\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7202\u001B[0m  0.4438\n",
      "      9        \u001B[36m0.4454\u001B[0m       0.7438        0.7757  0.4489\n",
      "     10        \u001B[36m0.3681\u001B[0m       0.7636        \u001B[35m0.7200\u001B[0m  0.4486\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5848\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m0.9423\u001B[0m  0.4354\n",
      "      2        \u001B[36m1.0051\u001B[0m       \u001B[32m0.7587\u001B[0m        \u001B[35m0.8310\u001B[0m  0.4405\n",
      "      3        \u001B[36m0.8383\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.7832\u001B[0m  0.4531\n",
      "      4        \u001B[36m0.7245\u001B[0m       0.7570        \u001B[35m0.7649\u001B[0m  0.4871\n",
      "      5        \u001B[36m0.6412\u001B[0m       \u001B[32m0.7653\u001B[0m        0.7789  0.4822\n",
      "      6        \u001B[36m0.5509\u001B[0m       0.7339        \u001B[35m0.7566\u001B[0m  0.4957\n",
      "      7        \u001B[36m0.5141\u001B[0m       0.7603        \u001B[35m0.7541\u001B[0m  0.5114\n",
      "      8        \u001B[36m0.4895\u001B[0m       0.7537        0.7750  0.4658\n",
      "      9        \u001B[36m0.4368\u001B[0m       0.7653        \u001B[35m0.7274\u001B[0m  0.4490\n",
      "     10        \u001B[36m0.3925\u001B[0m       0.7587        0.7681  0.4534\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3573\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.8792\u001B[0m  0.4700\n",
      "      2        \u001B[36m0.8080\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8150\u001B[0m  0.4667\n",
      "      3        \u001B[36m0.6361\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7521\u001B[0m  0.4829\n",
      "      4        \u001B[36m0.5231\u001B[0m       \u001B[32m0.7950\u001B[0m        0.7656  0.4796\n",
      "      5        \u001B[36m0.4664\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.7442\u001B[0m  0.4441\n",
      "      6        \u001B[36m0.3896\u001B[0m       0.7983        0.7504  0.4837\n",
      "      7        \u001B[36m0.3455\u001B[0m       0.7967        0.7889  0.5036\n",
      "      8        \u001B[36m0.3144\u001B[0m       0.8033        0.7962  0.5074\n",
      "      9        \u001B[36m0.2722\u001B[0m       \u001B[32m0.8116\u001B[0m        0.7942  0.4441\n",
      "     10        \u001B[36m0.2565\u001B[0m       \u001B[32m0.8132\u001B[0m        0.8145  0.4486\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3692\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.8686\u001B[0m  0.4643\n",
      "      2        \u001B[36m0.7875\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7542\u001B[0m  0.4237\n",
      "      3        \u001B[36m0.6459\u001B[0m       0.7769        \u001B[35m0.7183\u001B[0m  0.4234\n",
      "      4        \u001B[36m0.5384\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.6844\u001B[0m  0.4238\n",
      "      5        \u001B[36m0.4595\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6614\u001B[0m  0.4300\n",
      "      6        \u001B[36m0.3992\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6525\u001B[0m  0.4415\n",
      "      7        \u001B[36m0.3500\u001B[0m       \u001B[32m0.8149\u001B[0m        0.6535  0.4668\n",
      "      8        \u001B[36m0.2980\u001B[0m       0.7967        0.6919  0.4510\n",
      "      9        0.2994       0.8099        \u001B[35m0.6431\u001B[0m  0.4791\n",
      "     10        \u001B[36m0.2604\u001B[0m       0.8017        0.7142  0.4592\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3676\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.8575\u001B[0m  0.4790\n",
      "      2        \u001B[36m0.7641\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7669\u001B[0m  0.4740\n",
      "      3        \u001B[36m0.6069\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.7457\u001B[0m  0.4757\n",
      "      4        \u001B[36m0.4904\u001B[0m       0.7884        \u001B[35m0.7182\u001B[0m  0.4426\n",
      "      5        \u001B[36m0.4078\u001B[0m       \u001B[32m0.7983\u001B[0m        0.7590  0.4221\n",
      "      6        \u001B[36m0.3540\u001B[0m       \u001B[32m0.8132\u001B[0m        0.7191  0.4418\n",
      "      7        \u001B[36m0.3172\u001B[0m       0.8033        0.7371  0.4207\n",
      "      8        \u001B[36m0.2876\u001B[0m       0.7934        0.7720  0.4234\n",
      "      9        \u001B[36m0.2502\u001B[0m       0.7983        0.7657  0.4539\n",
      "     10        \u001B[36m0.2312\u001B[0m       0.8017        0.7903  0.4626\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4536\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8477\u001B[0m  0.4545\n",
      "      2        \u001B[36m0.8205\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7776\u001B[0m  0.4287\n",
      "      3        \u001B[36m0.6677\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7354\u001B[0m  0.4288\n",
      "      4        \u001B[36m0.5834\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7299\u001B[0m  0.4401\n",
      "      5        \u001B[36m0.5143\u001B[0m       0.7983        \u001B[35m0.7290\u001B[0m  0.4415\n",
      "      6        \u001B[36m0.4229\u001B[0m       0.7917        0.8023  0.4432\n",
      "      7        \u001B[36m0.4075\u001B[0m       0.7917        0.7608  0.4454\n",
      "      8        \u001B[36m0.3567\u001B[0m       0.7901        0.7927  0.4452\n",
      "      9        \u001B[36m0.3128\u001B[0m       0.7818        0.8880  0.4501\n",
      "     10        \u001B[36m0.2779\u001B[0m       0.7934        0.7531  0.4473\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4021\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m0.8399\u001B[0m  0.4500\n",
      "      2        \u001B[36m0.8297\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7562\u001B[0m  0.4472\n",
      "      3        \u001B[36m0.6437\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7110\u001B[0m  0.4239\n",
      "      4        \u001B[36m0.5710\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.7017\u001B[0m  0.4292\n",
      "      5        \u001B[36m0.4777\u001B[0m       0.7818        0.7342  0.4315\n",
      "      6        \u001B[36m0.4331\u001B[0m       0.7851        0.7228  0.4304\n",
      "      7        \u001B[36m0.3692\u001B[0m       \u001B[32m0.8165\u001B[0m        0.7033  0.4338\n",
      "      8        \u001B[36m0.3361\u001B[0m       0.8033        0.7103  0.4455\n",
      "      9        \u001B[36m0.3244\u001B[0m       0.8050        0.7618  0.4462\n",
      "     10        \u001B[36m0.2929\u001B[0m       0.8033        0.7109  0.4485\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3858\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8344\u001B[0m  0.4544\n",
      "      2        \u001B[36m0.8243\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.7667\u001B[0m  0.4737\n",
      "      3        \u001B[36m0.6519\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7278\u001B[0m  0.4468\n",
      "      4        \u001B[36m0.5399\u001B[0m       0.7587        0.7653  0.4459\n",
      "      5        \u001B[36m0.4712\u001B[0m       0.7752        \u001B[35m0.7269\u001B[0m  0.4442\n",
      "      6        \u001B[36m0.3879\u001B[0m       0.7785        0.7726  0.4501\n",
      "      7        \u001B[36m0.3647\u001B[0m       0.7653        0.7780  0.4347\n",
      "      8        \u001B[36m0.3044\u001B[0m       \u001B[32m0.7901\u001B[0m        0.7477  0.4336\n",
      "      9        0.3062       0.7835        0.7996  0.4323\n",
      "     10        \u001B[36m0.2726\u001B[0m       0.7719        0.8050  0.4306\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4387\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8260\u001B[0m  0.4286\n",
      "      2        \u001B[36m0.9014\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7331\u001B[0m  0.4279\n",
      "      3        \u001B[36m0.7628\u001B[0m       \u001B[32m0.7802\u001B[0m        0.7574  0.4285\n",
      "      4        \u001B[36m0.6355\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7237\u001B[0m  0.4569\n",
      "      5        \u001B[36m0.5514\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.7081\u001B[0m  0.4894\n",
      "      6        \u001B[36m0.4728\u001B[0m       \u001B[32m0.8000\u001B[0m        0.7350  0.4659\n",
      "      7        \u001B[36m0.4315\u001B[0m       \u001B[32m0.8248\u001B[0m        \u001B[35m0.6807\u001B[0m  0.4368\n",
      "      8        \u001B[36m0.4001\u001B[0m       0.7769        0.8191  0.4417\n",
      "      9        \u001B[36m0.3405\u001B[0m       0.7967        0.7833  0.4239\n",
      "     10        \u001B[36m0.3058\u001B[0m       0.7917        0.8895  0.4249\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4821\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.8445\u001B[0m  0.4425\n",
      "      2        \u001B[36m0.9096\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.8389\u001B[0m  0.4298\n",
      "      3        \u001B[36m0.7829\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.7886\u001B[0m  0.4219\n",
      "      4        \u001B[36m0.6355\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7087\u001B[0m  0.4292\n",
      "      5        \u001B[36m0.5567\u001B[0m       0.7752        0.7400  0.4256\n",
      "      6        \u001B[36m0.4740\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.7063\u001B[0m  0.4253\n",
      "      7        \u001B[36m0.4080\u001B[0m       0.7769        0.7199  0.4250\n",
      "      8        \u001B[36m0.3896\u001B[0m       0.7587        0.7967  0.4251\n",
      "      9        \u001B[36m0.3458\u001B[0m       0.7884        0.8362  0.4260\n",
      "     10        \u001B[36m0.3431\u001B[0m       0.7934        0.8002  0.4243\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4350\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.8862\u001B[0m  0.4208\n",
      "      2        \u001B[36m0.9419\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7784\u001B[0m  0.4222\n",
      "      3        \u001B[36m0.7616\u001B[0m       0.7521        0.7991  0.4241\n",
      "      4        \u001B[36m0.6118\u001B[0m       0.7554        \u001B[35m0.7702\u001B[0m  0.4285\n",
      "      5        \u001B[36m0.5073\u001B[0m       0.7537        0.8119  0.4231\n",
      "      6        \u001B[36m0.4701\u001B[0m       0.7554        0.8127  0.4248\n",
      "      7        \u001B[36m0.4101\u001B[0m       0.7504        0.8668  0.4258\n",
      "      8        \u001B[36m0.3666\u001B[0m       \u001B[32m0.7686\u001B[0m        0.7824  0.4257\n",
      "      9        \u001B[36m0.3159\u001B[0m       0.7554        0.8761  0.4261\n",
      "     10        \u001B[36m0.3069\u001B[0m       0.7521        0.9266  0.4265\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2719\u001B[0m       \u001B[32m0.2810\u001B[0m        \u001B[35m1.7837\u001B[0m  0.4924\n",
      "      2        \u001B[36m1.8497\u001B[0m       \u001B[32m0.4331\u001B[0m        \u001B[35m1.5846\u001B[0m  0.4919\n",
      "      3        \u001B[36m1.6400\u001B[0m       \u001B[32m0.4876\u001B[0m        \u001B[35m1.4606\u001B[0m  0.4990\n",
      "      4        \u001B[36m1.4945\u001B[0m       \u001B[32m0.5306\u001B[0m        \u001B[35m1.3802\u001B[0m  0.4966\n",
      "      5        \u001B[36m1.4204\u001B[0m       \u001B[32m0.5554\u001B[0m        \u001B[35m1.3193\u001B[0m  0.4944\n",
      "      6        \u001B[36m1.3429\u001B[0m       \u001B[32m0.5917\u001B[0m        \u001B[35m1.2543\u001B[0m  0.5074\n",
      "      7        \u001B[36m1.2938\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.2065\u001B[0m  0.5126\n",
      "      8        \u001B[36m1.2126\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.1731\u001B[0m  0.4973\n",
      "      9        \u001B[36m1.1753\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1389\u001B[0m  0.4615\n",
      "     10        \u001B[36m1.1347\u001B[0m       \u001B[32m0.6562\u001B[0m        \u001B[35m1.1133\u001B[0m  0.4738\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   5.1s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1735\u001B[0m       \u001B[32m0.3124\u001B[0m        \u001B[35m1.6393\u001B[0m  0.4868\n",
      "      2        \u001B[36m1.7617\u001B[0m       \u001B[32m0.4678\u001B[0m        \u001B[35m1.4660\u001B[0m  0.4698\n",
      "      3        \u001B[36m1.5616\u001B[0m       \u001B[32m0.5273\u001B[0m        \u001B[35m1.3675\u001B[0m  0.5022\n",
      "      4        \u001B[36m1.4905\u001B[0m       \u001B[32m0.5620\u001B[0m        \u001B[35m1.2944\u001B[0m  0.5178\n",
      "      5        \u001B[36m1.3412\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.2368\u001B[0m  0.5069\n",
      "      6        \u001B[36m1.2759\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.1902\u001B[0m  0.4982\n",
      "      7        \u001B[36m1.2349\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.1592\u001B[0m  0.5150\n",
      "      8        \u001B[36m1.1700\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.1257\u001B[0m  0.5060\n",
      "      9        \u001B[36m1.1251\u001B[0m       0.6314        \u001B[35m1.0893\u001B[0m  0.5047\n",
      "     10        \u001B[36m1.0843\u001B[0m       \u001B[32m0.6479\u001B[0m        \u001B[35m1.0620\u001B[0m  0.5116\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   5.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.6324\u001B[0m       \u001B[32m0.2661\u001B[0m        \u001B[35m1.8844\u001B[0m  0.4901\n",
      "      2        \u001B[36m1.9370\u001B[0m       \u001B[32m0.4248\u001B[0m        \u001B[35m1.5856\u001B[0m  0.4842\n",
      "      3        \u001B[36m1.7146\u001B[0m       \u001B[32m0.4826\u001B[0m        \u001B[35m1.4411\u001B[0m  0.5080\n",
      "      4        \u001B[36m1.5342\u001B[0m       \u001B[32m0.5107\u001B[0m        \u001B[35m1.3512\u001B[0m  0.4978\n",
      "      5        \u001B[36m1.4433\u001B[0m       \u001B[32m0.5421\u001B[0m        \u001B[35m1.2856\u001B[0m  0.4578\n",
      "      6        \u001B[36m1.3883\u001B[0m       \u001B[32m0.5686\u001B[0m        \u001B[35m1.2368\u001B[0m  0.4608\n",
      "      7        \u001B[36m1.2700\u001B[0m       \u001B[32m0.5868\u001B[0m        \u001B[35m1.1838\u001B[0m  0.4601\n",
      "      8        \u001B[36m1.2291\u001B[0m       \u001B[32m0.6000\u001B[0m        \u001B[35m1.1499\u001B[0m  0.4633\n",
      "      9        \u001B[36m1.1590\u001B[0m       \u001B[32m0.6099\u001B[0m        \u001B[35m1.1218\u001B[0m  0.4626\n",
      "     10        \u001B[36m1.1170\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.0904\u001B[0m  0.4484\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3318\u001B[0m       \u001B[32m0.3934\u001B[0m        \u001B[35m1.6146\u001B[0m  0.4530\n",
      "      2        \u001B[36m1.8713\u001B[0m       \u001B[32m0.4595\u001B[0m        \u001B[35m1.4372\u001B[0m  0.4812\n",
      "      3        \u001B[36m1.6495\u001B[0m       \u001B[32m0.5140\u001B[0m        \u001B[35m1.3351\u001B[0m  0.4484\n",
      "      4        \u001B[36m1.5385\u001B[0m       \u001B[32m0.5488\u001B[0m        \u001B[35m1.2738\u001B[0m  0.4438\n",
      "      5        \u001B[36m1.4435\u001B[0m       \u001B[32m0.5736\u001B[0m        \u001B[35m1.2089\u001B[0m  0.4470\n",
      "      6        \u001B[36m1.3494\u001B[0m       \u001B[32m0.5917\u001B[0m        \u001B[35m1.1614\u001B[0m  0.4436\n",
      "      7        \u001B[36m1.3286\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.1179\u001B[0m  0.4703\n",
      "      8        \u001B[36m1.2170\u001B[0m       \u001B[32m0.6397\u001B[0m        \u001B[35m1.0923\u001B[0m  0.4597\n",
      "      9        \u001B[36m1.1667\u001B[0m       \u001B[32m0.6545\u001B[0m        \u001B[35m1.0792\u001B[0m  0.4611\n",
      "     10        1.1687       \u001B[32m0.6579\u001B[0m        \u001B[35m1.0475\u001B[0m  0.4512\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2209\u001B[0m       \u001B[32m0.3174\u001B[0m        \u001B[35m1.6305\u001B[0m  0.4589\n",
      "      2        \u001B[36m1.7594\u001B[0m       \u001B[32m0.4529\u001B[0m        \u001B[35m1.4328\u001B[0m  0.4783\n",
      "      3        \u001B[36m1.5620\u001B[0m       \u001B[32m0.5157\u001B[0m        \u001B[35m1.3322\u001B[0m  0.4864\n",
      "      4        \u001B[36m1.4710\u001B[0m       \u001B[32m0.5587\u001B[0m        \u001B[35m1.2616\u001B[0m  0.4633\n",
      "      5        \u001B[36m1.3488\u001B[0m       \u001B[32m0.6050\u001B[0m        \u001B[35m1.2114\u001B[0m  0.4688\n",
      "      6        \u001B[36m1.2926\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1665\u001B[0m  0.4650\n",
      "      7        \u001B[36m1.2393\u001B[0m       \u001B[32m0.6446\u001B[0m        \u001B[35m1.1301\u001B[0m  0.4682\n",
      "      8        \u001B[36m1.1842\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.1039\u001B[0m  0.5008\n",
      "      9        \u001B[36m1.1248\u001B[0m       \u001B[32m0.6760\u001B[0m        \u001B[35m1.0806\u001B[0m  0.4920\n",
      "     10        \u001B[36m1.0715\u001B[0m       \u001B[32m0.6810\u001B[0m        \u001B[35m1.0619\u001B[0m  0.5087\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2603\u001B[0m       \u001B[32m0.3736\u001B[0m        \u001B[35m1.7528\u001B[0m  0.5020\n",
      "      2        \u001B[36m1.8388\u001B[0m       \u001B[32m0.4678\u001B[0m        \u001B[35m1.5269\u001B[0m  0.4888\n",
      "      3        \u001B[36m1.6354\u001B[0m       \u001B[32m0.5289\u001B[0m        \u001B[35m1.3839\u001B[0m  0.5010\n",
      "      4        \u001B[36m1.5199\u001B[0m       \u001B[32m0.5620\u001B[0m        \u001B[35m1.2927\u001B[0m  0.4895\n",
      "      5        \u001B[36m1.3435\u001B[0m       \u001B[32m0.5901\u001B[0m        \u001B[35m1.2243\u001B[0m  0.4570\n",
      "      6        \u001B[36m1.3161\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.1753\u001B[0m  0.4678\n",
      "      7        \u001B[36m1.2079\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.1311\u001B[0m  0.5005\n",
      "      8        \u001B[36m1.1655\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.0961\u001B[0m  0.5122\n",
      "      9        \u001B[36m1.1326\u001B[0m       \u001B[32m0.6545\u001B[0m        \u001B[35m1.0669\u001B[0m  0.4994\n",
      "     10        \u001B[36m1.0771\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m1.0375\u001B[0m  0.5063\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   5.1s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2919\u001B[0m       \u001B[32m0.4099\u001B[0m        \u001B[35m1.5832\u001B[0m  0.4912\n",
      "      2        \u001B[36m1.7700\u001B[0m       \u001B[32m0.4777\u001B[0m        \u001B[35m1.4063\u001B[0m  0.4595\n",
      "      3        \u001B[36m1.5723\u001B[0m       \u001B[32m0.5240\u001B[0m        \u001B[35m1.3014\u001B[0m  0.4448\n",
      "      4        \u001B[36m1.4403\u001B[0m       \u001B[32m0.5769\u001B[0m        \u001B[35m1.2283\u001B[0m  0.4603\n",
      "      5        \u001B[36m1.3407\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1758\u001B[0m  0.4977\n",
      "      6        \u001B[36m1.2954\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.1283\u001B[0m  0.5233\n",
      "      7        \u001B[36m1.1971\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.0947\u001B[0m  0.5070\n",
      "      8        \u001B[36m1.1691\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m1.0632\u001B[0m  0.5189\n",
      "      9        \u001B[36m1.0923\u001B[0m       0.6909        \u001B[35m1.0321\u001B[0m  0.4989\n",
      "     10        \u001B[36m1.0616\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m1.0034\u001B[0m  0.4880\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   5.0s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2413\u001B[0m       \u001B[32m0.3917\u001B[0m        \u001B[35m1.6279\u001B[0m  0.4869\n",
      "      2        \u001B[36m1.8347\u001B[0m       \u001B[32m0.4612\u001B[0m        \u001B[35m1.4256\u001B[0m  0.5115\n",
      "      3        \u001B[36m1.6029\u001B[0m       \u001B[32m0.5190\u001B[0m        \u001B[35m1.3106\u001B[0m  0.4747\n",
      "      4        \u001B[36m1.5223\u001B[0m       \u001B[32m0.5752\u001B[0m        \u001B[35m1.2389\u001B[0m  0.4631\n",
      "      5        \u001B[36m1.3660\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.1854\u001B[0m  0.4829\n",
      "      6        \u001B[36m1.2799\u001B[0m       \u001B[32m0.6298\u001B[0m        \u001B[35m1.1354\u001B[0m  0.4958\n",
      "      7        \u001B[36m1.2320\u001B[0m       \u001B[32m0.6562\u001B[0m        \u001B[35m1.1033\u001B[0m  0.5044\n",
      "      8        \u001B[36m1.1919\u001B[0m       \u001B[32m0.6678\u001B[0m        \u001B[35m1.0632\u001B[0m  0.4729\n",
      "      9        \u001B[36m1.1042\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m1.0305\u001B[0m  0.4648\n",
      "     10        \u001B[36m1.0539\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m1.0087\u001B[0m  0.4476\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3352\u001B[0m       \u001B[32m0.3752\u001B[0m        \u001B[35m1.6561\u001B[0m  0.4448\n",
      "      2        \u001B[36m1.8239\u001B[0m       \u001B[32m0.4645\u001B[0m        \u001B[35m1.4376\u001B[0m  0.4440\n",
      "      3        \u001B[36m1.6449\u001B[0m       \u001B[32m0.5388\u001B[0m        \u001B[35m1.2988\u001B[0m  0.4667\n",
      "      4        \u001B[36m1.4728\u001B[0m       \u001B[32m0.5835\u001B[0m        \u001B[35m1.2155\u001B[0m  0.4386\n",
      "      5        \u001B[36m1.3600\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.1488\u001B[0m  0.4529\n",
      "      6        \u001B[36m1.2978\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.0852\u001B[0m  0.4739\n",
      "      7        \u001B[36m1.2247\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.0513\u001B[0m  0.4605\n",
      "      8        \u001B[36m1.1584\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0087\u001B[0m  0.4700\n",
      "      9        \u001B[36m1.1147\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m0.9804\u001B[0m  0.5092\n",
      "     10        \u001B[36m1.0485\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m0.9567\u001B[0m  0.5005\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1228\u001B[0m       \u001B[32m0.4248\u001B[0m        \u001B[35m1.5924\u001B[0m  0.4806\n",
      "      2        \u001B[36m1.6419\u001B[0m       \u001B[32m0.5008\u001B[0m        \u001B[35m1.3937\u001B[0m  0.4769\n",
      "      3        \u001B[36m1.4543\u001B[0m       \u001B[32m0.5719\u001B[0m        \u001B[35m1.2910\u001B[0m  0.4504\n",
      "      4        \u001B[36m1.3446\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.2181\u001B[0m  0.4524\n",
      "      5        \u001B[36m1.2171\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1578\u001B[0m  0.4476\n",
      "      6        \u001B[36m1.1233\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.1076\u001B[0m  0.4413\n",
      "      7        \u001B[36m1.0565\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0672\u001B[0m  0.4389\n",
      "      8        \u001B[36m0.9976\u001B[0m       \u001B[32m0.7008\u001B[0m        \u001B[35m1.0400\u001B[0m  0.4651\n",
      "      9        \u001B[36m0.9616\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m1.0058\u001B[0m  0.4957\n",
      "     10        \u001B[36m0.9107\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9878\u001B[0m  0.4604\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0789\u001B[0m       \u001B[32m0.4000\u001B[0m        \u001B[35m1.6084\u001B[0m  0.4514\n",
      "      2        \u001B[36m1.6262\u001B[0m       \u001B[32m0.4959\u001B[0m        \u001B[35m1.3931\u001B[0m  0.4559\n",
      "      3        \u001B[36m1.4123\u001B[0m       \u001B[32m0.5488\u001B[0m        \u001B[35m1.2744\u001B[0m  0.4579\n",
      "      4        \u001B[36m1.2684\u001B[0m       \u001B[32m0.5934\u001B[0m        \u001B[35m1.1921\u001B[0m  0.4808\n",
      "      5        \u001B[36m1.1898\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.1354\u001B[0m  0.4546\n",
      "      6        \u001B[36m1.1220\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.0800\u001B[0m  0.4557\n",
      "      7        \u001B[36m1.0714\u001B[0m       \u001B[32m0.6678\u001B[0m        \u001B[35m1.0372\u001B[0m  0.4762\n",
      "      8        \u001B[36m0.9727\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0085\u001B[0m  0.4910\n",
      "      9        \u001B[36m0.9224\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m0.9731\u001B[0m  0.4458\n",
      "     10        \u001B[36m0.9104\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9465\u001B[0m  0.4378\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9832\u001B[0m       \u001B[32m0.4562\u001B[0m        \u001B[35m1.4913\u001B[0m  0.4377\n",
      "      2        \u001B[36m1.5948\u001B[0m       \u001B[32m0.5372\u001B[0m        \u001B[35m1.3291\u001B[0m  0.4367\n",
      "      3        \u001B[36m1.4183\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.2318\u001B[0m  0.4914\n",
      "      4        \u001B[36m1.2849\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.1688\u001B[0m  0.4579\n",
      "      5        \u001B[36m1.1846\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.1084\u001B[0m  0.4545\n",
      "      6        \u001B[36m1.0821\u001B[0m       \u001B[32m0.6661\u001B[0m        \u001B[35m1.0700\u001B[0m  0.4422\n",
      "      7        \u001B[36m1.0333\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m1.0277\u001B[0m  0.4640\n",
      "      8        \u001B[36m0.9719\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m0.9922\u001B[0m  0.4715\n",
      "      9        \u001B[36m0.9331\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9680\u001B[0m  0.4596\n",
      "     10        \u001B[36m0.8928\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9381\u001B[0m  0.4878\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0565\u001B[0m       \u001B[32m0.4826\u001B[0m        \u001B[35m1.4400\u001B[0m  0.4444\n",
      "      2        \u001B[36m1.5802\u001B[0m       \u001B[32m0.5769\u001B[0m        \u001B[35m1.2509\u001B[0m  0.4588\n",
      "      3        \u001B[36m1.4210\u001B[0m       \u001B[32m0.6512\u001B[0m        \u001B[35m1.1445\u001B[0m  0.4482\n",
      "      4        \u001B[36m1.2570\u001B[0m       \u001B[32m0.6810\u001B[0m        \u001B[35m1.0786\u001B[0m  0.4507\n",
      "      5        \u001B[36m1.1707\u001B[0m       \u001B[32m0.7008\u001B[0m        \u001B[35m1.0162\u001B[0m  0.4429\n",
      "      6        \u001B[36m1.1226\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.9708\u001B[0m  0.4482\n",
      "      7        \u001B[36m1.0144\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9396\u001B[0m  0.4535\n",
      "      8        \u001B[36m0.9498\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.9080\u001B[0m  0.4282\n",
      "      9        \u001B[36m0.9286\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.8880\u001B[0m  0.4361\n",
      "     10        \u001B[36m0.9078\u001B[0m       0.7289        \u001B[35m0.8651\u001B[0m  0.4415\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9955\u001B[0m       \u001B[32m0.4397\u001B[0m        \u001B[35m1.5242\u001B[0m  0.4473\n",
      "      2        \u001B[36m1.6062\u001B[0m       \u001B[32m0.4992\u001B[0m        \u001B[35m1.3583\u001B[0m  0.4371\n",
      "      3        \u001B[36m1.4036\u001B[0m       \u001B[32m0.5901\u001B[0m        \u001B[35m1.2602\u001B[0m  0.4355\n",
      "      4        \u001B[36m1.2383\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.1831\u001B[0m  0.4897\n",
      "      5        \u001B[36m1.1928\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1253\u001B[0m  0.4691\n",
      "      6        \u001B[36m1.0889\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0687\u001B[0m  0.4481\n",
      "      7        \u001B[36m0.9966\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m1.0322\u001B[0m  0.4502\n",
      "      8        \u001B[36m0.9392\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9957\u001B[0m  0.4520\n",
      "      9        \u001B[36m0.8965\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.9636\u001B[0m  0.4430\n",
      "     10        \u001B[36m0.8594\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9400\u001B[0m  0.4425\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9869\u001B[0m       \u001B[32m0.4810\u001B[0m        \u001B[35m1.4498\u001B[0m  0.4650\n",
      "      2        \u001B[36m1.5909\u001B[0m       \u001B[32m0.5554\u001B[0m        \u001B[35m1.2852\u001B[0m  0.4716\n",
      "      3        \u001B[36m1.3699\u001B[0m       \u001B[32m0.6215\u001B[0m        \u001B[35m1.1886\u001B[0m  0.4664\n",
      "      4        \u001B[36m1.2452\u001B[0m       \u001B[32m0.6545\u001B[0m        \u001B[35m1.1019\u001B[0m  0.4391\n",
      "      5        \u001B[36m1.1427\u001B[0m       \u001B[32m0.6678\u001B[0m        \u001B[35m1.0585\u001B[0m  0.4732\n",
      "      6        \u001B[36m1.0615\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m1.0112\u001B[0m  0.4385\n",
      "      7        \u001B[36m1.0007\u001B[0m       \u001B[32m0.7008\u001B[0m        \u001B[35m0.9678\u001B[0m  0.4513\n",
      "      8        \u001B[36m0.9180\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.9348\u001B[0m  0.4451\n",
      "      9        \u001B[36m0.8958\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.9174\u001B[0m  0.4510\n",
      "     10        \u001B[36m0.8458\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.8897\u001B[0m  0.4685\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9125\u001B[0m       \u001B[32m0.4777\u001B[0m        \u001B[35m1.4299\u001B[0m  0.4451\n",
      "      2        \u001B[36m1.5043\u001B[0m       \u001B[32m0.5603\u001B[0m        \u001B[35m1.2793\u001B[0m  0.4395\n",
      "      3        \u001B[36m1.3336\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.1742\u001B[0m  0.4789\n",
      "      4        \u001B[36m1.2072\u001B[0m       \u001B[32m0.6479\u001B[0m        \u001B[35m1.1127\u001B[0m  0.4360\n",
      "      5        \u001B[36m1.1360\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0691\u001B[0m  0.4398\n",
      "      6        \u001B[36m1.0457\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m1.0212\u001B[0m  0.4350\n",
      "      7        \u001B[36m0.9755\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9780\u001B[0m  0.4348\n",
      "      8        \u001B[36m0.9379\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9626\u001B[0m  0.4348\n",
      "      9        \u001B[36m0.8814\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.9513\u001B[0m  0.4297\n",
      "     10        \u001B[36m0.8300\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.9283\u001B[0m  0.4352\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0394\u001B[0m       \u001B[32m0.4942\u001B[0m        \u001B[35m1.4218\u001B[0m  0.4668\n",
      "      2        \u001B[36m1.5694\u001B[0m       \u001B[32m0.5752\u001B[0m        \u001B[35m1.2440\u001B[0m  0.4405\n",
      "      3        \u001B[36m1.3732\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.1496\u001B[0m  0.4381\n",
      "      4        \u001B[36m1.2056\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.0646\u001B[0m  0.4336\n",
      "      5        \u001B[36m1.1066\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m1.0100\u001B[0m  0.4397\n",
      "      6        \u001B[36m1.0131\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9690\u001B[0m  0.4577\n",
      "      7        \u001B[36m0.9632\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.9311\u001B[0m  0.4365\n",
      "      8        \u001B[36m0.9182\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.9036\u001B[0m  0.4334\n",
      "      9        \u001B[36m0.8442\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8778\u001B[0m  0.4598\n",
      "     10        \u001B[36m0.8134\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8598\u001B[0m  0.4278\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1029\u001B[0m       \u001B[32m0.4512\u001B[0m        \u001B[35m1.4823\u001B[0m  0.4933\n",
      "      2        \u001B[36m1.5448\u001B[0m       \u001B[32m0.5603\u001B[0m        \u001B[35m1.2813\u001B[0m  0.4610\n",
      "      3        \u001B[36m1.3329\u001B[0m       \u001B[32m0.6215\u001B[0m        \u001B[35m1.1720\u001B[0m  0.4512\n",
      "      4        \u001B[36m1.2151\u001B[0m       \u001B[32m0.6479\u001B[0m        \u001B[35m1.0874\u001B[0m  0.4436\n",
      "      5        \u001B[36m1.0867\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0349\u001B[0m  0.4471\n",
      "      6        \u001B[36m1.0153\u001B[0m       \u001B[32m0.6727\u001B[0m        \u001B[35m0.9783\u001B[0m  0.4711\n",
      "      7        \u001B[36m0.9329\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m0.9334\u001B[0m  0.4663\n",
      "      8        \u001B[36m0.8965\u001B[0m       0.6959        \u001B[35m0.9109\u001B[0m  0.4358\n",
      "      9        \u001B[36m0.8429\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.8911\u001B[0m  0.4364\n",
      "     10        \u001B[36m0.8235\u001B[0m       0.7107        \u001B[35m0.8667\u001B[0m  0.4376\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8758\u001B[0m       \u001B[32m0.5074\u001B[0m        \u001B[35m1.3906\u001B[0m  0.4234\n",
      "      2        \u001B[36m1.3611\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.2097\u001B[0m  0.4269\n",
      "      3        \u001B[36m1.1982\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.1029\u001B[0m  0.4242\n",
      "      4        \u001B[36m1.0348\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m1.0454\u001B[0m  0.4243\n",
      "      5        \u001B[36m0.9363\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.9867\u001B[0m  0.4288\n",
      "      6        \u001B[36m0.8631\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.9455\u001B[0m  0.4236\n",
      "      7        \u001B[36m0.8031\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.9153\u001B[0m  0.4279\n",
      "      8        \u001B[36m0.7553\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.8926\u001B[0m  0.4252\n",
      "      9        \u001B[36m0.7035\u001B[0m       0.7603        \u001B[35m0.8728\u001B[0m  0.4251\n",
      "     10        \u001B[36m0.6715\u001B[0m       0.7669        \u001B[35m0.8533\u001B[0m  0.4295\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7579\u001B[0m       \u001B[32m0.5008\u001B[0m        \u001B[35m1.3957\u001B[0m  0.4338\n",
      "      2        \u001B[36m1.3163\u001B[0m       \u001B[32m0.5901\u001B[0m        \u001B[35m1.2075\u001B[0m  0.4253\n",
      "      3        \u001B[36m1.1487\u001B[0m       \u001B[32m0.6364\u001B[0m        \u001B[35m1.1024\u001B[0m  0.4260\n",
      "      4        \u001B[36m1.0212\u001B[0m       \u001B[32m0.6562\u001B[0m        \u001B[35m1.0186\u001B[0m  0.4254\n",
      "      5        \u001B[36m0.9333\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m0.9681\u001B[0m  0.4578\n",
      "      6        \u001B[36m0.8639\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m0.9093\u001B[0m  0.4565\n",
      "      7        \u001B[36m0.7802\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.8751\u001B[0m  0.4246\n",
      "      8        \u001B[36m0.7417\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.8567\u001B[0m  0.4354\n",
      "      9        \u001B[36m0.6977\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.8400\u001B[0m  0.4312\n",
      "     10        \u001B[36m0.6663\u001B[0m       0.7471        \u001B[35m0.8098\u001B[0m  0.4313\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7793\u001B[0m       \u001B[32m0.5355\u001B[0m        \u001B[35m1.3962\u001B[0m  0.4268\n",
      "      2        \u001B[36m1.3449\u001B[0m       \u001B[32m0.6116\u001B[0m        \u001B[35m1.1989\u001B[0m  0.4300\n",
      "      3        \u001B[36m1.1327\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0883\u001B[0m  0.4296\n",
      "      4        \u001B[36m1.0249\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m1.0102\u001B[0m  0.4278\n",
      "      5        \u001B[36m0.9418\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.9682\u001B[0m  0.4261\n",
      "      6        \u001B[36m0.8456\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.9327\u001B[0m  0.4982\n",
      "      7        \u001B[36m0.7906\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.8937\u001B[0m  0.4258\n",
      "      8        \u001B[36m0.7406\u001B[0m       0.7256        \u001B[35m0.8739\u001B[0m  0.4294\n",
      "      9        \u001B[36m0.6975\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.8538\u001B[0m  0.4280\n",
      "     10        \u001B[36m0.6614\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8236\u001B[0m  0.4352\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8558\u001B[0m       \u001B[32m0.4694\u001B[0m        \u001B[35m1.3505\u001B[0m  0.4718\n",
      "      2        \u001B[36m1.3884\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.1722\u001B[0m  0.4839\n",
      "      3        \u001B[36m1.1715\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.0769\u001B[0m  0.4734\n",
      "      4        \u001B[36m1.0176\u001B[0m       \u001B[32m0.7008\u001B[0m        \u001B[35m1.0066\u001B[0m  0.4378\n",
      "      5        \u001B[36m0.9570\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9456\u001B[0m  0.4914\n",
      "      6        \u001B[36m0.8513\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.9206\u001B[0m  0.4664\n",
      "      7        \u001B[36m0.7892\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.8883\u001B[0m  0.4578\n",
      "      8        \u001B[36m0.7457\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8644\u001B[0m  0.4536\n",
      "      9        \u001B[36m0.6894\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.8357\u001B[0m  0.4452\n",
      "     10        \u001B[36m0.6735\u001B[0m       0.7620        \u001B[35m0.8208\u001B[0m  0.4389\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7579\u001B[0m       \u001B[32m0.5322\u001B[0m        \u001B[35m1.3159\u001B[0m  0.4425\n",
      "      2        \u001B[36m1.2985\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.1296\u001B[0m  0.4632\n",
      "      3        \u001B[36m1.1172\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m1.0224\u001B[0m  0.4448\n",
      "      4        \u001B[36m1.0025\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.9627\u001B[0m  0.4533\n",
      "      5        \u001B[36m0.8821\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.9029\u001B[0m  0.4340\n",
      "      6        \u001B[36m0.8084\u001B[0m       0.7521        \u001B[35m0.8671\u001B[0m  0.4320\n",
      "      7        \u001B[36m0.7828\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.8274\u001B[0m  0.4417\n",
      "      8        \u001B[36m0.7007\u001B[0m       \u001B[32m0.7587\u001B[0m        \u001B[35m0.8050\u001B[0m  0.4423\n",
      "      9        \u001B[36m0.6729\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.7770\u001B[0m  0.4560\n",
      "     10        \u001B[36m0.6111\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7618\u001B[0m  0.4848\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7590\u001B[0m       \u001B[32m0.5405\u001B[0m        \u001B[35m1.2988\u001B[0m  0.4782\n",
      "      2        \u001B[36m1.2930\u001B[0m       \u001B[32m0.6364\u001B[0m        \u001B[35m1.1189\u001B[0m  0.4474\n",
      "      3        \u001B[36m1.1398\u001B[0m       \u001B[32m0.6777\u001B[0m        \u001B[35m1.0114\u001B[0m  0.4409\n",
      "      4        \u001B[36m0.9969\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9416\u001B[0m  0.4515\n",
      "      5        \u001B[36m0.8833\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.8928\u001B[0m  0.4423\n",
      "      6        \u001B[36m0.8277\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.8505\u001B[0m  0.4332\n",
      "      7        \u001B[36m0.7666\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.8186\u001B[0m  0.4379\n",
      "      8        \u001B[36m0.7117\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.7956\u001B[0m  0.4381\n",
      "      9        \u001B[36m0.6829\u001B[0m       0.7521        \u001B[35m0.7722\u001B[0m  0.4320\n",
      "     10        \u001B[36m0.6316\u001B[0m       0.7554        \u001B[35m0.7558\u001B[0m  0.4646\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9154\u001B[0m       \u001B[32m0.5669\u001B[0m        \u001B[35m1.2761\u001B[0m  0.4785\n",
      "      2        \u001B[36m1.3394\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.1086\u001B[0m  0.4422\n",
      "      3        \u001B[36m1.1345\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m1.0283\u001B[0m  0.4322\n",
      "      4        \u001B[36m0.9994\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.9645\u001B[0m  0.4400\n",
      "      5        \u001B[36m0.8866\u001B[0m       0.7306        \u001B[35m0.9201\u001B[0m  0.4567\n",
      "      6        \u001B[36m0.8401\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.8903\u001B[0m  0.4714\n",
      "      7        \u001B[36m0.7519\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.8636\u001B[0m  0.4771\n",
      "      8        \u001B[36m0.7089\u001B[0m       0.7223        \u001B[35m0.8581\u001B[0m  0.4277\n",
      "      9        \u001B[36m0.6735\u001B[0m       0.7421        \u001B[35m0.8309\u001B[0m  0.4334\n",
      "     10        \u001B[36m0.6522\u001B[0m       0.7372        \u001B[35m0.8157\u001B[0m  0.4314\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8306\u001B[0m       \u001B[32m0.5686\u001B[0m        \u001B[35m1.3229\u001B[0m  0.4339\n",
      "      2        \u001B[36m1.3479\u001B[0m       \u001B[32m0.6347\u001B[0m        \u001B[35m1.1404\u001B[0m  0.4332\n",
      "      3        \u001B[36m1.0987\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m1.0357\u001B[0m  0.4324\n",
      "      4        \u001B[36m0.9756\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.9812\u001B[0m  0.4747\n",
      "      5        \u001B[36m0.8736\u001B[0m       0.7091        \u001B[35m0.9423\u001B[0m  0.4572\n",
      "      6        \u001B[36m0.8194\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9092\u001B[0m  0.4391\n",
      "      7        \u001B[36m0.7677\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.8764\u001B[0m  0.4340\n",
      "      8        \u001B[36m0.6986\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8524\u001B[0m  0.4426\n",
      "      9        \u001B[36m0.6508\u001B[0m       0.7306        0.8525  0.4337\n",
      "     10        \u001B[36m0.6044\u001B[0m       0.7372        \u001B[35m0.8283\u001B[0m  0.4347\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8015\u001B[0m       \u001B[32m0.5603\u001B[0m        \u001B[35m1.3275\u001B[0m  0.4286\n",
      "      2        \u001B[36m1.3352\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1473\u001B[0m  0.4321\n",
      "      3        \u001B[36m1.1281\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m1.0434\u001B[0m  0.4358\n",
      "      4        \u001B[36m0.9929\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.9962\u001B[0m  0.4304\n",
      "      5        \u001B[36m0.8958\u001B[0m       0.7107        \u001B[35m0.9193\u001B[0m  0.4394\n",
      "      6        \u001B[36m0.8461\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.8955\u001B[0m  0.4269\n",
      "      7        \u001B[36m0.7862\u001B[0m       0.7174        \u001B[35m0.8657\u001B[0m  0.4422\n",
      "      8        \u001B[36m0.7103\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.8503\u001B[0m  0.4353\n",
      "      9        \u001B[36m0.6710\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8312\u001B[0m  0.4390\n",
      "     10        \u001B[36m0.6357\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8134\u001B[0m  0.4395\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2957\u001B[0m       \u001B[32m0.3388\u001B[0m        \u001B[35m1.7167\u001B[0m  0.4677\n",
      "      2        \u001B[36m1.8930\u001B[0m       \u001B[32m0.4545\u001B[0m        \u001B[35m1.5145\u001B[0m  0.4789\n",
      "      3        \u001B[36m1.7809\u001B[0m       \u001B[32m0.5058\u001B[0m        \u001B[35m1.4179\u001B[0m  0.4480\n",
      "      4        \u001B[36m1.6310\u001B[0m       \u001B[32m0.5355\u001B[0m        \u001B[35m1.3521\u001B[0m  0.4522\n",
      "      5        \u001B[36m1.5695\u001B[0m       \u001B[32m0.5620\u001B[0m        \u001B[35m1.3056\u001B[0m  0.4527\n",
      "      6        \u001B[36m1.4703\u001B[0m       \u001B[32m0.5884\u001B[0m        \u001B[35m1.2611\u001B[0m  0.4433\n",
      "      7        \u001B[36m1.4111\u001B[0m       \u001B[32m0.6116\u001B[0m        \u001B[35m1.2280\u001B[0m  0.4457\n",
      "      8        \u001B[36m1.3082\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1945\u001B[0m  0.4433\n",
      "      9        \u001B[36m1.2908\u001B[0m       \u001B[32m0.6364\u001B[0m        \u001B[35m1.1723\u001B[0m  0.4549\n",
      "     10        \u001B[36m1.2419\u001B[0m       \u001B[32m0.6397\u001B[0m        \u001B[35m1.1391\u001B[0m  0.4623\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2282\u001B[0m       \u001B[32m0.3702\u001B[0m        \u001B[35m1.7243\u001B[0m  0.4663\n",
      "      2        \u001B[36m1.9096\u001B[0m       \u001B[32m0.4298\u001B[0m        \u001B[35m1.5594\u001B[0m  0.4786\n",
      "      3        \u001B[36m1.7218\u001B[0m       \u001B[32m0.4612\u001B[0m        \u001B[35m1.4529\u001B[0m  0.4548\n",
      "      4        \u001B[36m1.6098\u001B[0m       \u001B[32m0.5124\u001B[0m        \u001B[35m1.3882\u001B[0m  0.4611\n",
      "      5        \u001B[36m1.5185\u001B[0m       \u001B[32m0.5372\u001B[0m        \u001B[35m1.3281\u001B[0m  0.4647\n",
      "      6        \u001B[36m1.4432\u001B[0m       \u001B[32m0.5537\u001B[0m        \u001B[35m1.2768\u001B[0m  0.4817\n",
      "      7        \u001B[36m1.3760\u001B[0m       \u001B[32m0.5785\u001B[0m        \u001B[35m1.2358\u001B[0m  0.4682\n",
      "      8        \u001B[36m1.3326\u001B[0m       \u001B[32m0.5917\u001B[0m        \u001B[35m1.2041\u001B[0m  0.4657\n",
      "      9        \u001B[36m1.2693\u001B[0m       \u001B[32m0.6182\u001B[0m        \u001B[35m1.1716\u001B[0m  0.4423\n",
      "     10        \u001B[36m1.2350\u001B[0m       \u001B[32m0.6264\u001B[0m        \u001B[35m1.1459\u001B[0m  0.4493\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4042\u001B[0m       \u001B[32m0.2975\u001B[0m        \u001B[35m1.8005\u001B[0m  0.4522\n",
      "      2        \u001B[36m1.9829\u001B[0m       \u001B[32m0.4149\u001B[0m        \u001B[35m1.6313\u001B[0m  0.4578\n",
      "      3        \u001B[36m1.7981\u001B[0m       \u001B[32m0.4860\u001B[0m        \u001B[35m1.5091\u001B[0m  0.4690\n",
      "      4        \u001B[36m1.6545\u001B[0m       \u001B[32m0.5207\u001B[0m        \u001B[35m1.4159\u001B[0m  0.5626\n",
      "      5        \u001B[36m1.6204\u001B[0m       \u001B[32m0.5504\u001B[0m        \u001B[35m1.3520\u001B[0m  0.4600\n",
      "      6        \u001B[36m1.5068\u001B[0m       \u001B[32m0.5636\u001B[0m        \u001B[35m1.2911\u001B[0m  0.4726\n",
      "      7        \u001B[36m1.4409\u001B[0m       \u001B[32m0.6000\u001B[0m        \u001B[35m1.2484\u001B[0m  0.4558\n",
      "      8        \u001B[36m1.3486\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.2155\u001B[0m  0.4591\n",
      "      9        \u001B[36m1.2872\u001B[0m       \u001B[32m0.6198\u001B[0m        \u001B[35m1.1802\u001B[0m  0.4588\n",
      "     10        \u001B[36m1.2465\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.1522\u001B[0m  0.4374\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2854\u001B[0m       \u001B[32m0.3455\u001B[0m        \u001B[35m1.6673\u001B[0m  0.4307\n",
      "      2        \u001B[36m1.8953\u001B[0m       \u001B[32m0.4231\u001B[0m        \u001B[35m1.5132\u001B[0m  0.4352\n",
      "      3        \u001B[36m1.8133\u001B[0m       \u001B[32m0.4876\u001B[0m        \u001B[35m1.4073\u001B[0m  0.4416\n",
      "      4        \u001B[36m1.6280\u001B[0m       \u001B[32m0.5140\u001B[0m        \u001B[35m1.3370\u001B[0m  0.4323\n",
      "      5        \u001B[36m1.5500\u001B[0m       \u001B[32m0.5537\u001B[0m        \u001B[35m1.2903\u001B[0m  0.5015\n",
      "      6        \u001B[36m1.4435\u001B[0m       \u001B[32m0.5868\u001B[0m        \u001B[35m1.2426\u001B[0m  0.4576\n",
      "      7        \u001B[36m1.3649\u001B[0m       \u001B[32m0.6099\u001B[0m        \u001B[35m1.2010\u001B[0m  0.4574\n",
      "      8        \u001B[36m1.3023\u001B[0m       \u001B[32m0.6198\u001B[0m        \u001B[35m1.1709\u001B[0m  0.4544\n",
      "      9        \u001B[36m1.2496\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1450\u001B[0m  0.4717\n",
      "     10        \u001B[36m1.1902\u001B[0m       \u001B[32m0.6512\u001B[0m        \u001B[35m1.1134\u001B[0m  0.4565\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3771\u001B[0m       \u001B[32m0.3603\u001B[0m        \u001B[35m1.6474\u001B[0m  0.4628\n",
      "      2        \u001B[36m1.8980\u001B[0m       \u001B[32m0.4331\u001B[0m        \u001B[35m1.4867\u001B[0m  0.4474\n",
      "      3        \u001B[36m1.7459\u001B[0m       \u001B[32m0.4893\u001B[0m        \u001B[35m1.3922\u001B[0m  0.4542\n",
      "      4        \u001B[36m1.6340\u001B[0m       \u001B[32m0.5273\u001B[0m        \u001B[35m1.3271\u001B[0m  0.4704\n",
      "      5        \u001B[36m1.5338\u001B[0m       \u001B[32m0.5769\u001B[0m        \u001B[35m1.2670\u001B[0m  0.4643\n",
      "      6        \u001B[36m1.4503\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.2269\u001B[0m  0.4661\n",
      "      7        \u001B[36m1.3927\u001B[0m       \u001B[32m0.6298\u001B[0m        \u001B[35m1.1906\u001B[0m  0.4575\n",
      "      8        \u001B[36m1.3293\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1616\u001B[0m  0.4544\n",
      "      9        \u001B[36m1.2498\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.1319\u001B[0m  0.4594\n",
      "     10        \u001B[36m1.2313\u001B[0m       \u001B[32m0.6661\u001B[0m        \u001B[35m1.1036\u001B[0m  0.4767\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2649\u001B[0m       \u001B[32m0.3802\u001B[0m        \u001B[35m1.6398\u001B[0m  0.4554\n",
      "      2        \u001B[36m1.9070\u001B[0m       \u001B[32m0.4562\u001B[0m        \u001B[35m1.4922\u001B[0m  0.4745\n",
      "      3        \u001B[36m1.7210\u001B[0m       \u001B[32m0.4876\u001B[0m        \u001B[35m1.3924\u001B[0m  0.4651\n",
      "      4        \u001B[36m1.5986\u001B[0m       \u001B[32m0.5306\u001B[0m        \u001B[35m1.3270\u001B[0m  0.4749\n",
      "      5        \u001B[36m1.4889\u001B[0m       \u001B[32m0.5537\u001B[0m        \u001B[35m1.2664\u001B[0m  0.4638\n",
      "      6        \u001B[36m1.4325\u001B[0m       \u001B[32m0.5835\u001B[0m        \u001B[35m1.2189\u001B[0m  0.4533\n",
      "      7        \u001B[36m1.3571\u001B[0m       \u001B[32m0.5983\u001B[0m        \u001B[35m1.1833\u001B[0m  0.4722\n",
      "      8        \u001B[36m1.3343\u001B[0m       \u001B[32m0.6198\u001B[0m        \u001B[35m1.1535\u001B[0m  0.4746\n",
      "      9        \u001B[36m1.2427\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1170\u001B[0m  0.4641\n",
      "     10        \u001B[36m1.1823\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.0843\u001B[0m  0.4497\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.5987\u001B[0m       \u001B[32m0.3653\u001B[0m        \u001B[35m1.5929\u001B[0m  0.4447\n",
      "      2        \u001B[36m1.9972\u001B[0m       \u001B[32m0.4727\u001B[0m        \u001B[35m1.4291\u001B[0m  0.4621\n",
      "      3        \u001B[36m1.8128\u001B[0m       \u001B[32m0.5025\u001B[0m        \u001B[35m1.3432\u001B[0m  0.4657\n",
      "      4        \u001B[36m1.7074\u001B[0m       \u001B[32m0.5669\u001B[0m        \u001B[35m1.2711\u001B[0m  0.4546\n",
      "      5        \u001B[36m1.5876\u001B[0m       \u001B[32m0.5802\u001B[0m        \u001B[35m1.2091\u001B[0m  0.4518\n",
      "      6        \u001B[36m1.4875\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.1735\u001B[0m  0.4515\n",
      "      7        \u001B[36m1.4196\u001B[0m       \u001B[32m0.6347\u001B[0m        \u001B[35m1.1526\u001B[0m  0.4448\n",
      "      8        \u001B[36m1.3581\u001B[0m       \u001B[32m0.6479\u001B[0m        \u001B[35m1.1226\u001B[0m  0.4771\n",
      "      9        1.3587       \u001B[32m0.6496\u001B[0m        \u001B[35m1.1010\u001B[0m  0.4764\n",
      "     10        \u001B[36m1.2683\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0543\u001B[0m  0.4382\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4356\u001B[0m       \u001B[32m0.4298\u001B[0m        \u001B[35m1.5619\u001B[0m  0.4368\n",
      "      2        \u001B[36m1.8993\u001B[0m       \u001B[32m0.5008\u001B[0m        \u001B[35m1.4094\u001B[0m  0.4612\n",
      "      3        \u001B[36m1.7185\u001B[0m       \u001B[32m0.5405\u001B[0m        \u001B[35m1.3121\u001B[0m  0.4541\n",
      "      4        \u001B[36m1.6089\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.2489\u001B[0m  0.4456\n",
      "      5        \u001B[36m1.4825\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.1919\u001B[0m  0.4621\n",
      "      6        \u001B[36m1.4281\u001B[0m       \u001B[32m0.6182\u001B[0m        \u001B[35m1.1623\u001B[0m  0.4495\n",
      "      7        \u001B[36m1.3582\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.1238\u001B[0m  0.4497\n",
      "      8        \u001B[36m1.2992\u001B[0m       0.6198        \u001B[35m1.0926\u001B[0m  0.4781\n",
      "      9        \u001B[36m1.2933\u001B[0m       \u001B[32m0.6430\u001B[0m        \u001B[35m1.0600\u001B[0m  0.4718\n",
      "     10        \u001B[36m1.1754\u001B[0m       0.6331        \u001B[35m1.0447\u001B[0m  0.4508\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2564\u001B[0m       \u001B[32m0.4413\u001B[0m        \u001B[35m1.5312\u001B[0m  0.4786\n",
      "      2        \u001B[36m1.8413\u001B[0m       \u001B[32m0.5174\u001B[0m        \u001B[35m1.3890\u001B[0m  0.4738\n",
      "      3        \u001B[36m1.6422\u001B[0m       \u001B[32m0.5636\u001B[0m        \u001B[35m1.2896\u001B[0m  0.5002\n",
      "      4        \u001B[36m1.5528\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.2094\u001B[0m  0.5148\n",
      "      5        \u001B[36m1.4158\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.1677\u001B[0m  0.4762\n",
      "      6        \u001B[36m1.3325\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.1330\u001B[0m  0.5260\n",
      "      7        \u001B[36m1.3089\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.0874\u001B[0m  0.4487\n",
      "      8        \u001B[36m1.2517\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0638\u001B[0m  0.4646\n",
      "      9        \u001B[36m1.1912\u001B[0m       \u001B[32m0.6678\u001B[0m        \u001B[35m1.0369\u001B[0m  0.4626\n",
      "     10        \u001B[36m1.1521\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0168\u001B[0m  0.4478\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2235\u001B[0m       \u001B[32m0.3669\u001B[0m        \u001B[35m1.6923\u001B[0m  0.4784\n",
      "      2        \u001B[36m1.7683\u001B[0m       \u001B[32m0.4612\u001B[0m        \u001B[35m1.4741\u001B[0m  0.4665\n",
      "      3        \u001B[36m1.5757\u001B[0m       \u001B[32m0.5190\u001B[0m        \u001B[35m1.3540\u001B[0m  0.4638\n",
      "      4        \u001B[36m1.4357\u001B[0m       \u001B[32m0.5570\u001B[0m        \u001B[35m1.2824\u001B[0m  0.4598\n",
      "      5        \u001B[36m1.3687\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.2226\u001B[0m  0.4560\n",
      "      6        \u001B[36m1.2527\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.1671\u001B[0m  0.5287\n",
      "      7        \u001B[36m1.1771\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.1353\u001B[0m  0.4804\n",
      "      8        \u001B[36m1.1179\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.1014\u001B[0m  0.4531\n",
      "      9        \u001B[36m1.0781\u001B[0m       \u001B[32m0.6744\u001B[0m        \u001B[35m1.0740\u001B[0m  0.4604\n",
      "     10        \u001B[36m1.0212\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m1.0468\u001B[0m  0.4536\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2128\u001B[0m       \u001B[32m0.4264\u001B[0m        \u001B[35m1.6279\u001B[0m  0.4409\n",
      "      2        \u001B[36m1.7409\u001B[0m       \u001B[32m0.5074\u001B[0m        \u001B[35m1.4448\u001B[0m  0.4489\n",
      "      3        \u001B[36m1.5795\u001B[0m       \u001B[32m0.5554\u001B[0m        \u001B[35m1.3460\u001B[0m  0.4631\n",
      "      4        \u001B[36m1.3895\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.2590\u001B[0m  0.4565\n",
      "      5        \u001B[36m1.3141\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.2019\u001B[0m  0.4682\n",
      "      6        \u001B[36m1.2242\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1579\u001B[0m  0.4976\n",
      "      7        \u001B[36m1.1572\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.1106\u001B[0m  0.4629\n",
      "      8        \u001B[36m1.1068\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.0796\u001B[0m  0.4678\n",
      "      9        \u001B[36m1.0580\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m1.0527\u001B[0m  0.4561\n",
      "     10        \u001B[36m0.9933\u001B[0m       \u001B[32m0.7008\u001B[0m        \u001B[35m1.0113\u001B[0m  0.4769\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1429\u001B[0m       \u001B[32m0.4314\u001B[0m        \u001B[35m1.6208\u001B[0m  0.4890\n",
      "      2        \u001B[36m1.7084\u001B[0m       \u001B[32m0.5157\u001B[0m        \u001B[35m1.3948\u001B[0m  0.5212\n",
      "      3        \u001B[36m1.5154\u001B[0m       \u001B[32m0.5752\u001B[0m        \u001B[35m1.2742\u001B[0m  0.5185\n",
      "      4        \u001B[36m1.3573\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.1953\u001B[0m  0.4869\n",
      "      5        \u001B[36m1.2762\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1332\u001B[0m  0.5109\n",
      "      6        \u001B[36m1.1402\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.0854\u001B[0m  0.5340\n",
      "      7        \u001B[36m1.1036\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0400\u001B[0m  0.4918\n",
      "      8        \u001B[36m1.0600\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m1.0036\u001B[0m  0.4412\n",
      "      9        \u001B[36m0.9832\u001B[0m       0.6893        \u001B[35m0.9674\u001B[0m  0.4351\n",
      "     10        0.9856       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9451\u001B[0m  0.4453\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   5.0s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1579\u001B[0m       \u001B[32m0.4331\u001B[0m        \u001B[35m1.4996\u001B[0m  0.4907\n",
      "      2        \u001B[36m1.6916\u001B[0m       \u001B[32m0.5240\u001B[0m        \u001B[35m1.3372\u001B[0m  0.5231\n",
      "      3        \u001B[36m1.5090\u001B[0m       \u001B[32m0.5917\u001B[0m        \u001B[35m1.2423\u001B[0m  0.4911\n",
      "      4        \u001B[36m1.4074\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.1791\u001B[0m  0.4758\n",
      "      5        \u001B[36m1.2692\u001B[0m       \u001B[32m0.6479\u001B[0m        \u001B[35m1.1273\u001B[0m  0.4583\n",
      "      6        \u001B[36m1.2225\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0847\u001B[0m  0.4593\n",
      "      7        \u001B[36m1.1332\u001B[0m       \u001B[32m0.6777\u001B[0m        \u001B[35m1.0481\u001B[0m  0.4772\n",
      "      8        \u001B[36m1.0810\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m1.0166\u001B[0m  0.4892\n",
      "      9        \u001B[36m1.0240\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9954\u001B[0m  0.4641\n",
      "     10        \u001B[36m1.0008\u001B[0m       0.7008        \u001B[35m0.9808\u001B[0m  0.4563\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1345\u001B[0m       \u001B[32m0.4397\u001B[0m        \u001B[35m1.5559\u001B[0m  0.4934\n",
      "      2        \u001B[36m1.7342\u001B[0m       \u001B[32m0.5174\u001B[0m        \u001B[35m1.3846\u001B[0m  0.4824\n",
      "      3        \u001B[36m1.4966\u001B[0m       \u001B[32m0.5785\u001B[0m        \u001B[35m1.2829\u001B[0m  0.4773\n",
      "      4        \u001B[36m1.3803\u001B[0m       \u001B[32m0.6017\u001B[0m        \u001B[35m1.2021\u001B[0m  0.4776\n",
      "      5        \u001B[36m1.2813\u001B[0m       \u001B[32m0.6545\u001B[0m        \u001B[35m1.1469\u001B[0m  0.4742\n",
      "      6        \u001B[36m1.2235\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.1069\u001B[0m  0.4947\n",
      "      7        \u001B[36m1.1097\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m1.0551\u001B[0m  0.4568\n",
      "      8        \u001B[36m1.0664\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m1.0278\u001B[0m  0.4608\n",
      "      9        \u001B[36m1.0103\u001B[0m       0.6926        \u001B[35m0.9949\u001B[0m  0.4540\n",
      "     10        \u001B[36m0.9616\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9710\u001B[0m  0.4510\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0332\u001B[0m       \u001B[32m0.4529\u001B[0m        \u001B[35m1.4785\u001B[0m  0.4610\n",
      "      2        \u001B[36m1.6914\u001B[0m       \u001B[32m0.5273\u001B[0m        \u001B[35m1.3055\u001B[0m  0.4957\n",
      "      3        \u001B[36m1.5069\u001B[0m       \u001B[32m0.5802\u001B[0m        \u001B[35m1.1976\u001B[0m  0.5140\n",
      "      4        \u001B[36m1.4023\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.1237\u001B[0m  0.4861\n",
      "      5        \u001B[36m1.2525\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.0692\u001B[0m  0.4638\n",
      "      6        \u001B[36m1.2003\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0254\u001B[0m  0.4522\n",
      "      7        \u001B[36m1.1091\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9871\u001B[0m  0.4447\n",
      "      8        \u001B[36m1.0510\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.9563\u001B[0m  0.4535\n",
      "      9        \u001B[36m0.9936\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.9322\u001B[0m  0.4566\n",
      "     10        1.0058       \u001B[32m0.7240\u001B[0m        \u001B[35m0.9076\u001B[0m  0.4514\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1775\u001B[0m       \u001B[32m0.4314\u001B[0m        \u001B[35m1.4464\u001B[0m  0.4826\n",
      "      2        \u001B[36m1.7146\u001B[0m       \u001B[32m0.5603\u001B[0m        \u001B[35m1.2901\u001B[0m  0.4506\n",
      "      3        \u001B[36m1.4853\u001B[0m       \u001B[32m0.6264\u001B[0m        \u001B[35m1.1956\u001B[0m  0.4319\n",
      "      4        \u001B[36m1.3847\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.1349\u001B[0m  0.4495\n",
      "      5        \u001B[36m1.2646\u001B[0m       0.6595        \u001B[35m1.0992\u001B[0m  0.4295\n",
      "      6        \u001B[36m1.1804\u001B[0m       0.6628        \u001B[35m1.0389\u001B[0m  0.4270\n",
      "      7        \u001B[36m1.0900\u001B[0m       0.6628        \u001B[35m1.0154\u001B[0m  0.4287\n",
      "      8        \u001B[36m1.0575\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m0.9927\u001B[0m  0.4278\n",
      "      9        \u001B[36m1.0192\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9541\u001B[0m  0.4402\n",
      "     10        \u001B[36m0.9671\u001B[0m       0.6975        \u001B[35m0.9490\u001B[0m  0.4891\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1801\u001B[0m       \u001B[32m0.4099\u001B[0m        \u001B[35m1.4894\u001B[0m  0.4334\n",
      "      2        \u001B[36m1.7688\u001B[0m       \u001B[32m0.5273\u001B[0m        \u001B[35m1.3094\u001B[0m  0.4747\n",
      "      3        \u001B[36m1.5506\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.2076\u001B[0m  0.4673\n",
      "      4        \u001B[36m1.3835\u001B[0m       \u001B[32m0.6198\u001B[0m        \u001B[35m1.1382\u001B[0m  0.4925\n",
      "      5        \u001B[36m1.2991\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.0770\u001B[0m  0.4597\n",
      "      6        \u001B[36m1.2375\u001B[0m       0.6595        \u001B[35m1.0534\u001B[0m  0.4496\n",
      "      7        \u001B[36m1.1512\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m1.0057\u001B[0m  0.4550\n",
      "      8        \u001B[36m1.0719\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m0.9839\u001B[0m  0.4586\n",
      "      9        \u001B[36m1.0369\u001B[0m       0.6876        \u001B[35m0.9710\u001B[0m  0.4737\n",
      "     10        \u001B[36m0.9856\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9329\u001B[0m  0.4716\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3353\u001B[0m       \u001B[32m0.4430\u001B[0m        \u001B[35m1.5618\u001B[0m  0.4778\n",
      "      2        \u001B[36m1.7774\u001B[0m       \u001B[32m0.5488\u001B[0m        \u001B[35m1.3302\u001B[0m  0.4747\n",
      "      3        \u001B[36m1.5475\u001B[0m       \u001B[32m0.5884\u001B[0m        \u001B[35m1.2198\u001B[0m  0.4546\n",
      "      4        \u001B[36m1.3836\u001B[0m       \u001B[32m0.6198\u001B[0m        \u001B[35m1.1351\u001B[0m  0.4571\n",
      "      5        \u001B[36m1.2888\u001B[0m       \u001B[32m0.6430\u001B[0m        \u001B[35m1.0770\u001B[0m  0.4554\n",
      "      6        \u001B[36m1.2089\u001B[0m       \u001B[32m0.6661\u001B[0m        \u001B[35m1.0424\u001B[0m  0.4866\n",
      "      7        \u001B[36m1.1256\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m0.9882\u001B[0m  0.4938\n",
      "      8        \u001B[36m1.0666\u001B[0m       0.6810        \u001B[35m0.9714\u001B[0m  0.4888\n",
      "      9        \u001B[36m1.0186\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m0.9414\u001B[0m  0.4797\n",
      "     10        \u001B[36m0.9819\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9081\u001B[0m  0.4405\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1068\u001B[0m       \u001B[32m0.5058\u001B[0m        \u001B[35m1.4173\u001B[0m  0.4793\n",
      "      2        \u001B[36m1.5110\u001B[0m       \u001B[32m0.6000\u001B[0m        \u001B[35m1.2153\u001B[0m  0.4443\n",
      "      3        \u001B[36m1.3229\u001B[0m       \u001B[32m0.6512\u001B[0m        \u001B[35m1.1158\u001B[0m  0.4331\n",
      "      4        \u001B[36m1.1779\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.0571\u001B[0m  0.4409\n",
      "      5        \u001B[36m1.0662\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m0.9993\u001B[0m  0.4312\n",
      "      6        \u001B[36m0.9811\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9515\u001B[0m  0.4325\n",
      "      7        \u001B[36m0.9296\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9277\u001B[0m  0.4314\n",
      "      8        \u001B[36m0.8716\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.8919\u001B[0m  0.4291\n",
      "      9        \u001B[36m0.8193\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8669\u001B[0m  0.4312\n",
      "     10        \u001B[36m0.7717\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8517\u001B[0m  0.4283\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0042\u001B[0m       \u001B[32m0.5157\u001B[0m        \u001B[35m1.4363\u001B[0m  0.4347\n",
      "      2        \u001B[36m1.5002\u001B[0m       \u001B[32m0.6066\u001B[0m        \u001B[35m1.2357\u001B[0m  0.4967\n",
      "      3        \u001B[36m1.2842\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.1244\u001B[0m  0.4371\n",
      "      4        \u001B[36m1.1366\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m1.0448\u001B[0m  0.4316\n",
      "      5        \u001B[36m1.0245\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9908\u001B[0m  0.4368\n",
      "      6        \u001B[36m0.9713\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.9411\u001B[0m  0.4402\n",
      "      7        \u001B[36m0.9044\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.9153\u001B[0m  0.4384\n",
      "      8        \u001B[36m0.8645\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.8859\u001B[0m  0.4352\n",
      "      9        \u001B[36m0.8092\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8541\u001B[0m  0.4471\n",
      "     10        \u001B[36m0.7558\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8347\u001B[0m  0.4353\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9081\u001B[0m       \u001B[32m0.5273\u001B[0m        \u001B[35m1.5308\u001B[0m  0.4355\n",
      "      2        \u001B[36m1.5018\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.3250\u001B[0m  0.4392\n",
      "      3        \u001B[36m1.3052\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.2162\u001B[0m  0.4598\n",
      "      4        \u001B[36m1.1344\u001B[0m       \u001B[32m0.6760\u001B[0m        \u001B[35m1.1264\u001B[0m  0.4706\n",
      "      5        \u001B[36m1.0540\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m1.0796\u001B[0m  0.4595\n",
      "      6        \u001B[36m0.9608\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m1.0298\u001B[0m  0.4474\n",
      "      7        \u001B[36m0.9033\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.9999\u001B[0m  0.4417\n",
      "      8        \u001B[36m0.8605\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.9638\u001B[0m  0.4290\n",
      "      9        \u001B[36m0.8027\u001B[0m       0.7388        \u001B[35m0.9443\u001B[0m  0.4332\n",
      "     10        \u001B[36m0.7449\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.9222\u001B[0m  0.4316\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0114\u001B[0m       \u001B[32m0.4926\u001B[0m        \u001B[35m1.3853\u001B[0m  0.4713\n",
      "      2        \u001B[36m1.5166\u001B[0m       \u001B[32m0.6017\u001B[0m        \u001B[35m1.2002\u001B[0m  0.4927\n",
      "      3        \u001B[36m1.2858\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.1063\u001B[0m  0.4755\n",
      "      4        \u001B[36m1.1869\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m1.0404\u001B[0m  0.4564\n",
      "      5        \u001B[36m1.0446\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m1.0005\u001B[0m  0.4559\n",
      "      6        \u001B[36m0.9764\u001B[0m       0.7240        \u001B[35m0.9582\u001B[0m  0.4383\n",
      "      7        \u001B[36m0.9040\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.9312\u001B[0m  0.4384\n",
      "      8        \u001B[36m0.8681\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.9067\u001B[0m  0.4572\n",
      "      9        \u001B[36m0.8145\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.8740\u001B[0m  0.4383\n",
      "     10        \u001B[36m0.7629\u001B[0m       0.7521        \u001B[35m0.8574\u001B[0m  0.5091\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0341\u001B[0m       \u001B[32m0.4843\u001B[0m        \u001B[35m1.4572\u001B[0m  0.4567\n",
      "      2        \u001B[36m1.5134\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.2654\u001B[0m  0.4498\n",
      "      3        \u001B[36m1.3134\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.1498\u001B[0m  0.4439\n",
      "      4        \u001B[36m1.1568\u001B[0m       \u001B[32m0.6760\u001B[0m        \u001B[35m1.0736\u001B[0m  0.4407\n",
      "      5        \u001B[36m1.0586\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m1.0011\u001B[0m  0.4662\n",
      "      6        \u001B[36m0.9584\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.9682\u001B[0m  0.4864\n",
      "      7        \u001B[36m0.8866\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.9310\u001B[0m  0.5107\n",
      "      8        \u001B[36m0.8658\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.9003\u001B[0m  0.4633\n",
      "      9        \u001B[36m0.8065\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8793\u001B[0m  0.4668\n",
      "     10        \u001B[36m0.7711\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8566\u001B[0m  0.4478\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9309\u001B[0m       \u001B[32m0.5025\u001B[0m        \u001B[35m1.3832\u001B[0m  0.4363\n",
      "      2        \u001B[36m1.4484\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.1941\u001B[0m  0.4438\n",
      "      3        \u001B[36m1.2670\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.0891\u001B[0m  0.4384\n",
      "      4        \u001B[36m1.1125\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0145\u001B[0m  0.4386\n",
      "      5        \u001B[36m1.0454\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m0.9711\u001B[0m  0.5019\n",
      "      6        \u001B[36m0.9628\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9200\u001B[0m  0.4495\n",
      "      7        \u001B[36m0.8959\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.8895\u001B[0m  0.4480\n",
      "      8        \u001B[36m0.8359\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.8586\u001B[0m  0.4378\n",
      "      9        \u001B[36m0.7915\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8383\u001B[0m  0.4479\n",
      "     10        \u001B[36m0.7604\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.8276\u001B[0m  0.4462\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9338\u001B[0m       \u001B[32m0.5455\u001B[0m        \u001B[35m1.3255\u001B[0m  0.4437\n",
      "      2        \u001B[36m1.4769\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.1444\u001B[0m  0.4519\n",
      "      3        \u001B[36m1.2376\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0697\u001B[0m  0.4648\n",
      "      4        \u001B[36m1.0821\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m1.0100\u001B[0m  0.4420\n",
      "      5        \u001B[36m1.0459\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9611\u001B[0m  0.4585\n",
      "      6        \u001B[36m0.9344\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9206\u001B[0m  0.4785\n",
      "      7        \u001B[36m0.8962\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.8918\u001B[0m  0.4806\n",
      "      8        \u001B[36m0.8190\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.8626\u001B[0m  0.4726\n",
      "      9        \u001B[36m0.7871\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.8439\u001B[0m  0.4352\n",
      "     10        \u001B[36m0.7505\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8363\u001B[0m  0.4367\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9469\u001B[0m       \u001B[32m0.5074\u001B[0m        \u001B[35m1.3485\u001B[0m  0.4312\n",
      "      2        \u001B[36m1.4332\u001B[0m       \u001B[32m0.5983\u001B[0m        \u001B[35m1.1920\u001B[0m  0.4328\n",
      "      3        \u001B[36m1.2787\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.1024\u001B[0m  0.4341\n",
      "      4        \u001B[36m1.1239\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0390\u001B[0m  0.4360\n",
      "      5        \u001B[36m1.0180\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m0.9868\u001B[0m  0.4339\n",
      "      6        \u001B[36m0.9356\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m0.9395\u001B[0m  0.4341\n",
      "      7        \u001B[36m0.8793\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9182\u001B[0m  0.4346\n",
      "      8        \u001B[36m0.8247\u001B[0m       0.7058        \u001B[35m0.8953\u001B[0m  0.4341\n",
      "      9        \u001B[36m0.7612\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.8610\u001B[0m  0.5031\n",
      "     10        \u001B[36m0.7472\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8568\u001B[0m  0.4311\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0342\u001B[0m       \u001B[32m0.4959\u001B[0m        \u001B[35m1.3144\u001B[0m  0.4407\n",
      "      2        \u001B[36m1.5221\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.1326\u001B[0m  0.4343\n",
      "      3        \u001B[36m1.2737\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0234\u001B[0m  0.4415\n",
      "      4        \u001B[36m1.1253\u001B[0m       \u001B[32m0.7008\u001B[0m        \u001B[35m0.9609\u001B[0m  0.4414\n",
      "      5        \u001B[36m1.0344\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.9243\u001B[0m  0.4464\n",
      "      6        \u001B[36m0.9329\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.8911\u001B[0m  0.4368\n",
      "      7        \u001B[36m0.8959\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8535\u001B[0m  0.4434\n",
      "      8        \u001B[36m0.8391\u001B[0m       0.7306        \u001B[35m0.8358\u001B[0m  0.4645\n",
      "      9        \u001B[36m0.7887\u001B[0m       0.7405        \u001B[35m0.8189\u001B[0m  0.4555\n",
      "     10        \u001B[36m0.7447\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.8061\u001B[0m  0.4311\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7234\u001B[0m       \u001B[32m0.6017\u001B[0m        \u001B[35m1.1728\u001B[0m  0.4198\n",
      "      2        \u001B[36m1.1434\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m0.9416\u001B[0m  0.2339\n",
      "      3        \u001B[36m0.9167\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.8480\u001B[0m  0.2309\n",
      "      4        \u001B[36m0.7916\u001B[0m       \u001B[32m0.7587\u001B[0m        \u001B[35m0.7707\u001B[0m  0.2267\n",
      "      5        \u001B[36m0.6946\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7394\u001B[0m  0.2295\n",
      "      6        \u001B[36m0.6305\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.7084\u001B[0m  0.2289\n",
      "      7        \u001B[36m0.5983\u001B[0m       0.7901        0.7108  0.2292\n",
      "      8        \u001B[36m0.5358\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.6876\u001B[0m  0.2298\n",
      "      9        \u001B[36m0.5032\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6859\u001B[0m  0.2277\n",
      "     10        \u001B[36m0.4708\u001B[0m       \u001B[32m0.8116\u001B[0m        \u001B[35m0.6819\u001B[0m  0.2314\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5570\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1563\u001B[0m  0.3559\n",
      "      2        \u001B[36m1.0558\u001B[0m       \u001B[32m0.6810\u001B[0m        \u001B[35m0.9590\u001B[0m  0.2257\n",
      "      3        \u001B[36m0.8712\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.8606\u001B[0m  0.2297\n",
      "      4        \u001B[36m0.7545\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7927\u001B[0m  0.2631\n",
      "      5        \u001B[36m0.6817\u001B[0m       0.7669        \u001B[35m0.7761\u001B[0m  0.2555\n",
      "      6        \u001B[36m0.5978\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7082\u001B[0m  0.2408\n",
      "      7        \u001B[36m0.5623\u001B[0m       0.7967        \u001B[35m0.6855\u001B[0m  0.2453\n",
      "      8        \u001B[36m0.5105\u001B[0m       0.7967        \u001B[35m0.6736\u001B[0m  0.2538\n",
      "      9        \u001B[36m0.4799\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.6496\u001B[0m  0.2424\n",
      "     10        \u001B[36m0.4541\u001B[0m       \u001B[32m0.8182\u001B[0m        \u001B[35m0.6403\u001B[0m  0.2401\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6631\u001B[0m       \u001B[32m0.6050\u001B[0m        \u001B[35m1.1897\u001B[0m  0.2460\n",
      "      2        \u001B[36m1.1236\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m0.9754\u001B[0m  0.2446\n",
      "      3        \u001B[36m0.8977\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.8707\u001B[0m  0.2323\n",
      "      4        \u001B[36m0.7748\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.7958\u001B[0m  0.2456\n",
      "      5        \u001B[36m0.6808\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7574\u001B[0m  0.2563\n",
      "      6        \u001B[36m0.6318\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7161\u001B[0m  0.2508\n",
      "      7        \u001B[36m0.5555\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6913\u001B[0m  0.2271\n",
      "      8        \u001B[36m0.5262\u001B[0m       0.7901        \u001B[35m0.6798\u001B[0m  0.2365\n",
      "      9        \u001B[36m0.4777\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.6486\u001B[0m  0.2428\n",
      "     10        \u001B[36m0.4430\u001B[0m       \u001B[32m0.8017\u001B[0m        0.6701  0.2299\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7209\u001B[0m       \u001B[32m0.6264\u001B[0m        \u001B[35m1.1431\u001B[0m  0.2503\n",
      "      2        \u001B[36m1.0674\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.9025\u001B[0m  0.2202\n",
      "      3        \u001B[36m0.9177\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8086\u001B[0m  0.2232\n",
      "      4        \u001B[36m0.7866\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7564\u001B[0m  0.2255\n",
      "      5        \u001B[36m0.7005\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.7272\u001B[0m  0.2212\n",
      "      6        \u001B[36m0.6379\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.6955\u001B[0m  0.2232\n",
      "      7        \u001B[36m0.5592\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6722\u001B[0m  0.2206\n",
      "      8        \u001B[36m0.5304\u001B[0m       0.7967        0.6890  0.2226\n",
      "      9        \u001B[36m0.4761\u001B[0m       0.7950        \u001B[35m0.6690\u001B[0m  0.2225\n",
      "     10        \u001B[36m0.4632\u001B[0m       \u001B[32m0.8165\u001B[0m        \u001B[35m0.6447\u001B[0m  0.2215\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6423\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.0803\u001B[0m  0.2334\n",
      "      2        \u001B[36m1.0943\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.8814\u001B[0m  0.2361\n",
      "      3        \u001B[36m0.8962\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.8051\u001B[0m  0.2266\n",
      "      4        \u001B[36m0.7774\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7654\u001B[0m  0.2276\n",
      "      5        \u001B[36m0.6997\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7342\u001B[0m  0.2639\n",
      "      6        \u001B[36m0.6200\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.6962\u001B[0m  0.2734\n",
      "      7        \u001B[36m0.5714\u001B[0m       0.7884        \u001B[35m0.6903\u001B[0m  0.2265\n",
      "      8        \u001B[36m0.5263\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6597\u001B[0m  0.2646\n",
      "      9        \u001B[36m0.4823\u001B[0m       0.7950        \u001B[35m0.6563\u001B[0m  0.2464\n",
      "     10        \u001B[36m0.4562\u001B[0m       0.7967        \u001B[35m0.6493\u001B[0m  0.2607\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6204\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.1402\u001B[0m  0.2293\n",
      "      2        \u001B[36m1.0541\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.9398\u001B[0m  0.2233\n",
      "      3        \u001B[36m0.8676\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8502\u001B[0m  0.2293\n",
      "      4        \u001B[36m0.7319\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7846\u001B[0m  0.2348\n",
      "      5        \u001B[36m0.6799\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7571\u001B[0m  0.2247\n",
      "      6        \u001B[36m0.5819\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.7161\u001B[0m  0.2332\n",
      "      7        \u001B[36m0.5224\u001B[0m       0.7851        0.7276  0.2202\n",
      "      8        \u001B[36m0.5026\u001B[0m       0.7917        0.7214  0.2370\n",
      "      9        \u001B[36m0.4396\u001B[0m       0.7884        \u001B[35m0.7146\u001B[0m  0.2212\n",
      "     10        \u001B[36m0.4166\u001B[0m       \u001B[32m0.8050\u001B[0m        0.7301  0.2269\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6353\u001B[0m       \u001B[32m0.6760\u001B[0m        \u001B[35m0.9891\u001B[0m  0.3460\n",
      "      2        \u001B[36m1.0048\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8375\u001B[0m  0.2310\n",
      "      3        \u001B[36m0.8611\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.7763\u001B[0m  0.2188\n",
      "      4        \u001B[36m0.7515\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.6935\u001B[0m  0.2205\n",
      "      5        \u001B[36m0.6621\u001B[0m       0.7636        0.7056  0.2297\n",
      "      6        \u001B[36m0.6065\u001B[0m       0.7587        0.6976  0.2234\n",
      "      7        \u001B[36m0.5470\u001B[0m       0.7702        \u001B[35m0.6798\u001B[0m  0.2175\n",
      "      8        \u001B[36m0.5087\u001B[0m       0.7818        0.6815  0.2219\n",
      "      9        \u001B[36m0.4663\u001B[0m       0.7851        \u001B[35m0.6796\u001B[0m  0.2215\n",
      "     10        \u001B[36m0.4627\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.6651\u001B[0m  0.2180\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6261\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.0810\u001B[0m  0.2745\n",
      "      2        \u001B[36m1.1039\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.9216\u001B[0m  0.2278\n",
      "      3        \u001B[36m0.8957\u001B[0m       \u001B[32m0.7587\u001B[0m        \u001B[35m0.8302\u001B[0m  0.2298\n",
      "      4        \u001B[36m0.7576\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.7973\u001B[0m  0.2337\n",
      "      5        \u001B[36m0.6957\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7525\u001B[0m  0.2298\n",
      "      6        \u001B[36m0.6321\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7055\u001B[0m  0.2280\n",
      "      7        \u001B[36m0.5921\u001B[0m       0.7802        0.7117  0.2521\n",
      "      8        \u001B[36m0.5207\u001B[0m       0.7769        0.7385  0.2504\n",
      "      9        \u001B[36m0.4823\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6943\u001B[0m  0.2448\n",
      "     10        \u001B[36m0.4471\u001B[0m       \u001B[32m0.8000\u001B[0m        0.7016  0.2630\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6572\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0703\u001B[0m  0.2435\n",
      "      2        \u001B[36m1.0758\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8220\u001B[0m  0.2350\n",
      "      3        \u001B[36m0.8612\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.7691\u001B[0m  0.2390\n",
      "      4        \u001B[36m0.7551\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7165\u001B[0m  0.2435\n",
      "      5        \u001B[36m0.6892\u001B[0m       0.7719        \u001B[35m0.7053\u001B[0m  0.2513\n",
      "      6        \u001B[36m0.6126\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6751\u001B[0m  0.2339\n",
      "      7        \u001B[36m0.5402\u001B[0m       0.7901        0.6847  0.2184\n",
      "      8        \u001B[36m0.4868\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.6424\u001B[0m  0.2359\n",
      "      9        \u001B[36m0.4584\u001B[0m       0.7934        \u001B[35m0.6371\u001B[0m  0.2439\n",
      "     10        \u001B[36m0.4370\u001B[0m       0.7967        0.6439  0.2173\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4755\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m1.0113\u001B[0m  0.3425\n",
      "      2        \u001B[36m0.8883\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.7943\u001B[0m  0.2342\n",
      "      3        \u001B[36m0.7214\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7322\u001B[0m  0.2411\n",
      "      4        \u001B[36m0.5962\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6766\u001B[0m  0.2300\n",
      "      5        \u001B[36m0.5133\u001B[0m       \u001B[32m0.8132\u001B[0m        \u001B[35m0.6462\u001B[0m  0.2303\n",
      "      6        \u001B[36m0.4800\u001B[0m       \u001B[32m0.8149\u001B[0m        0.6540  0.2540\n",
      "      7        \u001B[36m0.4262\u001B[0m       0.8050        0.6819  0.2282\n",
      "      8        \u001B[36m0.3749\u001B[0m       0.8017        0.6942  0.2283\n",
      "      9        \u001B[36m0.3542\u001B[0m       0.8099        0.6706  0.2318\n",
      "     10        \u001B[36m0.3048\u001B[0m       0.8099        0.7075  0.2286\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4625\u001B[0m       \u001B[32m0.6777\u001B[0m        \u001B[35m1.0165\u001B[0m  0.2952\n",
      "      2        \u001B[36m0.9014\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8055\u001B[0m  0.2553\n",
      "      3        \u001B[36m0.7048\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7308\u001B[0m  0.2463\n",
      "      4        \u001B[36m0.6070\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.6865\u001B[0m  0.2536\n",
      "      5        \u001B[36m0.5254\u001B[0m       \u001B[32m0.8132\u001B[0m        \u001B[35m0.6598\u001B[0m  0.2632\n",
      "      6        \u001B[36m0.4775\u001B[0m       0.8116        \u001B[35m0.6400\u001B[0m  0.2358\n",
      "      7        \u001B[36m0.4312\u001B[0m       \u001B[32m0.8347\u001B[0m        \u001B[35m0.6192\u001B[0m  0.2322\n",
      "      8        \u001B[36m0.3830\u001B[0m       0.8198        \u001B[35m0.6175\u001B[0m  0.2452\n",
      "      9        \u001B[36m0.3526\u001B[0m       0.8132        0.6245  0.2608\n",
      "     10        \u001B[36m0.3366\u001B[0m       0.8331        \u001B[35m0.5973\u001B[0m  0.2497\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5105\u001B[0m       \u001B[32m0.6430\u001B[0m        \u001B[35m1.0347\u001B[0m  0.2311\n",
      "      2        \u001B[36m0.9215\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.8413\u001B[0m  0.2287\n",
      "      3        \u001B[36m0.7151\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7453\u001B[0m  0.2296\n",
      "      4        \u001B[36m0.6023\u001B[0m       0.7702        \u001B[35m0.7329\u001B[0m  0.2302\n",
      "      5        \u001B[36m0.5294\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.7180\u001B[0m  0.2301\n",
      "      6        \u001B[36m0.4558\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.7005\u001B[0m  0.2454\n",
      "      7        \u001B[36m0.4071\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.6801\u001B[0m  0.2486\n",
      "      8        \u001B[36m0.3743\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6643\u001B[0m  0.2317\n",
      "      9        \u001B[36m0.3380\u001B[0m       0.7868        0.7005  0.2299\n",
      "     10        \u001B[36m0.2969\u001B[0m       0.7901        0.7015  0.2326\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3910\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9283\u001B[0m  0.2259\n",
      "      2        \u001B[36m0.8500\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.7807\u001B[0m  0.2258\n",
      "      3        \u001B[36m0.6965\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.7111\u001B[0m  0.2244\n",
      "      4        \u001B[36m0.5908\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.6757\u001B[0m  0.2251\n",
      "      5        \u001B[36m0.5019\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.6516\u001B[0m  0.2229\n",
      "      6        \u001B[36m0.4456\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6422\u001B[0m  0.2256\n",
      "      7        \u001B[36m0.4049\u001B[0m       \u001B[32m0.8116\u001B[0m        \u001B[35m0.6338\u001B[0m  0.2268\n",
      "      8        \u001B[36m0.3703\u001B[0m       0.8050        0.6481  0.2257\n",
      "      9        \u001B[36m0.3103\u001B[0m       0.8000        0.6829  0.2267\n",
      "     10        \u001B[36m0.2891\u001B[0m       0.8017        0.7162  0.2244\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4492\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m0.9556\u001B[0m  0.2267\n",
      "      2        \u001B[36m0.8691\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.7737\u001B[0m  0.2258\n",
      "      3        \u001B[36m0.7051\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.7075\u001B[0m  0.2252\n",
      "      4        \u001B[36m0.6122\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.6670\u001B[0m  0.2245\n",
      "      5        \u001B[36m0.5109\u001B[0m       0.7901        \u001B[35m0.6632\u001B[0m  0.2277\n",
      "      6        \u001B[36m0.4619\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.6299\u001B[0m  0.2385\n",
      "      7        \u001B[36m0.4007\u001B[0m       0.7983        0.6498  0.2310\n",
      "      8        \u001B[36m0.3765\u001B[0m       0.8000        0.6627  0.2277\n",
      "      9        \u001B[36m0.3226\u001B[0m       \u001B[32m0.8116\u001B[0m        0.6780  0.2253\n",
      "     10        \u001B[36m0.3070\u001B[0m       0.8033        0.6604  0.2247\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4311\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0109\u001B[0m  0.2270\n",
      "      2        \u001B[36m0.9109\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.8894\u001B[0m  0.2279\n",
      "      3        \u001B[36m0.7258\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.8003\u001B[0m  0.2322\n",
      "      4        \u001B[36m0.5835\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7516\u001B[0m  0.2220\n",
      "      5        \u001B[36m0.5022\u001B[0m       0.7950        \u001B[35m0.7127\u001B[0m  0.2224\n",
      "      6        \u001B[36m0.4583\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.7111\u001B[0m  0.2270\n",
      "      7        \u001B[36m0.4036\u001B[0m       0.7983        \u001B[35m0.6684\u001B[0m  0.2332\n",
      "      8        \u001B[36m0.3761\u001B[0m       0.8000        0.7286  0.2395\n",
      "      9        \u001B[36m0.3096\u001B[0m       0.8066        0.7355  0.2369\n",
      "     10        \u001B[36m0.2836\u001B[0m       0.8017        0.7283  0.2398\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4990\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9815\u001B[0m  0.2576\n",
      "      2        \u001B[36m0.8849\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.8285\u001B[0m  0.2139\n",
      "      3        \u001B[36m0.7243\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7539\u001B[0m  0.2125\n",
      "      4        \u001B[36m0.6162\u001B[0m       0.7653        \u001B[35m0.7461\u001B[0m  0.2162\n",
      "      5        \u001B[36m0.5475\u001B[0m       \u001B[32m0.7719\u001B[0m        0.7508  0.2121\n",
      "      6        \u001B[36m0.4363\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7348\u001B[0m  0.2156\n",
      "      7        0.4402       0.7587        0.7630  0.2142\n",
      "      8        \u001B[36m0.3641\u001B[0m       0.7785        0.7582  0.2125\n",
      "      9        \u001B[36m0.3352\u001B[0m       \u001B[32m0.7851\u001B[0m        0.7552  0.2129\n",
      "     10        \u001B[36m0.3198\u001B[0m       \u001B[32m0.8066\u001B[0m        0.7771  0.2122\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5128\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m0.9628\u001B[0m  0.2258\n",
      "      2        \u001B[36m0.8749\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.8084\u001B[0m  0.2169\n",
      "      3        \u001B[36m0.7225\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.7256\u001B[0m  0.2160\n",
      "      4        \u001B[36m0.6286\u001B[0m       0.7802        0.7529  0.2162\n",
      "      5        \u001B[36m0.5495\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.7088\u001B[0m  0.2175\n",
      "      6        \u001B[36m0.4628\u001B[0m       0.8017        0.7195  0.2172\n",
      "      7        \u001B[36m0.4146\u001B[0m       0.8017        0.7300  0.2169\n",
      "      8        \u001B[36m0.4049\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.7012\u001B[0m  0.2168\n",
      "      9        \u001B[36m0.3541\u001B[0m       \u001B[32m0.8116\u001B[0m        0.7538  0.2164\n",
      "     10        \u001B[36m0.2971\u001B[0m       \u001B[32m0.8132\u001B[0m        0.7144  0.2154\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4925\u001B[0m       \u001B[32m0.6727\u001B[0m        \u001B[35m1.0075\u001B[0m  0.2224\n",
      "      2        \u001B[36m0.8706\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.8372\u001B[0m  0.2208\n",
      "      3        \u001B[36m0.7024\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.7581\u001B[0m  0.2212\n",
      "      4        \u001B[36m0.5815\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7157\u001B[0m  0.2201\n",
      "      5        \u001B[36m0.4976\u001B[0m       0.7719        0.7302  0.2188\n",
      "      6        \u001B[36m0.4377\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6898\u001B[0m  0.2210\n",
      "      7        \u001B[36m0.4137\u001B[0m       \u001B[32m0.7950\u001B[0m        0.7216  0.2203\n",
      "      8        \u001B[36m0.3531\u001B[0m       0.7950        0.7184  0.2200\n",
      "      9        \u001B[36m0.3396\u001B[0m       \u001B[32m0.8033\u001B[0m        0.7149  0.2199\n",
      "     10        \u001B[36m0.2996\u001B[0m       0.7884        0.7696  0.2198\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3242\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.8927\u001B[0m  0.3022\n",
      "      2        \u001B[36m0.7282\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.7548\u001B[0m  0.2143\n",
      "      3        \u001B[36m0.5786\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.7192\u001B[0m  0.2169\n",
      "      4        \u001B[36m0.4672\u001B[0m       \u001B[32m0.8116\u001B[0m        0.7295  0.2187\n",
      "      5        \u001B[36m0.4242\u001B[0m       \u001B[32m0.8149\u001B[0m        \u001B[35m0.6904\u001B[0m  0.2187\n",
      "      6        \u001B[36m0.3629\u001B[0m       \u001B[32m0.8165\u001B[0m        0.7115  0.2161\n",
      "      7        \u001B[36m0.3085\u001B[0m       0.8116        0.7447  0.2167\n",
      "      8        \u001B[36m0.2615\u001B[0m       \u001B[32m0.8264\u001B[0m        0.7230  0.2248\n",
      "      9        \u001B[36m0.2403\u001B[0m       0.8215        0.7892  0.2178\n",
      "     10        \u001B[36m0.2083\u001B[0m       0.8099        0.8248  0.2145\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3633\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9257\u001B[0m  0.2955\n",
      "      2        \u001B[36m0.7296\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7520\u001B[0m  0.2139\n",
      "      3        \u001B[36m0.5571\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6989\u001B[0m  0.2136\n",
      "      4        \u001B[36m0.4776\u001B[0m       \u001B[32m0.8182\u001B[0m        \u001B[35m0.6540\u001B[0m  0.2142\n",
      "      5        \u001B[36m0.4088\u001B[0m       0.8000        0.7146  0.2139\n",
      "      6        \u001B[36m0.3459\u001B[0m       \u001B[32m0.8264\u001B[0m        0.6861  0.2141\n",
      "      7        \u001B[36m0.3081\u001B[0m       0.8264        0.6598  0.2138\n",
      "      8        \u001B[36m0.2746\u001B[0m       0.8198        0.7222  0.2141\n",
      "      9        \u001B[36m0.2376\u001B[0m       0.8198        0.7732  0.2147\n",
      "     10        \u001B[36m0.2227\u001B[0m       0.8099        0.7170  0.2161\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3007\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m0.9181\u001B[0m  0.2155\n",
      "      2        \u001B[36m0.7022\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7978\u001B[0m  0.2180\n",
      "      3        \u001B[36m0.5563\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7265\u001B[0m  0.2149\n",
      "      4        \u001B[36m0.4456\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6959\u001B[0m  0.2152\n",
      "      5        \u001B[36m0.3814\u001B[0m       0.7934        \u001B[35m0.6885\u001B[0m  0.2142\n",
      "      6        \u001B[36m0.3068\u001B[0m       0.7802        0.7254  0.2144\n",
      "      7        \u001B[36m0.2648\u001B[0m       0.8050        0.7117  0.2148\n",
      "      8        \u001B[36m0.2423\u001B[0m       0.8017        0.7445  0.2137\n",
      "      9        \u001B[36m0.2127\u001B[0m       0.7802        0.7797  0.2147\n",
      "     10        \u001B[36m0.1817\u001B[0m       0.7967        0.7667  0.2155\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3602\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.8614\u001B[0m  0.2669\n",
      "      2        \u001B[36m0.7294\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7801\u001B[0m  0.2169\n",
      "      3        \u001B[36m0.5790\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7331\u001B[0m  0.2195\n",
      "      4        \u001B[36m0.4708\u001B[0m       0.7702        0.7466  0.2172\n",
      "      5        \u001B[36m0.3876\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7106\u001B[0m  0.2180\n",
      "      6        \u001B[36m0.3416\u001B[0m       0.7884        0.7208  0.2309\n",
      "      7        \u001B[36m0.3016\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6954\u001B[0m  0.2353\n",
      "      8        \u001B[36m0.2653\u001B[0m       0.8000        0.7446  0.2365\n",
      "      9        0.2674       \u001B[32m0.8116\u001B[0m        0.7603  0.2303\n",
      "     10        \u001B[36m0.2236\u001B[0m       0.8116        0.7455  0.2390\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3792\u001B[0m       \u001B[32m0.6777\u001B[0m        \u001B[35m0.9173\u001B[0m  0.2485\n",
      "      2        \u001B[36m0.7720\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.7641\u001B[0m  0.2213\n",
      "      3        \u001B[36m0.5675\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.7000\u001B[0m  0.2171\n",
      "      4        \u001B[36m0.4787\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.6928\u001B[0m  0.2165\n",
      "      5        \u001B[36m0.4150\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6786\u001B[0m  0.2172\n",
      "      6        \u001B[36m0.3463\u001B[0m       0.8017        0.7201  0.2170\n",
      "      7        \u001B[36m0.3134\u001B[0m       0.7950        0.7166  0.2171\n",
      "      8        \u001B[36m0.2517\u001B[0m       \u001B[32m0.8182\u001B[0m        0.7023  0.2147\n",
      "      9        \u001B[36m0.2402\u001B[0m       0.8116        0.7281  0.2155\n",
      "     10        \u001B[36m0.1907\u001B[0m       0.8099        0.7570  0.2171\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3338\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m0.9137\u001B[0m  0.2181\n",
      "      2        \u001B[36m0.7265\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.8123\u001B[0m  0.2190\n",
      "      3        \u001B[36m0.5379\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.7416\u001B[0m  0.2183\n",
      "      4        \u001B[36m0.4499\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.7394\u001B[0m  0.2165\n",
      "      5        \u001B[36m0.3885\u001B[0m       0.7934        \u001B[35m0.7344\u001B[0m  0.2200\n",
      "      6        \u001B[36m0.3237\u001B[0m       0.7934        \u001B[35m0.7246\u001B[0m  0.2186\n",
      "      7        \u001B[36m0.2701\u001B[0m       0.7950        0.7396  0.2179\n",
      "      8        \u001B[36m0.2271\u001B[0m       \u001B[32m0.8066\u001B[0m        0.7572  0.2166\n",
      "      9        \u001B[36m0.1986\u001B[0m       0.7950        0.8145  0.2176\n",
      "     10        \u001B[36m0.1983\u001B[0m       0.7884        0.8436  0.2183\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4277\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8751\u001B[0m  0.2661\n",
      "      2        \u001B[36m0.7724\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.7646\u001B[0m  0.2159\n",
      "      3        \u001B[36m0.6108\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.7508\u001B[0m  0.2191\n",
      "      4        \u001B[36m0.5124\u001B[0m       0.7752        0.7773  0.2158\n",
      "      5        \u001B[36m0.4000\u001B[0m       0.7802        0.7850  0.2164\n",
      "      6        \u001B[36m0.3480\u001B[0m       0.7736        0.8366  0.2156\n",
      "      7        \u001B[36m0.3119\u001B[0m       \u001B[32m0.7934\u001B[0m        0.8300  0.2168\n",
      "      8        \u001B[36m0.2882\u001B[0m       \u001B[32m0.7967\u001B[0m        0.8217  0.2477\n",
      "      9        \u001B[36m0.2552\u001B[0m       0.7950        0.8759  0.2320\n",
      "     10        \u001B[36m0.2405\u001B[0m       0.7818        0.9495  0.2158\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3789\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m0.9221\u001B[0m  0.2426\n",
      "      2        \u001B[36m0.7432\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7348\u001B[0m  0.2179\n",
      "      3        \u001B[36m0.5763\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7157\u001B[0m  0.2165\n",
      "      4        \u001B[36m0.4876\u001B[0m       0.7967        \u001B[35m0.6962\u001B[0m  0.2184\n",
      "      5        \u001B[36m0.4057\u001B[0m       0.7901        0.7284  0.2178\n",
      "      6        \u001B[36m0.3587\u001B[0m       0.7950        0.7385  0.2157\n",
      "      7        \u001B[36m0.3069\u001B[0m       \u001B[32m0.8017\u001B[0m        0.7683  0.2110\n",
      "      8        \u001B[36m0.2747\u001B[0m       0.8017        0.8040  0.2112\n",
      "      9        \u001B[36m0.2523\u001B[0m       0.7884        0.8627  0.2123\n",
      "     10        \u001B[36m0.2194\u001B[0m       \u001B[32m0.8149\u001B[0m        0.7956  0.2119\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3722\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.8931\u001B[0m  0.2115\n",
      "      2        \u001B[36m0.7545\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7411\u001B[0m  0.2107\n",
      "      3        \u001B[36m0.5938\u001B[0m       0.7686        \u001B[35m0.7324\u001B[0m  0.2101\n",
      "      4        \u001B[36m0.4568\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7137\u001B[0m  0.2107\n",
      "      5        \u001B[36m0.3760\u001B[0m       \u001B[32m0.7835\u001B[0m        0.7967  0.2113\n",
      "      6        \u001B[36m0.3182\u001B[0m       \u001B[32m0.8066\u001B[0m        0.7410  0.2202\n",
      "      7        \u001B[36m0.2983\u001B[0m       0.7835        0.8077  0.2207\n",
      "      8        \u001B[36m0.2554\u001B[0m       0.7669        0.8578  0.2213\n",
      "      9        \u001B[36m0.2160\u001B[0m       0.7934        0.7888  0.2114\n",
      "     10        \u001B[36m0.1970\u001B[0m       0.7835        0.9086  0.2109\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7856\u001B[0m       \u001B[32m0.5818\u001B[0m        \u001B[35m1.1861\u001B[0m  0.2273\n",
      "      2        \u001B[36m1.2230\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0002\u001B[0m  0.2404\n",
      "      3        \u001B[36m1.0004\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9046\u001B[0m  0.2463\n",
      "      4        \u001B[36m0.8841\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.8323\u001B[0m  0.2573\n",
      "      5        \u001B[36m0.7990\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.8007\u001B[0m  0.2641\n",
      "      6        \u001B[36m0.7367\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.7772\u001B[0m  0.2658\n",
      "      7        \u001B[36m0.6504\u001B[0m       0.7868        \u001B[35m0.7620\u001B[0m  0.2450\n",
      "      8        \u001B[36m0.6026\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.7401\u001B[0m  0.2462\n",
      "      9        \u001B[36m0.5767\u001B[0m       0.7868        \u001B[35m0.7384\u001B[0m  0.2631\n",
      "     10        \u001B[36m0.5634\u001B[0m       0.7934        0.7474  0.2632\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8062\u001B[0m       \u001B[32m0.5686\u001B[0m        \u001B[35m1.2076\u001B[0m  0.2364\n",
      "      2        \u001B[36m1.2035\u001B[0m       \u001B[32m0.6545\u001B[0m        \u001B[35m1.0422\u001B[0m  0.2680\n",
      "      3        \u001B[36m1.0069\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m0.9344\u001B[0m  0.2729\n",
      "      4        \u001B[36m0.8825\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.8704\u001B[0m  0.2328\n",
      "      5        \u001B[36m0.8068\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.8229\u001B[0m  0.2401\n",
      "      6        \u001B[36m0.7333\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7827\u001B[0m  0.2365\n",
      "      7        \u001B[36m0.6980\u001B[0m       0.7587        \u001B[35m0.7752\u001B[0m  0.2344\n",
      "      8        \u001B[36m0.6258\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7241\u001B[0m  0.3016\n",
      "      9        \u001B[36m0.6008\u001B[0m       0.7769        \u001B[35m0.7106\u001B[0m  0.2699\n",
      "     10        \u001B[36m0.5647\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.6910\u001B[0m  0.2460\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8248\u001B[0m       \u001B[32m0.5785\u001B[0m        \u001B[35m1.1602\u001B[0m  0.2411\n",
      "      2        \u001B[36m1.2158\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m0.9881\u001B[0m  0.2506\n",
      "      3        \u001B[36m1.0485\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.8831\u001B[0m  0.2484\n",
      "      4        \u001B[36m0.8778\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.8157\u001B[0m  0.2486\n",
      "      5        \u001B[36m0.8150\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.7723\u001B[0m  0.2528\n",
      "      6        \u001B[36m0.7225\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7383\u001B[0m  0.2561\n",
      "      7        \u001B[36m0.6786\u001B[0m       0.7736        \u001B[35m0.7111\u001B[0m  0.2680\n",
      "      8        \u001B[36m0.6201\u001B[0m       0.7802        \u001B[35m0.7057\u001B[0m  0.2571\n",
      "      9        \u001B[36m0.5787\u001B[0m       0.7802        0.7091  0.2534\n",
      "     10        \u001B[36m0.5501\u001B[0m       0.7736        \u001B[35m0.7026\u001B[0m  0.2593\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7608\u001B[0m       \u001B[32m0.5835\u001B[0m        \u001B[35m1.1482\u001B[0m  0.2554\n",
      "      2        \u001B[36m1.1803\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m0.9415\u001B[0m  0.2623\n",
      "      3        \u001B[36m0.9755\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8375\u001B[0m  0.2611\n",
      "      4        \u001B[36m0.8583\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.7997\u001B[0m  0.2535\n",
      "      5        \u001B[36m0.7793\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.7745\u001B[0m  0.2543\n",
      "      6        \u001B[36m0.7247\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7217\u001B[0m  0.2675\n",
      "      7        \u001B[36m0.6767\u001B[0m       0.7620        \u001B[35m0.7070\u001B[0m  0.2617\n",
      "      8        \u001B[36m0.6188\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.6683\u001B[0m  0.2596\n",
      "      9        \u001B[36m0.5854\u001B[0m       0.7719        \u001B[35m0.6641\u001B[0m  0.2547\n",
      "     10        \u001B[36m0.5416\u001B[0m       0.7521        0.6973  0.2545\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7757\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.2017\u001B[0m  0.2416\n",
      "      2        \u001B[36m1.1701\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m0.9719\u001B[0m  0.2568\n",
      "      3        \u001B[36m1.0091\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.8719\u001B[0m  0.2619\n",
      "      4        \u001B[36m0.8854\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8437\u001B[0m  0.2536\n",
      "      5        \u001B[36m0.8198\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7811\u001B[0m  0.2630\n",
      "      6        \u001B[36m0.7139\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7403\u001B[0m  0.2711\n",
      "      7        \u001B[36m0.6512\u001B[0m       0.7752        \u001B[35m0.7316\u001B[0m  0.2649\n",
      "      8        \u001B[36m0.6413\u001B[0m       0.7653        \u001B[35m0.7297\u001B[0m  0.2614\n",
      "      9        \u001B[36m0.5729\u001B[0m       0.7785        \u001B[35m0.7149\u001B[0m  0.2609\n",
      "     10        \u001B[36m0.5232\u001B[0m       0.7785        0.7199  0.2624\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8347\u001B[0m       \u001B[32m0.5669\u001B[0m        \u001B[35m1.2481\u001B[0m  0.2536\n",
      "      2        \u001B[36m1.2015\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m1.0443\u001B[0m  0.2585\n",
      "      3        \u001B[36m1.0390\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.9632\u001B[0m  0.2679\n",
      "      4        \u001B[36m0.9149\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8890\u001B[0m  0.2501\n",
      "      5        \u001B[36m0.8254\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8152\u001B[0m  0.2600\n",
      "      6        \u001B[36m0.7266\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.7882\u001B[0m  0.2696\n",
      "      7        \u001B[36m0.6956\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7585\u001B[0m  0.2608\n",
      "      8        \u001B[36m0.6277\u001B[0m       0.7686        \u001B[35m0.7366\u001B[0m  0.2627\n",
      "      9        \u001B[36m0.5860\u001B[0m       0.7719        \u001B[35m0.7276\u001B[0m  0.2625\n",
      "     10        \u001B[36m0.5612\u001B[0m       0.7752        0.7291  0.2724\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7110\u001B[0m       \u001B[32m0.6298\u001B[0m        \u001B[35m1.1141\u001B[0m  0.2606\n",
      "      2        \u001B[36m1.1478\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.8925\u001B[0m  0.2397\n",
      "      3        \u001B[36m0.9759\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.8239\u001B[0m  0.2234\n",
      "      4        \u001B[36m0.8756\u001B[0m       0.7488        \u001B[35m0.7867\u001B[0m  0.2178\n",
      "      5        \u001B[36m0.7760\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.7466\u001B[0m  0.2215\n",
      "      6        \u001B[36m0.7141\u001B[0m       0.7554        0.7503  0.2297\n",
      "      7        \u001B[36m0.6602\u001B[0m       0.7554        0.7535  0.2213\n",
      "      8        \u001B[36m0.6092\u001B[0m       0.7405        0.7501  0.2161\n",
      "      9        \u001B[36m0.5815\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7074\u001B[0m  0.2169\n",
      "     10        \u001B[36m0.5790\u001B[0m       \u001B[32m0.7736\u001B[0m        0.7218  0.2186\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7652\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1485\u001B[0m  0.2169\n",
      "      2        \u001B[36m1.1787\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9967\u001B[0m  0.2139\n",
      "      3        \u001B[36m0.9734\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.8719\u001B[0m  0.2136\n",
      "      4        \u001B[36m0.8862\u001B[0m       0.7306        0.8819  0.2150\n",
      "      5        \u001B[36m0.8135\u001B[0m       0.7107        \u001B[35m0.8661\u001B[0m  0.2204\n",
      "      6        \u001B[36m0.7297\u001B[0m       0.7471        \u001B[35m0.7928\u001B[0m  0.2239\n",
      "      7        \u001B[36m0.6674\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7580\u001B[0m  0.2317\n",
      "      8        \u001B[36m0.6039\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7421\u001B[0m  0.2306\n",
      "      9        \u001B[36m0.5961\u001B[0m       0.7488        0.7755  0.2277\n",
      "     10        \u001B[36m0.5263\u001B[0m       0.7719        \u001B[35m0.7398\u001B[0m  0.2318\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7977\u001B[0m       \u001B[32m0.6099\u001B[0m        \u001B[35m1.1452\u001B[0m  0.2140\n",
      "      2        \u001B[36m1.1905\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.9570\u001B[0m  0.2135\n",
      "      3        \u001B[36m1.0127\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.8763\u001B[0m  0.2122\n",
      "      4        \u001B[36m0.8970\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8293\u001B[0m  0.2158\n",
      "      5        \u001B[36m0.7941\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.7839\u001B[0m  0.2125\n",
      "      6        \u001B[36m0.7084\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.7408\u001B[0m  0.2133\n",
      "      7        \u001B[36m0.6636\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7169\u001B[0m  0.2147\n",
      "      8        \u001B[36m0.6087\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.6999\u001B[0m  0.2195\n",
      "      9        \u001B[36m0.5720\u001B[0m       0.7587        0.7010  0.2128\n",
      "     10        \u001B[36m0.5312\u001B[0m       0.7702        0.7129  0.2131\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5931\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m1.0643\u001B[0m  0.2194\n",
      "      2        \u001B[36m1.0088\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.8548\u001B[0m  0.2281\n",
      "      3        \u001B[36m0.8076\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7857\u001B[0m  0.2394\n",
      "      4        \u001B[36m0.6870\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.7380\u001B[0m  0.2573\n",
      "      5        \u001B[36m0.6014\u001B[0m       \u001B[32m0.8083\u001B[0m        \u001B[35m0.6909\u001B[0m  0.2596\n",
      "      6        \u001B[36m0.5560\u001B[0m       0.8066        \u001B[35m0.6743\u001B[0m  0.2564\n",
      "      7        \u001B[36m0.4997\u001B[0m       0.8050        0.6973  0.2480\n",
      "      8        \u001B[36m0.4670\u001B[0m       0.8050        0.6845  0.2613\n",
      "      9        \u001B[36m0.4305\u001B[0m       \u001B[32m0.8165\u001B[0m        0.6762  0.2673\n",
      "     10        \u001B[36m0.4039\u001B[0m       0.8033        0.7209  0.2591\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5768\u001B[0m       \u001B[32m0.6446\u001B[0m        \u001B[35m1.1071\u001B[0m  0.2356\n",
      "      2        \u001B[36m0.9965\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m0.8934\u001B[0m  0.2604\n",
      "      3        \u001B[36m0.8073\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.8105\u001B[0m  0.2578\n",
      "      4        \u001B[36m0.6928\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7485\u001B[0m  0.2590\n",
      "      5        \u001B[36m0.6139\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.7181\u001B[0m  0.2592\n",
      "      6        \u001B[36m0.5340\u001B[0m       0.7835        \u001B[35m0.7158\u001B[0m  0.2570\n",
      "      7        \u001B[36m0.5140\u001B[0m       0.7785        \u001B[35m0.7055\u001B[0m  0.2635\n",
      "      8        \u001B[36m0.4781\u001B[0m       \u001B[32m0.8116\u001B[0m        \u001B[35m0.6507\u001B[0m  0.2627\n",
      "      9        \u001B[36m0.4234\u001B[0m       \u001B[32m0.8132\u001B[0m        \u001B[35m0.6383\u001B[0m  0.2572\n",
      "     10        \u001B[36m0.4146\u001B[0m       0.8116        0.6598  0.2575\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5560\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0599\u001B[0m  0.2379\n",
      "      2        \u001B[36m1.0115\u001B[0m       \u001B[32m0.7008\u001B[0m        \u001B[35m0.8430\u001B[0m  0.2315\n",
      "      3        \u001B[36m0.8212\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.7712\u001B[0m  0.2331\n",
      "      4        \u001B[36m0.6961\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7342\u001B[0m  0.2471\n",
      "      5        \u001B[36m0.6120\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.7058\u001B[0m  0.2517\n",
      "      6        \u001B[36m0.5539\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.6954\u001B[0m  0.2345\n",
      "      7        \u001B[36m0.5008\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6868\u001B[0m  0.2393\n",
      "      8        \u001B[36m0.4571\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6833\u001B[0m  0.2430\n",
      "      9        \u001B[36m0.4181\u001B[0m       0.7934        \u001B[35m0.6691\u001B[0m  0.2299\n",
      "     10        \u001B[36m0.3960\u001B[0m       0.8000        0.7065  0.2351\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6424\u001B[0m       \u001B[32m0.6777\u001B[0m        \u001B[35m1.0935\u001B[0m  0.2356\n",
      "      2        \u001B[36m1.0485\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.9086\u001B[0m  0.2397\n",
      "      3        \u001B[36m0.8357\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8278\u001B[0m  0.2332\n",
      "      4        \u001B[36m0.7053\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7644\u001B[0m  0.2337\n",
      "      5        \u001B[36m0.6279\u001B[0m       0.7455        0.7782  0.2302\n",
      "      6        \u001B[36m0.5747\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.7106\u001B[0m  0.2228\n",
      "      7        \u001B[36m0.5471\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.6673\u001B[0m  0.2273\n",
      "      8        \u001B[36m0.4908\u001B[0m       0.7983        0.7141  0.2258\n",
      "      9        \u001B[36m0.4438\u001B[0m       0.8000        0.7126  0.2193\n",
      "     10        \u001B[36m0.4199\u001B[0m       0.7917        0.7023  0.2392\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5325\u001B[0m       \u001B[32m0.6810\u001B[0m        \u001B[35m1.0234\u001B[0m  0.2306\n",
      "      2        \u001B[36m1.0103\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.8702\u001B[0m  0.2327\n",
      "      3        \u001B[36m0.8149\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.8242\u001B[0m  0.2499\n",
      "      4        \u001B[36m0.7203\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7590\u001B[0m  0.2507\n",
      "      5        \u001B[36m0.6081\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7253\u001B[0m  0.2472\n",
      "      6        \u001B[36m0.5603\u001B[0m       0.7785        \u001B[35m0.7132\u001B[0m  0.2490\n",
      "      7        \u001B[36m0.5188\u001B[0m       \u001B[32m0.8099\u001B[0m        \u001B[35m0.6762\u001B[0m  0.2501\n",
      "      8        \u001B[36m0.4816\u001B[0m       0.7884        0.7046  0.2413\n",
      "      9        \u001B[36m0.4366\u001B[0m       0.7901        0.6964  0.2539\n",
      "     10        \u001B[36m0.4170\u001B[0m       0.8017        0.6810  0.2631\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5859\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.0669\u001B[0m  0.2967\n",
      "      2        \u001B[36m1.0063\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.8756\u001B[0m  0.2672\n",
      "      3        \u001B[36m0.8250\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.7746\u001B[0m  0.2629\n",
      "      4        \u001B[36m0.6893\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7372\u001B[0m  0.2551\n",
      "      5        \u001B[36m0.6162\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7033\u001B[0m  0.2456\n",
      "      6        \u001B[36m0.5585\u001B[0m       0.7818        0.7054  0.2279\n",
      "      7        \u001B[36m0.5043\u001B[0m       0.7835        \u001B[35m0.6852\u001B[0m  0.2255\n",
      "      8        \u001B[36m0.4625\u001B[0m       0.7851        0.7011  0.2245\n",
      "      9        0.4630       \u001B[32m0.7884\u001B[0m        \u001B[35m0.6672\u001B[0m  0.2368\n",
      "     10        \u001B[36m0.4023\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.6658\u001B[0m  0.2438\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5781\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m0.9791\u001B[0m  0.2359\n",
      "      2        \u001B[36m1.0155\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8180\u001B[0m  0.2336\n",
      "      3        \u001B[36m0.8232\u001B[0m       0.7289        \u001B[35m0.8032\u001B[0m  0.2191\n",
      "      4        \u001B[36m0.6941\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.7296\u001B[0m  0.2195\n",
      "      5        \u001B[36m0.6376\u001B[0m       \u001B[32m0.7802\u001B[0m        0.7391  0.2205\n",
      "      6        \u001B[36m0.5841\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.6805\u001B[0m  0.2240\n",
      "      7        \u001B[36m0.5373\u001B[0m       0.7851        0.7027  0.2213\n",
      "      8        \u001B[36m0.4854\u001B[0m       \u001B[32m0.7967\u001B[0m        0.6878  0.2203\n",
      "      9        \u001B[36m0.4438\u001B[0m       0.7917        0.7192  0.2182\n",
      "     10        \u001B[36m0.4398\u001B[0m       \u001B[32m0.8066\u001B[0m        0.7027  0.2190\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5845\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9896\u001B[0m  0.2203\n",
      "      2        \u001B[36m0.9637\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.8182\u001B[0m  0.2181\n",
      "      3        \u001B[36m0.8594\u001B[0m       \u001B[32m0.7587\u001B[0m        \u001B[35m0.7738\u001B[0m  0.2217\n",
      "      4        \u001B[36m0.7133\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7357\u001B[0m  0.2187\n",
      "      5        \u001B[36m0.6681\u001B[0m       \u001B[32m0.7884\u001B[0m        0.7568  0.2199\n",
      "      6        \u001B[36m0.5844\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.7156\u001B[0m  0.2215\n",
      "      7        \u001B[36m0.5152\u001B[0m       0.7769        0.7283  0.2181\n",
      "      8        \u001B[36m0.4772\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6965\u001B[0m  0.2206\n",
      "      9        \u001B[36m0.4572\u001B[0m       0.7736        0.7206  0.2215\n",
      "     10        \u001B[36m0.4197\u001B[0m       0.7917        0.7074  0.2210\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7389\u001B[0m       \u001B[32m0.6397\u001B[0m        \u001B[35m1.0365\u001B[0m  0.2243\n",
      "      2        \u001B[36m1.0589\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9030\u001B[0m  0.2194\n",
      "      3        \u001B[36m0.9059\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.8724\u001B[0m  0.2202\n",
      "      4        \u001B[36m0.7477\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8164\u001B[0m  0.2218\n",
      "      5        \u001B[36m0.6908\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.7555\u001B[0m  0.2202\n",
      "      6        \u001B[36m0.6171\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7302\u001B[0m  0.2205\n",
      "      7        \u001B[36m0.5415\u001B[0m       0.7851        0.7531  0.2186\n",
      "      8        \u001B[36m0.4741\u001B[0m       0.7736        0.7691  0.2207\n",
      "      9        \u001B[36m0.4551\u001B[0m       0.7851        0.7712  0.2219\n",
      "     10        \u001B[36m0.4207\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.7163\u001B[0m  0.2183\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3912\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m0.9605\u001B[0m  0.2240\n",
      "      2        \u001B[36m0.8291\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.7964\u001B[0m  0.2228\n",
      "      3        \u001B[36m0.6549\u001B[0m       \u001B[32m0.7752\u001B[0m        0.8248  0.2225\n",
      "      4        \u001B[36m0.5776\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.7545\u001B[0m  0.2198\n",
      "      5        \u001B[36m0.4974\u001B[0m       0.7950        \u001B[35m0.7433\u001B[0m  0.2236\n",
      "      6        \u001B[36m0.4315\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7285\u001B[0m  0.2212\n",
      "      7        \u001B[36m0.3794\u001B[0m       0.7983        0.7750  0.2212\n",
      "      8        \u001B[36m0.3583\u001B[0m       \u001B[32m0.8165\u001B[0m        0.7289  0.2230\n",
      "      9        \u001B[36m0.3187\u001B[0m       0.7917        0.7434  0.2209\n",
      "     10        \u001B[36m0.2929\u001B[0m       0.7884        0.8008  0.2223\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4141\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m0.9117\u001B[0m  0.2227\n",
      "      2        \u001B[36m0.8050\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.7535\u001B[0m  0.2235\n",
      "      3        \u001B[36m0.6283\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7154\u001B[0m  0.2207\n",
      "      4        \u001B[36m0.5510\u001B[0m       \u001B[32m0.8165\u001B[0m        \u001B[35m0.6941\u001B[0m  0.2204\n",
      "      5        \u001B[36m0.4675\u001B[0m       \u001B[32m0.8231\u001B[0m        \u001B[35m0.6554\u001B[0m  0.2195\n",
      "      6        \u001B[36m0.4068\u001B[0m       \u001B[32m0.8314\u001B[0m        \u001B[35m0.6373\u001B[0m  0.2252\n",
      "      7        \u001B[36m0.3931\u001B[0m       \u001B[32m0.8397\u001B[0m        0.6435  0.2204\n",
      "      8        \u001B[36m0.3417\u001B[0m       \u001B[32m0.8430\u001B[0m        0.6395  0.2243\n",
      "      9        \u001B[36m0.3185\u001B[0m       0.8364        0.6428  0.2197\n",
      "     10        \u001B[36m0.2815\u001B[0m       0.8215        0.6610  0.2241\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3906\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9402\u001B[0m  0.2224\n",
      "      2        \u001B[36m0.7951\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.7905\u001B[0m  0.2215\n",
      "      3        \u001B[36m0.6165\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.7665\u001B[0m  0.2251\n",
      "      4        \u001B[36m0.5429\u001B[0m       0.7967        \u001B[35m0.7336\u001B[0m  0.2520\n",
      "      5        \u001B[36m0.4471\u001B[0m       \u001B[32m0.8132\u001B[0m        \u001B[35m0.7091\u001B[0m  0.2316\n",
      "      6        \u001B[36m0.3951\u001B[0m       0.8132        0.7272  0.2236\n",
      "      7        \u001B[36m0.3475\u001B[0m       0.8099        \u001B[35m0.7084\u001B[0m  0.2212\n",
      "      8        \u001B[36m0.3259\u001B[0m       \u001B[32m0.8149\u001B[0m        \u001B[35m0.7076\u001B[0m  0.2326\n",
      "      9        \u001B[36m0.2973\u001B[0m       0.8149        0.7441  0.2381\n",
      "     10        \u001B[36m0.2583\u001B[0m       0.7835        0.7636  0.2407\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4338\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9197\u001B[0m  0.2389\n",
      "      2        \u001B[36m0.8251\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.7742\u001B[0m  0.2492\n",
      "      3        \u001B[36m0.6386\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7321\u001B[0m  0.2311\n",
      "      4        \u001B[36m0.5467\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.7011\u001B[0m  0.2232\n",
      "      5        \u001B[36m0.4857\u001B[0m       \u001B[32m0.7983\u001B[0m        0.7074  0.2261\n",
      "      6        \u001B[36m0.4570\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6833\u001B[0m  0.2223\n",
      "      7        \u001B[36m0.3929\u001B[0m       \u001B[32m0.8099\u001B[0m        0.6852  0.2262\n",
      "      8        \u001B[36m0.3564\u001B[0m       0.7818        0.7598  0.2228\n",
      "      9        \u001B[36m0.3372\u001B[0m       0.8083        0.7324  0.2259\n",
      "     10        \u001B[36m0.2999\u001B[0m       0.7736        0.8047  0.2328\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4717\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.9188\u001B[0m  0.2279\n",
      "      2        \u001B[36m0.8797\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.8021\u001B[0m  0.2290\n",
      "      3        \u001B[36m0.6671\u001B[0m       0.7702        \u001B[35m0.7420\u001B[0m  0.2241\n",
      "      4        \u001B[36m0.5738\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.7414\u001B[0m  0.2271\n",
      "      5        \u001B[36m0.4902\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6786\u001B[0m  0.2247\n",
      "      6        \u001B[36m0.4503\u001B[0m       \u001B[32m0.8182\u001B[0m        \u001B[35m0.6522\u001B[0m  0.2271\n",
      "      7        \u001B[36m0.4048\u001B[0m       0.8099        0.6874  0.2227\n",
      "      8        \u001B[36m0.3554\u001B[0m       0.8165        0.7036  0.2246\n",
      "      9        \u001B[36m0.3304\u001B[0m       \u001B[32m0.8248\u001B[0m        0.6930  0.2245\n",
      "     10        \u001B[36m0.3202\u001B[0m       0.8198        0.7585  0.2234\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4713\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m0.8756\u001B[0m  0.2228\n",
      "      2        \u001B[36m0.8395\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7498\u001B[0m  0.2223\n",
      "      3        \u001B[36m0.6457\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7268\u001B[0m  0.2220\n",
      "      4        \u001B[36m0.5457\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6662\u001B[0m  0.2282\n",
      "      5        \u001B[36m0.4715\u001B[0m       0.7917        0.6817  0.2278\n",
      "      6        \u001B[36m0.4181\u001B[0m       \u001B[32m0.8000\u001B[0m        0.6741  0.2244\n",
      "      7        \u001B[36m0.3753\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.6594\u001B[0m  0.2441\n",
      "      8        \u001B[36m0.3565\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6517\u001B[0m  0.2584\n",
      "      9        \u001B[36m0.2930\u001B[0m       0.7967        0.7028  0.2748\n",
      "     10        \u001B[36m0.2806\u001B[0m       0.8033        0.7258  0.2620\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4880\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.9031\u001B[0m  0.2623\n",
      "      2        \u001B[36m0.8425\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.8069\u001B[0m  0.2415\n",
      "      3        \u001B[36m0.7157\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7647\u001B[0m  0.2387\n",
      "      4        \u001B[36m0.5984\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7268\u001B[0m  0.2378\n",
      "      5        \u001B[36m0.5134\u001B[0m       \u001B[32m0.7983\u001B[0m        0.7356  0.2393\n",
      "      6        \u001B[36m0.4573\u001B[0m       0.7868        0.7906  0.2469\n",
      "      7        \u001B[36m0.4264\u001B[0m       0.7917        0.7792  0.2442\n",
      "      8        \u001B[36m0.3627\u001B[0m       0.7851        0.7975  0.2397\n",
      "      9        \u001B[36m0.3470\u001B[0m       0.7967        0.7912  0.2437\n",
      "     10        \u001B[36m0.3129\u001B[0m       \u001B[32m0.8066\u001B[0m        0.7968  0.2400\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4859\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m0.9185\u001B[0m  0.2481\n",
      "      2        \u001B[36m0.9032\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.8019\u001B[0m  0.2393\n",
      "      3        \u001B[36m0.7087\u001B[0m       0.7620        0.8352  0.2426\n",
      "      4        \u001B[36m0.6325\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7646\u001B[0m  0.2392\n",
      "      5        \u001B[36m0.5343\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.7530\u001B[0m  0.2395\n",
      "      6        \u001B[36m0.4811\u001B[0m       0.7884        0.7804  0.2395\n",
      "      7        \u001B[36m0.4424\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.7264\u001B[0m  0.2413\n",
      "      8        \u001B[36m0.3647\u001B[0m       \u001B[32m0.7983\u001B[0m        0.7325  0.2399\n",
      "      9        \u001B[36m0.3343\u001B[0m       0.7967        0.8176  0.2419\n",
      "     10        \u001B[36m0.3262\u001B[0m       0.7983        0.7899  0.2429\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5208\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9372\u001B[0m  0.2502\n",
      "      2        \u001B[36m0.8532\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8278\u001B[0m  0.2428\n",
      "      3        \u001B[36m0.7049\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.7863\u001B[0m  0.2414\n",
      "      4        \u001B[36m0.6193\u001B[0m       \u001B[32m0.7835\u001B[0m        0.7878  0.2417\n",
      "      5        \u001B[36m0.5360\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.7360\u001B[0m  0.2420\n",
      "      6        \u001B[36m0.4477\u001B[0m       0.7686        0.7920  0.2405\n",
      "      7        \u001B[36m0.4240\u001B[0m       0.7884        0.7543  0.2413\n",
      "      8        \u001B[36m0.3661\u001B[0m       0.7818        0.7816  0.2384\n",
      "      9        \u001B[36m0.3275\u001B[0m       0.7950        0.8048  0.2377\n",
      "     10        \u001B[36m0.2909\u001B[0m       0.7917        0.8429  0.2395\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2571\u001B[0m       \u001B[32m0.3041\u001B[0m        \u001B[35m1.7630\u001B[0m  0.2568\n",
      "      2        \u001B[36m1.9416\u001B[0m       \u001B[32m0.4281\u001B[0m        \u001B[35m1.6062\u001B[0m  0.2494\n",
      "      3        \u001B[36m1.7828\u001B[0m       \u001B[32m0.4529\u001B[0m        \u001B[35m1.4878\u001B[0m  0.2615\n",
      "      4        \u001B[36m1.6568\u001B[0m       \u001B[32m0.4909\u001B[0m        \u001B[35m1.4041\u001B[0m  0.2620\n",
      "      5        \u001B[36m1.5155\u001B[0m       \u001B[32m0.5223\u001B[0m        \u001B[35m1.3382\u001B[0m  0.2659\n",
      "      6        1.5232       \u001B[32m0.5521\u001B[0m        \u001B[35m1.2797\u001B[0m  0.2663\n",
      "      7        \u001B[36m1.4161\u001B[0m       \u001B[32m0.5934\u001B[0m        \u001B[35m1.2390\u001B[0m  0.2684\n",
      "      8        \u001B[36m1.3656\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.1966\u001B[0m  0.2445\n",
      "      9        \u001B[36m1.3045\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.1648\u001B[0m  0.2486\n",
      "     10        \u001B[36m1.2589\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.1359\u001B[0m  0.2480\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1716\u001B[0m       \u001B[32m0.2909\u001B[0m        \u001B[35m1.7558\u001B[0m  0.2549\n",
      "      2        \u001B[36m1.8833\u001B[0m       \u001B[32m0.3934\u001B[0m        \u001B[35m1.5779\u001B[0m  0.2445\n",
      "      3        \u001B[36m1.7359\u001B[0m       \u001B[32m0.4512\u001B[0m        \u001B[35m1.4736\u001B[0m  0.2464\n",
      "      4        \u001B[36m1.6003\u001B[0m       \u001B[32m0.4843\u001B[0m        \u001B[35m1.3886\u001B[0m  0.2756\n",
      "      5        \u001B[36m1.4822\u001B[0m       \u001B[32m0.5091\u001B[0m        \u001B[35m1.3268\u001B[0m  0.2529\n",
      "      6        \u001B[36m1.4059\u001B[0m       \u001B[32m0.5289\u001B[0m        \u001B[35m1.2716\u001B[0m  0.2532\n",
      "      7        \u001B[36m1.3885\u001B[0m       \u001B[32m0.5521\u001B[0m        \u001B[35m1.2293\u001B[0m  0.2443\n",
      "      8        \u001B[36m1.2995\u001B[0m       \u001B[32m0.5736\u001B[0m        \u001B[35m1.1896\u001B[0m  0.2478\n",
      "      9        \u001B[36m1.2601\u001B[0m       \u001B[32m0.5835\u001B[0m        \u001B[35m1.1581\u001B[0m  0.2442\n",
      "     10        \u001B[36m1.2246\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.1324\u001B[0m  0.2474\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2583\u001B[0m       \u001B[32m0.2909\u001B[0m        \u001B[35m1.7172\u001B[0m  0.2563\n",
      "      2        \u001B[36m1.9507\u001B[0m       \u001B[32m0.4000\u001B[0m        \u001B[35m1.5600\u001B[0m  0.2512\n",
      "      3        \u001B[36m1.7468\u001B[0m       \u001B[32m0.4777\u001B[0m        \u001B[35m1.4421\u001B[0m  0.2480\n",
      "      4        \u001B[36m1.6196\u001B[0m       \u001B[32m0.5107\u001B[0m        \u001B[35m1.3560\u001B[0m  0.2495\n",
      "      5        \u001B[36m1.5213\u001B[0m       \u001B[32m0.5421\u001B[0m        \u001B[35m1.2908\u001B[0m  0.2456\n",
      "      6        \u001B[36m1.4429\u001B[0m       \u001B[32m0.5653\u001B[0m        \u001B[35m1.2417\u001B[0m  0.2466\n",
      "      7        \u001B[36m1.3865\u001B[0m       \u001B[32m0.5934\u001B[0m        \u001B[35m1.1995\u001B[0m  0.2451\n",
      "      8        \u001B[36m1.3342\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.1558\u001B[0m  0.2467\n",
      "      9        \u001B[36m1.2764\u001B[0m       \u001B[32m0.6298\u001B[0m        \u001B[35m1.1255\u001B[0m  0.2446\n",
      "     10        \u001B[36m1.2221\u001B[0m       \u001B[32m0.6512\u001B[0m        \u001B[35m1.0954\u001B[0m  0.2473\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2513\u001B[0m       \u001B[32m0.3620\u001B[0m        \u001B[35m1.7206\u001B[0m  0.2470\n",
      "      2        \u001B[36m1.8782\u001B[0m       \u001B[32m0.4380\u001B[0m        \u001B[35m1.5617\u001B[0m  0.2521\n",
      "      3        \u001B[36m1.6904\u001B[0m       \u001B[32m0.4793\u001B[0m        \u001B[35m1.4577\u001B[0m  0.2575\n",
      "      4        \u001B[36m1.5749\u001B[0m       \u001B[32m0.5008\u001B[0m        \u001B[35m1.3710\u001B[0m  0.2513\n",
      "      5        \u001B[36m1.5244\u001B[0m       \u001B[32m0.5405\u001B[0m        \u001B[35m1.3053\u001B[0m  0.2390\n",
      "      6        \u001B[36m1.4094\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.2505\u001B[0m  0.2521\n",
      "      7        \u001B[36m1.3191\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.2113\u001B[0m  0.2567\n",
      "      8        \u001B[36m1.2981\u001B[0m       \u001B[32m0.6298\u001B[0m        \u001B[35m1.1709\u001B[0m  0.2590\n",
      "      9        \u001B[36m1.2501\u001B[0m       \u001B[32m0.6430\u001B[0m        \u001B[35m1.1417\u001B[0m  0.2593\n",
      "     10        \u001B[36m1.2257\u001B[0m       \u001B[32m0.6479\u001B[0m        \u001B[35m1.1072\u001B[0m  0.2534\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4471\u001B[0m       \u001B[32m0.2612\u001B[0m        \u001B[35m1.8982\u001B[0m  0.2643\n",
      "      2        \u001B[36m2.0114\u001B[0m       \u001B[32m0.4017\u001B[0m        \u001B[35m1.7184\u001B[0m  0.2586\n",
      "      3        \u001B[36m1.7526\u001B[0m       \u001B[32m0.4529\u001B[0m        \u001B[35m1.5834\u001B[0m  0.2553\n",
      "      4        \u001B[36m1.6316\u001B[0m       \u001B[32m0.4843\u001B[0m        \u001B[35m1.4771\u001B[0m  0.2532\n",
      "      5        \u001B[36m1.5362\u001B[0m       \u001B[32m0.5124\u001B[0m        \u001B[35m1.4031\u001B[0m  0.2543\n",
      "      6        \u001B[36m1.4612\u001B[0m       \u001B[32m0.5471\u001B[0m        \u001B[35m1.3462\u001B[0m  0.2551\n",
      "      7        \u001B[36m1.3713\u001B[0m       \u001B[32m0.5653\u001B[0m        \u001B[35m1.3021\u001B[0m  0.2538\n",
      "      8        \u001B[36m1.3332\u001B[0m       \u001B[32m0.5934\u001B[0m        \u001B[35m1.2503\u001B[0m  0.2516\n",
      "      9        \u001B[36m1.2897\u001B[0m       \u001B[32m0.6050\u001B[0m        \u001B[35m1.2095\u001B[0m  0.2539\n",
      "     10        \u001B[36m1.2403\u001B[0m       \u001B[32m0.6099\u001B[0m        \u001B[35m1.1697\u001B[0m  0.2532\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3714\u001B[0m       \u001B[32m0.2793\u001B[0m        \u001B[35m1.7951\u001B[0m  0.2642\n",
      "      2        \u001B[36m1.9869\u001B[0m       \u001B[32m0.3719\u001B[0m        \u001B[35m1.6545\u001B[0m  0.2497\n",
      "      3        \u001B[36m1.7888\u001B[0m       \u001B[32m0.4413\u001B[0m        \u001B[35m1.5240\u001B[0m  0.2407\n",
      "      4        \u001B[36m1.6321\u001B[0m       \u001B[32m0.4909\u001B[0m        \u001B[35m1.4312\u001B[0m  0.2376\n",
      "      5        \u001B[36m1.5157\u001B[0m       \u001B[32m0.5157\u001B[0m        \u001B[35m1.3632\u001B[0m  0.2400\n",
      "      6        \u001B[36m1.4499\u001B[0m       \u001B[32m0.5554\u001B[0m        \u001B[35m1.3073\u001B[0m  0.2392\n",
      "      7        \u001B[36m1.3974\u001B[0m       \u001B[32m0.5785\u001B[0m        \u001B[35m1.2574\u001B[0m  0.2392\n",
      "      8        \u001B[36m1.3384\u001B[0m       \u001B[32m0.5901\u001B[0m        \u001B[35m1.2139\u001B[0m  0.2402\n",
      "      9        \u001B[36m1.2761\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.1770\u001B[0m  0.2414\n",
      "     10        \u001B[36m1.2083\u001B[0m       \u001B[32m0.6116\u001B[0m        \u001B[35m1.1423\u001B[0m  0.2422\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3932\u001B[0m       \u001B[32m0.3339\u001B[0m        \u001B[35m1.7270\u001B[0m  0.2417\n",
      "      2        \u001B[36m1.9400\u001B[0m       \u001B[32m0.4314\u001B[0m        \u001B[35m1.5333\u001B[0m  0.2426\n",
      "      3        \u001B[36m1.7384\u001B[0m       \u001B[32m0.4793\u001B[0m        \u001B[35m1.4074\u001B[0m  0.2426\n",
      "      4        \u001B[36m1.5776\u001B[0m       \u001B[32m0.5322\u001B[0m        \u001B[35m1.3176\u001B[0m  0.2391\n",
      "      5        \u001B[36m1.4610\u001B[0m       \u001B[32m0.5785\u001B[0m        \u001B[35m1.2517\u001B[0m  0.2525\n",
      "      6        \u001B[36m1.3489\u001B[0m       \u001B[32m0.6116\u001B[0m        \u001B[35m1.1989\u001B[0m  0.2582\n",
      "      7        \u001B[36m1.2955\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.1594\u001B[0m  0.2557\n",
      "      8        \u001B[36m1.2542\u001B[0m       0.6331        \u001B[35m1.1117\u001B[0m  0.2502\n",
      "      9        \u001B[36m1.1934\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0761\u001B[0m  0.2548\n",
      "     10        \u001B[36m1.1600\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m1.0541\u001B[0m  0.2403\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2898\u001B[0m       \u001B[32m0.3488\u001B[0m        \u001B[35m1.6783\u001B[0m  0.2452\n",
      "      2        \u001B[36m1.8038\u001B[0m       \u001B[32m0.4661\u001B[0m        \u001B[35m1.5022\u001B[0m  0.2390\n",
      "      3        \u001B[36m1.6350\u001B[0m       \u001B[32m0.5289\u001B[0m        \u001B[35m1.4012\u001B[0m  0.2372\n",
      "      4        \u001B[36m1.5231\u001B[0m       \u001B[32m0.5504\u001B[0m        \u001B[35m1.3304\u001B[0m  0.2384\n",
      "      5        \u001B[36m1.4210\u001B[0m       \u001B[32m0.5884\u001B[0m        \u001B[35m1.2711\u001B[0m  0.2379\n",
      "      6        \u001B[36m1.3310\u001B[0m       \u001B[32m0.6017\u001B[0m        \u001B[35m1.2205\u001B[0m  0.2405\n",
      "      7        \u001B[36m1.2850\u001B[0m       \u001B[32m0.6165\u001B[0m        \u001B[35m1.1840\u001B[0m  0.2383\n",
      "      8        \u001B[36m1.2112\u001B[0m       \u001B[32m0.6347\u001B[0m        \u001B[35m1.1444\u001B[0m  0.2400\n",
      "      9        \u001B[36m1.1694\u001B[0m       \u001B[32m0.6364\u001B[0m        \u001B[35m1.1208\u001B[0m  0.2391\n",
      "     10        \u001B[36m1.1117\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0900\u001B[0m  0.2381\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1740\u001B[0m       \u001B[32m0.3967\u001B[0m        \u001B[35m1.5855\u001B[0m  0.2457\n",
      "      2        \u001B[36m1.7607\u001B[0m       \u001B[32m0.4744\u001B[0m        \u001B[35m1.4097\u001B[0m  0.2390\n",
      "      3        \u001B[36m1.6230\u001B[0m       \u001B[32m0.4975\u001B[0m        \u001B[35m1.3066\u001B[0m  0.2370\n",
      "      4        \u001B[36m1.4889\u001B[0m       \u001B[32m0.5554\u001B[0m        \u001B[35m1.2339\u001B[0m  0.2407\n",
      "      5        \u001B[36m1.4037\u001B[0m       \u001B[32m0.5868\u001B[0m        \u001B[35m1.1762\u001B[0m  0.2387\n",
      "      6        \u001B[36m1.3583\u001B[0m       \u001B[32m0.6215\u001B[0m        \u001B[35m1.1328\u001B[0m  0.2406\n",
      "      7        \u001B[36m1.2797\u001B[0m       \u001B[32m0.6364\u001B[0m        \u001B[35m1.0987\u001B[0m  0.2774\n",
      "      8        \u001B[36m1.2238\u001B[0m       \u001B[32m0.6512\u001B[0m        \u001B[35m1.0622\u001B[0m  0.2640\n",
      "      9        \u001B[36m1.1588\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0401\u001B[0m  0.2543\n",
      "     10        \u001B[36m1.1375\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0142\u001B[0m  0.2517\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1145\u001B[0m       \u001B[32m0.3124\u001B[0m        \u001B[35m1.6567\u001B[0m  0.2663\n",
      "      2        \u001B[36m1.6854\u001B[0m       \u001B[32m0.4595\u001B[0m        \u001B[35m1.4588\u001B[0m  0.2569\n",
      "      3        \u001B[36m1.5067\u001B[0m       \u001B[32m0.5223\u001B[0m        \u001B[35m1.3356\u001B[0m  0.2657\n",
      "      4        \u001B[36m1.3923\u001B[0m       \u001B[32m0.5653\u001B[0m        \u001B[35m1.2560\u001B[0m  0.2574\n",
      "      5        \u001B[36m1.2874\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.1899\u001B[0m  0.2587\n",
      "      6        \u001B[36m1.2395\u001B[0m       \u001B[32m0.6430\u001B[0m        \u001B[35m1.1369\u001B[0m  0.2561\n",
      "      7        \u001B[36m1.1122\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.0943\u001B[0m  0.2583\n",
      "      8        \u001B[36m1.0793\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m1.0536\u001B[0m  0.2548\n",
      "      9        \u001B[36m1.0277\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m1.0192\u001B[0m  0.2460\n",
      "     10        \u001B[36m0.9897\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9963\u001B[0m  0.2440\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9936\u001B[0m       \u001B[32m0.3851\u001B[0m        \u001B[35m1.6080\u001B[0m  0.2544\n",
      "      2        \u001B[36m1.6620\u001B[0m       \u001B[32m0.4727\u001B[0m        \u001B[35m1.4532\u001B[0m  0.2440\n",
      "      3        \u001B[36m1.4970\u001B[0m       \u001B[32m0.5322\u001B[0m        \u001B[35m1.3371\u001B[0m  0.2441\n",
      "      4        \u001B[36m1.3699\u001B[0m       \u001B[32m0.5702\u001B[0m        \u001B[35m1.2542\u001B[0m  0.2450\n",
      "      5        \u001B[36m1.2980\u001B[0m       \u001B[32m0.5950\u001B[0m        \u001B[35m1.1884\u001B[0m  0.2461\n",
      "      6        \u001B[36m1.1762\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.1370\u001B[0m  0.2426\n",
      "      7        \u001B[36m1.1308\u001B[0m       \u001B[32m0.6446\u001B[0m        \u001B[35m1.0884\u001B[0m  0.2562\n",
      "      8        \u001B[36m1.0758\u001B[0m       \u001B[32m0.6678\u001B[0m        \u001B[35m1.0490\u001B[0m  0.2596\n",
      "      9        \u001B[36m1.0386\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m1.0158\u001B[0m  0.2583\n",
      "     10        \u001B[36m0.9819\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9866\u001B[0m  0.2583\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9348\u001B[0m       \u001B[32m0.3917\u001B[0m        \u001B[35m1.5706\u001B[0m  0.2735\n",
      "      2        \u001B[36m1.6663\u001B[0m       \u001B[32m0.4545\u001B[0m        \u001B[35m1.4198\u001B[0m  0.2560\n",
      "      3        \u001B[36m1.4873\u001B[0m       \u001B[32m0.5240\u001B[0m        \u001B[35m1.3154\u001B[0m  0.2596\n",
      "      4        \u001B[36m1.3740\u001B[0m       \u001B[32m0.5669\u001B[0m        \u001B[35m1.2363\u001B[0m  0.2596\n",
      "      5        \u001B[36m1.2654\u001B[0m       \u001B[32m0.5950\u001B[0m        \u001B[35m1.1774\u001B[0m  0.2574\n",
      "      6        \u001B[36m1.2061\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.1306\u001B[0m  0.2565\n",
      "      7        \u001B[36m1.1301\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.0940\u001B[0m  0.2588\n",
      "      8        \u001B[36m1.0718\u001B[0m       \u001B[32m0.6727\u001B[0m        \u001B[35m1.0528\u001B[0m  0.2567\n",
      "      9        \u001B[36m1.0313\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m1.0192\u001B[0m  0.2551\n",
      "     10        \u001B[36m0.9848\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9858\u001B[0m  0.2573\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2087\u001B[0m       \u001B[32m0.3802\u001B[0m        \u001B[35m1.6344\u001B[0m  0.2681\n",
      "      2        \u001B[36m1.7786\u001B[0m       \u001B[32m0.4909\u001B[0m        \u001B[35m1.4278\u001B[0m  0.2569\n",
      "      3        \u001B[36m1.5533\u001B[0m       \u001B[32m0.5455\u001B[0m        \u001B[35m1.3075\u001B[0m  0.2551\n",
      "      4        \u001B[36m1.4536\u001B[0m       \u001B[32m0.5736\u001B[0m        \u001B[35m1.2213\u001B[0m  0.2534\n",
      "      5        \u001B[36m1.3009\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.1649\u001B[0m  0.2551\n",
      "      6        \u001B[36m1.2410\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.1112\u001B[0m  0.2647\n",
      "      7        \u001B[36m1.1869\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.0679\u001B[0m  0.2683\n",
      "      8        \u001B[36m1.1083\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0325\u001B[0m  0.2710\n",
      "      9        \u001B[36m1.0672\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m0.9970\u001B[0m  0.2614\n",
      "     10        \u001B[36m1.0198\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9665\u001B[0m  0.2782\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1560\u001B[0m       \u001B[32m0.4149\u001B[0m        \u001B[35m1.5955\u001B[0m  0.2706\n",
      "      2        \u001B[36m1.6669\u001B[0m       \u001B[32m0.4893\u001B[0m        \u001B[35m1.4025\u001B[0m  0.2577\n",
      "      3        \u001B[36m1.4946\u001B[0m       \u001B[32m0.5537\u001B[0m        \u001B[35m1.2826\u001B[0m  0.2580\n",
      "      4        \u001B[36m1.3771\u001B[0m       \u001B[32m0.6116\u001B[0m        \u001B[35m1.1996\u001B[0m  0.2520\n",
      "      5        \u001B[36m1.2572\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1467\u001B[0m  0.2569\n",
      "      6        \u001B[36m1.1688\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.1008\u001B[0m  0.2525\n",
      "      7        \u001B[36m1.1167\u001B[0m       \u001B[32m0.6678\u001B[0m        \u001B[35m1.0650\u001B[0m  0.2606\n",
      "      8        \u001B[36m1.0555\u001B[0m       \u001B[32m0.6760\u001B[0m        \u001B[35m1.0334\u001B[0m  0.2550\n",
      "      9        \u001B[36m1.0048\u001B[0m       \u001B[32m0.7008\u001B[0m        \u001B[35m1.0022\u001B[0m  0.2576\n",
      "     10        \u001B[36m0.9777\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.9691\u001B[0m  0.2545\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3402\u001B[0m       \u001B[32m0.3372\u001B[0m        \u001B[35m1.7006\u001B[0m  0.2587\n",
      "      2        \u001B[36m1.8042\u001B[0m       \u001B[32m0.4529\u001B[0m        \u001B[35m1.4864\u001B[0m  0.2394\n",
      "      3        \u001B[36m1.5573\u001B[0m       \u001B[32m0.4959\u001B[0m        \u001B[35m1.3597\u001B[0m  0.2412\n",
      "      4        \u001B[36m1.4201\u001B[0m       \u001B[32m0.5455\u001B[0m        \u001B[35m1.2719\u001B[0m  0.2381\n",
      "      5        \u001B[36m1.3036\u001B[0m       \u001B[32m0.5785\u001B[0m        \u001B[35m1.1963\u001B[0m  0.2413\n",
      "      6        \u001B[36m1.2802\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.1459\u001B[0m  0.2397\n",
      "      7        \u001B[36m1.1824\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.0926\u001B[0m  0.2410\n",
      "      8        \u001B[36m1.1148\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0480\u001B[0m  0.2421\n",
      "      9        \u001B[36m1.0573\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0134\u001B[0m  0.2424\n",
      "     10        \u001B[36m1.0128\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9850\u001B[0m  0.2387\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1867\u001B[0m       \u001B[32m0.4231\u001B[0m        \u001B[35m1.4781\u001B[0m  0.2375\n",
      "      2        \u001B[36m1.6593\u001B[0m       \u001B[32m0.4744\u001B[0m        \u001B[35m1.3208\u001B[0m  0.2318\n",
      "      3        \u001B[36m1.4682\u001B[0m       \u001B[32m0.5669\u001B[0m        \u001B[35m1.2137\u001B[0m  0.2327\n",
      "      4        \u001B[36m1.3868\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.1397\u001B[0m  0.2328\n",
      "      5        \u001B[36m1.2206\u001B[0m       \u001B[32m0.6198\u001B[0m        \u001B[35m1.0855\u001B[0m  0.2371\n",
      "      6        \u001B[36m1.1724\u001B[0m       \u001B[32m0.6446\u001B[0m        \u001B[35m1.0382\u001B[0m  0.2335\n",
      "      7        \u001B[36m1.0824\u001B[0m       \u001B[32m0.6678\u001B[0m        \u001B[35m0.9996\u001B[0m  0.2609\n",
      "      8        \u001B[36m1.0443\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9683\u001B[0m  0.2380\n",
      "      9        \u001B[36m0.9828\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9449\u001B[0m  0.2339\n",
      "     10        \u001B[36m0.9395\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9203\u001B[0m  0.2349\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0927\u001B[0m       \u001B[32m0.4165\u001B[0m        \u001B[35m1.5727\u001B[0m  0.2541\n",
      "      2        \u001B[36m1.6194\u001B[0m       \u001B[32m0.5223\u001B[0m        \u001B[35m1.3727\u001B[0m  0.2487\n",
      "      3        \u001B[36m1.4492\u001B[0m       \u001B[32m0.5835\u001B[0m        \u001B[35m1.2534\u001B[0m  0.2481\n",
      "      4        \u001B[36m1.3345\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.1870\u001B[0m  0.2455\n",
      "      5        \u001B[36m1.1964\u001B[0m       \u001B[32m0.6397\u001B[0m        \u001B[35m1.1186\u001B[0m  0.2473\n",
      "      6        \u001B[36m1.1119\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.0714\u001B[0m  0.2442\n",
      "      7        \u001B[36m1.0637\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0275\u001B[0m  0.2484\n",
      "      8        \u001B[36m0.9980\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m0.9952\u001B[0m  0.2452\n",
      "      9        \u001B[36m0.9491\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.9633\u001B[0m  0.2478\n",
      "     10        \u001B[36m0.9342\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.9423\u001B[0m  0.2452\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2147\u001B[0m       \u001B[32m0.4215\u001B[0m        \u001B[35m1.5283\u001B[0m  0.2519\n",
      "      2        \u001B[36m1.7129\u001B[0m       \u001B[32m0.5041\u001B[0m        \u001B[35m1.3110\u001B[0m  0.2453\n",
      "      3        \u001B[36m1.5249\u001B[0m       \u001B[32m0.5636\u001B[0m        \u001B[35m1.1976\u001B[0m  0.2492\n",
      "      4        \u001B[36m1.3381\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.1111\u001B[0m  0.2467\n",
      "      5        \u001B[36m1.2626\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.0597\u001B[0m  0.2474\n",
      "      6        \u001B[36m1.1737\u001B[0m       \u001B[32m0.6760\u001B[0m        \u001B[35m1.0058\u001B[0m  0.2445\n",
      "      7        \u001B[36m1.0888\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m0.9655\u001B[0m  0.2479\n",
      "      8        \u001B[36m1.0363\u001B[0m       0.6942        \u001B[35m0.9333\u001B[0m  0.2480\n",
      "      9        \u001B[36m0.9630\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m0.9030\u001B[0m  0.2440\n",
      "     10        \u001B[36m0.9376\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m0.8733\u001B[0m  0.2389\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8889\u001B[0m       \u001B[32m0.4711\u001B[0m        \u001B[35m1.5257\u001B[0m  0.2504\n",
      "      2        \u001B[36m1.4501\u001B[0m       \u001B[32m0.5570\u001B[0m        \u001B[35m1.3178\u001B[0m  0.2754\n",
      "      3        \u001B[36m1.2738\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.2084\u001B[0m  0.2572\n",
      "      4        \u001B[36m1.1533\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.1374\u001B[0m  0.2816\n",
      "      5        \u001B[36m1.0489\u001B[0m       \u001B[32m0.6810\u001B[0m        \u001B[35m1.0720\u001B[0m  0.2509\n",
      "      6        \u001B[36m0.9660\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m1.0304\u001B[0m  0.2828\n",
      "      7        \u001B[36m0.9094\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9862\u001B[0m  0.2959\n",
      "      8        \u001B[36m0.8448\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.9567\u001B[0m  0.2710\n",
      "      9        \u001B[36m0.8041\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.9255\u001B[0m  0.2710\n",
      "     10        \u001B[36m0.7726\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.9051\u001B[0m  0.2591\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0179\u001B[0m       \u001B[32m0.4364\u001B[0m        \u001B[35m1.5184\u001B[0m  0.2650\n",
      "      2        \u001B[36m1.5122\u001B[0m       \u001B[32m0.5372\u001B[0m        \u001B[35m1.3069\u001B[0m  0.2806\n",
      "      3        \u001B[36m1.3197\u001B[0m       \u001B[32m0.5818\u001B[0m        \u001B[35m1.1879\u001B[0m  0.2490\n",
      "      4        \u001B[36m1.1748\u001B[0m       \u001B[32m0.6347\u001B[0m        \u001B[35m1.0999\u001B[0m  0.2540\n",
      "      5        \u001B[36m1.0603\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0402\u001B[0m  0.2580\n",
      "      6        \u001B[36m0.9737\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m0.9842\u001B[0m  0.2289\n",
      "      7        \u001B[36m0.9032\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9503\u001B[0m  0.2572\n",
      "      8        \u001B[36m0.8733\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9026\u001B[0m  0.2332\n",
      "      9        \u001B[36m0.8095\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8757\u001B[0m  0.2519\n",
      "     10        \u001B[36m0.7634\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8530\u001B[0m  0.2288\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0375\u001B[0m       \u001B[32m0.4380\u001B[0m        \u001B[35m1.5462\u001B[0m  0.2501\n",
      "      2        \u001B[36m1.4862\u001B[0m       \u001B[32m0.5488\u001B[0m        \u001B[35m1.3324\u001B[0m  0.2471\n",
      "      3        \u001B[36m1.3049\u001B[0m       \u001B[32m0.5934\u001B[0m        \u001B[35m1.2097\u001B[0m  0.2509\n",
      "      4        \u001B[36m1.1518\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.1262\u001B[0m  0.2456\n",
      "      5        \u001B[36m1.0661\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0531\u001B[0m  0.2438\n",
      "      6        \u001B[36m0.9788\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0066\u001B[0m  0.2507\n",
      "      7        \u001B[36m0.9352\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9747\u001B[0m  0.2464\n",
      "      8        \u001B[36m0.8577\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9417\u001B[0m  0.2559\n",
      "      9        \u001B[36m0.8085\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.9134\u001B[0m  0.2482\n",
      "     10        \u001B[36m0.7703\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8855\u001B[0m  0.2466\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0495\u001B[0m       \u001B[32m0.4281\u001B[0m        \u001B[35m1.5001\u001B[0m  0.2582\n",
      "      2        \u001B[36m1.5025\u001B[0m       \u001B[32m0.5455\u001B[0m        \u001B[35m1.2936\u001B[0m  0.2535\n",
      "      3        \u001B[36m1.2786\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.1699\u001B[0m  0.2441\n",
      "      4        \u001B[36m1.1641\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0845\u001B[0m  0.2876\n",
      "      5        \u001B[36m1.0703\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m1.0218\u001B[0m  0.2667\n",
      "      6        \u001B[36m0.9688\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m0.9812\u001B[0m  0.2527\n",
      "      7        \u001B[36m0.8950\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.9442\u001B[0m  0.2431\n",
      "      8        \u001B[36m0.8618\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.9131\u001B[0m  0.2820\n",
      "      9        \u001B[36m0.8111\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.8876\u001B[0m  0.2536\n",
      "     10        \u001B[36m0.7593\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8608\u001B[0m  0.2518\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9956\u001B[0m       \u001B[32m0.4529\u001B[0m        \u001B[35m1.4934\u001B[0m  0.2519\n",
      "      2        \u001B[36m1.5307\u001B[0m       \u001B[32m0.5504\u001B[0m        \u001B[35m1.2889\u001B[0m  0.2445\n",
      "      3        \u001B[36m1.2881\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.1663\u001B[0m  0.2424\n",
      "      4        \u001B[36m1.1509\u001B[0m       \u001B[32m0.6347\u001B[0m        \u001B[35m1.0886\u001B[0m  0.2417\n",
      "      5        \u001B[36m1.0505\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0231\u001B[0m  0.2393\n",
      "      6        \u001B[36m0.9686\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9748\u001B[0m  0.2435\n",
      "      7        \u001B[36m0.8983\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9465\u001B[0m  0.2429\n",
      "      8        \u001B[36m0.8586\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.9095\u001B[0m  0.2457\n",
      "      9        \u001B[36m0.8073\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.8853\u001B[0m  0.2413\n",
      "     10        \u001B[36m0.7623\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8530\u001B[0m  0.2422\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0167\u001B[0m       \u001B[32m0.4595\u001B[0m        \u001B[35m1.5142\u001B[0m  0.2497\n",
      "      2        \u001B[36m1.5098\u001B[0m       \u001B[32m0.5603\u001B[0m        \u001B[35m1.3171\u001B[0m  0.2451\n",
      "      3        \u001B[36m1.3121\u001B[0m       \u001B[32m0.6116\u001B[0m        \u001B[35m1.1910\u001B[0m  0.2422\n",
      "      4        \u001B[36m1.1634\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.1115\u001B[0m  0.2468\n",
      "      5        \u001B[36m1.0703\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0450\u001B[0m  0.2432\n",
      "      6        \u001B[36m0.9920\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m0.9923\u001B[0m  0.2457\n",
      "      7        \u001B[36m0.8962\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.9459\u001B[0m  0.2426\n",
      "      8        \u001B[36m0.8323\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.9115\u001B[0m  0.2424\n",
      "      9        \u001B[36m0.8034\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.8838\u001B[0m  0.2415\n",
      "     10        \u001B[36m0.7510\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.8580\u001B[0m  0.2436\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0438\u001B[0m       \u001B[32m0.4612\u001B[0m        \u001B[35m1.4116\u001B[0m  0.2476\n",
      "      2        \u001B[36m1.4535\u001B[0m       \u001B[32m0.6066\u001B[0m        \u001B[35m1.1747\u001B[0m  0.2433\n",
      "      3        \u001B[36m1.2680\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0635\u001B[0m  0.2437\n",
      "      4        \u001B[36m1.0897\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9804\u001B[0m  0.2420\n",
      "      5        \u001B[36m0.9847\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.9348\u001B[0m  0.2409\n",
      "      6        \u001B[36m0.9378\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8904\u001B[0m  0.2446\n",
      "      7        \u001B[36m0.8424\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8721\u001B[0m  0.2408\n",
      "      8        \u001B[36m0.7985\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.8388\u001B[0m  0.2476\n",
      "      9        \u001B[36m0.7544\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.8238\u001B[0m  0.2435\n",
      "     10        \u001B[36m0.7173\u001B[0m       0.7736        \u001B[35m0.8068\u001B[0m  0.2570\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8826\u001B[0m       \u001B[32m0.5240\u001B[0m        \u001B[35m1.4184\u001B[0m  0.2673\n",
      "      2        \u001B[36m1.4497\u001B[0m       \u001B[32m0.5785\u001B[0m        \u001B[35m1.2272\u001B[0m  0.2543\n",
      "      3        \u001B[36m1.2031\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.1116\u001B[0m  0.2527\n",
      "      4        \u001B[36m1.0693\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.0378\u001B[0m  0.2536\n",
      "      5        \u001B[36m0.9962\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m0.9711\u001B[0m  0.2395\n",
      "      6        \u001B[36m0.9081\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.9294\u001B[0m  0.2434\n",
      "      7        \u001B[36m0.8243\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.8931\u001B[0m  0.2410\n",
      "      8        \u001B[36m0.7943\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.8570\u001B[0m  0.2437\n",
      "      9        \u001B[36m0.7284\u001B[0m       \u001B[32m0.7587\u001B[0m        \u001B[35m0.8334\u001B[0m  0.2420\n",
      "     10        \u001B[36m0.6942\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.8133\u001B[0m  0.2433\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8009\u001B[0m       \u001B[32m0.5074\u001B[0m        \u001B[35m1.3200\u001B[0m  0.2532\n",
      "      2        \u001B[36m1.4094\u001B[0m       \u001B[32m0.5917\u001B[0m        \u001B[35m1.1613\u001B[0m  0.2435\n",
      "      3        \u001B[36m1.2219\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.0651\u001B[0m  0.2448\n",
      "      4        \u001B[36m1.0945\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m0.9980\u001B[0m  0.2419\n",
      "      5        \u001B[36m0.9849\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.9504\u001B[0m  0.2436\n",
      "      6        \u001B[36m0.8862\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.9138\u001B[0m  0.2414\n",
      "      7        \u001B[36m0.8681\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8726\u001B[0m  0.2450\n",
      "      8        \u001B[36m0.8025\u001B[0m       0.7405        \u001B[35m0.8440\u001B[0m  0.2441\n",
      "      9        \u001B[36m0.7314\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.8269\u001B[0m  0.2409\n",
      "     10        \u001B[36m0.7094\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.8022\u001B[0m  0.2445\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3824\u001B[0m       \u001B[32m0.2463\u001B[0m        \u001B[35m1.7746\u001B[0m  0.2547\n",
      "      2        \u001B[36m2.0206\u001B[0m       \u001B[32m0.3620\u001B[0m        \u001B[35m1.6317\u001B[0m  0.2499\n",
      "      3        \u001B[36m1.8358\u001B[0m       \u001B[32m0.4397\u001B[0m        \u001B[35m1.5137\u001B[0m  0.2452\n",
      "      4        \u001B[36m1.7061\u001B[0m       \u001B[32m0.4744\u001B[0m        \u001B[35m1.4320\u001B[0m  0.2506\n",
      "      5        \u001B[36m1.6201\u001B[0m       \u001B[32m0.5124\u001B[0m        \u001B[35m1.3678\u001B[0m  0.2464\n",
      "      6        \u001B[36m1.5346\u001B[0m       \u001B[32m0.5322\u001B[0m        \u001B[35m1.3171\u001B[0m  0.2513\n",
      "      7        \u001B[36m1.4846\u001B[0m       \u001B[32m0.5471\u001B[0m        \u001B[35m1.2721\u001B[0m  0.2556\n",
      "      8        \u001B[36m1.3963\u001B[0m       \u001B[32m0.5603\u001B[0m        \u001B[35m1.2347\u001B[0m  0.2493\n",
      "      9        \u001B[36m1.3851\u001B[0m       \u001B[32m0.5736\u001B[0m        \u001B[35m1.2040\u001B[0m  0.2468\n",
      "     10        \u001B[36m1.3422\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.1740\u001B[0m  0.2525\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4511\u001B[0m       \u001B[32m0.2926\u001B[0m        \u001B[35m1.8543\u001B[0m  0.2598\n",
      "      2        \u001B[36m2.0802\u001B[0m       \u001B[32m0.3719\u001B[0m        \u001B[35m1.7103\u001B[0m  0.2719\n",
      "      3        \u001B[36m1.8725\u001B[0m       \u001B[32m0.4083\u001B[0m        \u001B[35m1.5978\u001B[0m  0.2574\n",
      "      4        \u001B[36m1.7867\u001B[0m       \u001B[32m0.4364\u001B[0m        \u001B[35m1.5144\u001B[0m  0.2504\n",
      "      5        \u001B[36m1.6814\u001B[0m       \u001B[32m0.4793\u001B[0m        \u001B[35m1.4438\u001B[0m  0.2527\n",
      "      6        \u001B[36m1.5958\u001B[0m       \u001B[32m0.4992\u001B[0m        \u001B[35m1.3923\u001B[0m  0.2470\n",
      "      7        \u001B[36m1.5245\u001B[0m       \u001B[32m0.5355\u001B[0m        \u001B[35m1.3506\u001B[0m  0.2515\n",
      "      8        \u001B[36m1.4807\u001B[0m       \u001B[32m0.5438\u001B[0m        \u001B[35m1.3067\u001B[0m  0.2515\n",
      "      9        \u001B[36m1.4273\u001B[0m       \u001B[32m0.5636\u001B[0m        \u001B[35m1.2666\u001B[0m  0.2514\n",
      "     10        \u001B[36m1.3677\u001B[0m       \u001B[32m0.5884\u001B[0m        \u001B[35m1.2434\u001B[0m  0.2520\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3669\u001B[0m       \u001B[32m0.2810\u001B[0m        \u001B[35m1.8577\u001B[0m  0.2599\n",
      "      2        \u001B[36m2.0830\u001B[0m       \u001B[32m0.3702\u001B[0m        \u001B[35m1.7215\u001B[0m  0.2491\n",
      "      3        \u001B[36m1.9112\u001B[0m       \u001B[32m0.4215\u001B[0m        \u001B[35m1.5950\u001B[0m  0.2490\n",
      "      4        \u001B[36m1.7422\u001B[0m       \u001B[32m0.4678\u001B[0m        \u001B[35m1.5041\u001B[0m  0.2500\n",
      "      5        \u001B[36m1.7222\u001B[0m       \u001B[32m0.5058\u001B[0m        \u001B[35m1.4300\u001B[0m  0.2516\n",
      "      6        \u001B[36m1.6065\u001B[0m       \u001B[32m0.5388\u001B[0m        \u001B[35m1.3742\u001B[0m  0.2474\n",
      "      7        \u001B[36m1.5384\u001B[0m       \u001B[32m0.5620\u001B[0m        \u001B[35m1.3202\u001B[0m  0.2495\n",
      "      8        \u001B[36m1.4635\u001B[0m       \u001B[32m0.5917\u001B[0m        \u001B[35m1.2787\u001B[0m  0.2477\n",
      "      9        \u001B[36m1.4305\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.2484\u001B[0m  0.2490\n",
      "     10        \u001B[36m1.3629\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.2163\u001B[0m  0.2468\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.5102\u001B[0m       \u001B[32m0.3008\u001B[0m        \u001B[35m1.8215\u001B[0m  0.2527\n",
      "      2        \u001B[36m2.1058\u001B[0m       \u001B[32m0.3587\u001B[0m        \u001B[35m1.6593\u001B[0m  0.2455\n",
      "      3        \u001B[36m1.8975\u001B[0m       \u001B[32m0.4099\u001B[0m        \u001B[35m1.5263\u001B[0m  0.2466\n",
      "      4        \u001B[36m1.8200\u001B[0m       \u001B[32m0.4628\u001B[0m        \u001B[35m1.4489\u001B[0m  0.2417\n",
      "      5        \u001B[36m1.7211\u001B[0m       \u001B[32m0.4926\u001B[0m        \u001B[35m1.3863\u001B[0m  0.2418\n",
      "      6        \u001B[36m1.5878\u001B[0m       \u001B[32m0.5190\u001B[0m        \u001B[35m1.3407\u001B[0m  0.2391\n",
      "      7        \u001B[36m1.5137\u001B[0m       \u001B[32m0.5504\u001B[0m        \u001B[35m1.2971\u001B[0m  0.2441\n",
      "      8        \u001B[36m1.4733\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.2642\u001B[0m  0.2413\n",
      "      9        \u001B[36m1.4185\u001B[0m       \u001B[32m0.6099\u001B[0m        \u001B[35m1.2307\u001B[0m  0.2466\n",
      "     10        \u001B[36m1.3792\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.1965\u001B[0m  0.2421\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4360\u001B[0m       \u001B[32m0.2810\u001B[0m        \u001B[35m1.8445\u001B[0m  0.2515\n",
      "      2        \u001B[36m2.0769\u001B[0m       \u001B[32m0.4099\u001B[0m        \u001B[35m1.6694\u001B[0m  0.2539\n",
      "      3        \u001B[36m1.8510\u001B[0m       \u001B[32m0.4595\u001B[0m        \u001B[35m1.5410\u001B[0m  0.2587\n",
      "      4        \u001B[36m1.7659\u001B[0m       \u001B[32m0.5157\u001B[0m        \u001B[35m1.4473\u001B[0m  0.2603\n",
      "      5        \u001B[36m1.6455\u001B[0m       \u001B[32m0.5570\u001B[0m        \u001B[35m1.3738\u001B[0m  0.2569\n",
      "      6        \u001B[36m1.5446\u001B[0m       \u001B[32m0.5802\u001B[0m        \u001B[35m1.3211\u001B[0m  0.2582\n",
      "      7        \u001B[36m1.5055\u001B[0m       \u001B[32m0.6066\u001B[0m        \u001B[35m1.2732\u001B[0m  0.2457\n",
      "      8        \u001B[36m1.4455\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.2286\u001B[0m  0.2490\n",
      "      9        \u001B[36m1.3438\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1968\u001B[0m  0.2497\n",
      "     10        \u001B[36m1.3199\u001B[0m       \u001B[32m0.6397\u001B[0m        \u001B[35m1.1688\u001B[0m  0.2461\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2962\u001B[0m       \u001B[32m0.3736\u001B[0m        \u001B[35m1.6217\u001B[0m  0.2513\n",
      "      2        \u001B[36m1.9945\u001B[0m       \u001B[32m0.4380\u001B[0m        \u001B[35m1.4777\u001B[0m  0.2421\n",
      "      3        \u001B[36m1.8496\u001B[0m       \u001B[32m0.4843\u001B[0m        \u001B[35m1.3775\u001B[0m  0.2470\n",
      "      4        \u001B[36m1.7075\u001B[0m       \u001B[32m0.5207\u001B[0m        \u001B[35m1.3093\u001B[0m  0.2518\n",
      "      5        \u001B[36m1.6788\u001B[0m       \u001B[32m0.5537\u001B[0m        \u001B[35m1.2514\u001B[0m  0.2472\n",
      "      6        \u001B[36m1.6023\u001B[0m       \u001B[32m0.5686\u001B[0m        \u001B[35m1.2053\u001B[0m  0.2411\n",
      "      7        \u001B[36m1.5206\u001B[0m       \u001B[32m0.5934\u001B[0m        \u001B[35m1.1686\u001B[0m  0.2427\n",
      "      8        \u001B[36m1.4258\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.1316\u001B[0m  0.2424\n",
      "      9        \u001B[36m1.3937\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.1055\u001B[0m  0.2448\n",
      "     10        \u001B[36m1.3604\u001B[0m       \u001B[32m0.6364\u001B[0m        \u001B[35m1.0773\u001B[0m  0.2444\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.5253\u001B[0m       \u001B[32m0.3570\u001B[0m        \u001B[35m1.7070\u001B[0m  0.2513\n",
      "      2        \u001B[36m2.1743\u001B[0m       \u001B[32m0.4281\u001B[0m        \u001B[35m1.5438\u001B[0m  0.2440\n",
      "      3        \u001B[36m1.9297\u001B[0m       \u001B[32m0.4661\u001B[0m        \u001B[35m1.4313\u001B[0m  0.2418\n",
      "      4        \u001B[36m1.8357\u001B[0m       \u001B[32m0.5091\u001B[0m        \u001B[35m1.3483\u001B[0m  0.2440\n",
      "      5        \u001B[36m1.7217\u001B[0m       \u001B[32m0.5438\u001B[0m        \u001B[35m1.2879\u001B[0m  0.2441\n",
      "      6        \u001B[36m1.6242\u001B[0m       \u001B[32m0.5835\u001B[0m        \u001B[35m1.2348\u001B[0m  0.2444\n",
      "      7        \u001B[36m1.5537\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1847\u001B[0m  0.2460\n",
      "      8        \u001B[36m1.4277\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.1541\u001B[0m  0.2439\n",
      "      9        1.4312       \u001B[32m0.6562\u001B[0m        \u001B[35m1.1103\u001B[0m  0.2406\n",
      "     10        \u001B[36m1.3845\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0852\u001B[0m  0.2432\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4122\u001B[0m       \u001B[32m0.3587\u001B[0m        \u001B[35m1.7080\u001B[0m  0.2513\n",
      "      2        \u001B[36m2.0291\u001B[0m       \u001B[32m0.4264\u001B[0m        \u001B[35m1.5664\u001B[0m  0.2441\n",
      "      3        \u001B[36m1.8017\u001B[0m       \u001B[32m0.4645\u001B[0m        \u001B[35m1.4478\u001B[0m  0.2461\n",
      "      4        \u001B[36m1.7304\u001B[0m       \u001B[32m0.5240\u001B[0m        \u001B[35m1.3686\u001B[0m  0.2464\n",
      "      5        \u001B[36m1.6106\u001B[0m       \u001B[32m0.5653\u001B[0m        \u001B[35m1.2979\u001B[0m  0.2563\n",
      "      6        \u001B[36m1.5430\u001B[0m       \u001B[32m0.5950\u001B[0m        \u001B[35m1.2574\u001B[0m  0.2534\n",
      "      7        \u001B[36m1.5134\u001B[0m       0.5950        \u001B[35m1.2208\u001B[0m  0.2415\n",
      "      8        \u001B[36m1.4246\u001B[0m       \u001B[32m0.6264\u001B[0m        \u001B[35m1.1743\u001B[0m  0.2403\n",
      "      9        \u001B[36m1.3506\u001B[0m       \u001B[32m0.6430\u001B[0m        \u001B[35m1.1402\u001B[0m  0.2452\n",
      "     10        \u001B[36m1.3262\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.1130\u001B[0m  0.2421\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.6569\u001B[0m       \u001B[32m0.2810\u001B[0m        \u001B[35m1.7688\u001B[0m  0.2492\n",
      "      2        \u001B[36m2.0442\u001B[0m       \u001B[32m0.4264\u001B[0m        \u001B[35m1.5702\u001B[0m  0.2441\n",
      "      3        \u001B[36m1.8961\u001B[0m       \u001B[32m0.4727\u001B[0m        \u001B[35m1.4570\u001B[0m  0.2438\n",
      "      4        \u001B[36m1.7791\u001B[0m       \u001B[32m0.5058\u001B[0m        \u001B[35m1.3836\u001B[0m  0.2423\n",
      "      5        \u001B[36m1.6302\u001B[0m       \u001B[32m0.5355\u001B[0m        \u001B[35m1.3217\u001B[0m  0.2441\n",
      "      6        \u001B[36m1.5730\u001B[0m       \u001B[32m0.5603\u001B[0m        \u001B[35m1.2792\u001B[0m  0.2442\n",
      "      7        \u001B[36m1.4806\u001B[0m       \u001B[32m0.5785\u001B[0m        \u001B[35m1.2405\u001B[0m  0.2417\n",
      "      8        \u001B[36m1.4370\u001B[0m       \u001B[32m0.6000\u001B[0m        \u001B[35m1.2035\u001B[0m  0.2417\n",
      "      9        \u001B[36m1.4061\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.1751\u001B[0m  0.2420\n",
      "     10        \u001B[36m1.3192\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.1540\u001B[0m  0.2435\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2220\u001B[0m       \u001B[32m0.3107\u001B[0m        \u001B[35m1.6643\u001B[0m  0.2577\n",
      "      2        \u001B[36m1.9226\u001B[0m       \u001B[32m0.4215\u001B[0m        \u001B[35m1.5009\u001B[0m  0.2488\n",
      "      3        \u001B[36m1.6686\u001B[0m       \u001B[32m0.4727\u001B[0m        \u001B[35m1.3856\u001B[0m  0.2457\n",
      "      4        \u001B[36m1.5571\u001B[0m       \u001B[32m0.5190\u001B[0m        \u001B[35m1.3075\u001B[0m  0.2488\n",
      "      5        \u001B[36m1.4506\u001B[0m       \u001B[32m0.5620\u001B[0m        \u001B[35m1.2432\u001B[0m  0.2475\n",
      "      6        \u001B[36m1.3384\u001B[0m       \u001B[32m0.5934\u001B[0m        \u001B[35m1.1933\u001B[0m  0.2477\n",
      "      7        \u001B[36m1.3007\u001B[0m       \u001B[32m0.6215\u001B[0m        \u001B[35m1.1521\u001B[0m  0.2476\n",
      "      8        \u001B[36m1.2205\u001B[0m       \u001B[32m0.6562\u001B[0m        \u001B[35m1.1130\u001B[0m  0.2440\n",
      "      9        \u001B[36m1.1726\u001B[0m       0.6562        \u001B[35m1.0808\u001B[0m  0.2487\n",
      "     10        \u001B[36m1.1293\u001B[0m       \u001B[32m0.6810\u001B[0m        \u001B[35m1.0492\u001B[0m  0.2496\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2896\u001B[0m       \u001B[32m0.3041\u001B[0m        \u001B[35m1.7362\u001B[0m  0.2524\n",
      "      2        \u001B[36m1.8862\u001B[0m       \u001B[32m0.4512\u001B[0m        \u001B[35m1.5793\u001B[0m  0.2482\n",
      "      3        \u001B[36m1.6865\u001B[0m       \u001B[32m0.4860\u001B[0m        \u001B[35m1.4493\u001B[0m  0.2482\n",
      "      4        \u001B[36m1.5579\u001B[0m       \u001B[32m0.5256\u001B[0m        \u001B[35m1.3613\u001B[0m  0.2542\n",
      "      5        \u001B[36m1.4603\u001B[0m       \u001B[32m0.5603\u001B[0m        \u001B[35m1.2952\u001B[0m  0.2590\n",
      "      6        \u001B[36m1.3658\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.2377\u001B[0m  0.2674\n",
      "      7        \u001B[36m1.2989\u001B[0m       \u001B[32m0.5950\u001B[0m        \u001B[35m1.1953\u001B[0m  0.2595\n",
      "      8        \u001B[36m1.2373\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.1499\u001B[0m  0.2675\n",
      "      9        \u001B[36m1.1762\u001B[0m       \u001B[32m0.6198\u001B[0m        \u001B[35m1.1224\u001B[0m  0.2560\n",
      "     10        \u001B[36m1.1628\u001B[0m       \u001B[32m0.6364\u001B[0m        \u001B[35m1.0758\u001B[0m  0.2485\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4390\u001B[0m       \u001B[32m0.2711\u001B[0m        \u001B[35m1.8474\u001B[0m  0.2584\n",
      "      2        \u001B[36m1.9978\u001B[0m       \u001B[32m0.4000\u001B[0m        \u001B[35m1.6397\u001B[0m  0.2503\n",
      "      3        \u001B[36m1.7411\u001B[0m       \u001B[32m0.4810\u001B[0m        \u001B[35m1.4892\u001B[0m  0.2489\n",
      "      4        \u001B[36m1.6513\u001B[0m       \u001B[32m0.5289\u001B[0m        \u001B[35m1.3900\u001B[0m  0.2448\n",
      "      5        \u001B[36m1.5306\u001B[0m       \u001B[32m0.5702\u001B[0m        \u001B[35m1.3108\u001B[0m  0.2444\n",
      "      6        \u001B[36m1.4099\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.2570\u001B[0m  0.2479\n",
      "      7        \u001B[36m1.3481\u001B[0m       \u001B[32m0.6066\u001B[0m        \u001B[35m1.2065\u001B[0m  0.2466\n",
      "      8        \u001B[36m1.2983\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.1696\u001B[0m  0.2471\n",
      "      9        \u001B[36m1.2510\u001B[0m       \u001B[32m0.6397\u001B[0m        \u001B[35m1.1372\u001B[0m  0.2481\n",
      "     10        \u001B[36m1.1929\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.1063\u001B[0m  0.2453\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3819\u001B[0m       \u001B[32m0.3388\u001B[0m        \u001B[35m1.6915\u001B[0m  0.2511\n",
      "      2        \u001B[36m1.8473\u001B[0m       \u001B[32m0.4281\u001B[0m        \u001B[35m1.5096\u001B[0m  0.2435\n",
      "      3        \u001B[36m1.7116\u001B[0m       \u001B[32m0.4959\u001B[0m        \u001B[35m1.3971\u001B[0m  0.2461\n",
      "      4        \u001B[36m1.6491\u001B[0m       \u001B[32m0.5339\u001B[0m        \u001B[35m1.3151\u001B[0m  0.2450\n",
      "      5        \u001B[36m1.4459\u001B[0m       \u001B[32m0.5702\u001B[0m        \u001B[35m1.2525\u001B[0m  0.2430\n",
      "      6        \u001B[36m1.3969\u001B[0m       \u001B[32m0.6050\u001B[0m        \u001B[35m1.2010\u001B[0m  0.2465\n",
      "      7        \u001B[36m1.3283\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.1635\u001B[0m  0.2450\n",
      "      8        \u001B[36m1.2506\u001B[0m       \u001B[32m0.6512\u001B[0m        \u001B[35m1.1307\u001B[0m  0.2450\n",
      "      9        \u001B[36m1.1899\u001B[0m       \u001B[32m0.6777\u001B[0m        \u001B[35m1.0946\u001B[0m  0.2451\n",
      "     10        \u001B[36m1.1556\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m1.0676\u001B[0m  0.2450\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3170\u001B[0m       \u001B[32m0.3653\u001B[0m        \u001B[35m1.6579\u001B[0m  0.2546\n",
      "      2        \u001B[36m1.8953\u001B[0m       \u001B[32m0.4529\u001B[0m        \u001B[35m1.4963\u001B[0m  0.2452\n",
      "      3        \u001B[36m1.6741\u001B[0m       \u001B[32m0.5041\u001B[0m        \u001B[35m1.3825\u001B[0m  0.2444\n",
      "      4        \u001B[36m1.5696\u001B[0m       \u001B[32m0.5405\u001B[0m        \u001B[35m1.2942\u001B[0m  0.2437\n",
      "      5        \u001B[36m1.4415\u001B[0m       \u001B[32m0.5719\u001B[0m        \u001B[35m1.2301\u001B[0m  0.2465\n",
      "      6        \u001B[36m1.3577\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.1799\u001B[0m  0.2424\n",
      "      7        \u001B[36m1.3049\u001B[0m       \u001B[32m0.6182\u001B[0m        \u001B[35m1.1312\u001B[0m  0.2706\n",
      "      8        \u001B[36m1.2351\u001B[0m       \u001B[32m0.6430\u001B[0m        \u001B[35m1.0965\u001B[0m  0.2513\n",
      "      9        \u001B[36m1.1800\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0709\u001B[0m  0.2433\n",
      "     10        \u001B[36m1.1450\u001B[0m       \u001B[32m0.6744\u001B[0m        \u001B[35m1.0363\u001B[0m  0.2426\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3659\u001B[0m       \u001B[32m0.3124\u001B[0m        \u001B[35m1.7380\u001B[0m  0.2519\n",
      "      2        \u001B[36m1.9010\u001B[0m       \u001B[32m0.4347\u001B[0m        \u001B[35m1.5642\u001B[0m  0.2459\n",
      "      3        \u001B[36m1.7094\u001B[0m       \u001B[32m0.4942\u001B[0m        \u001B[35m1.4437\u001B[0m  0.2426\n",
      "      4        \u001B[36m1.5676\u001B[0m       \u001B[32m0.5190\u001B[0m        \u001B[35m1.3571\u001B[0m  0.2439\n",
      "      5        \u001B[36m1.4290\u001B[0m       \u001B[32m0.5438\u001B[0m        \u001B[35m1.2888\u001B[0m  0.2470\n",
      "      6        \u001B[36m1.3841\u001B[0m       \u001B[32m0.5868\u001B[0m        \u001B[35m1.2222\u001B[0m  0.2439\n",
      "      7        \u001B[36m1.2745\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.1848\u001B[0m  0.2415\n",
      "      8        \u001B[36m1.2177\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.1384\u001B[0m  0.2448\n",
      "      9        \u001B[36m1.1814\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1052\u001B[0m  0.2442\n",
      "     10        \u001B[36m1.1569\u001B[0m       \u001B[32m0.6512\u001B[0m        \u001B[35m1.0762\u001B[0m  0.2456\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4277\u001B[0m       \u001B[32m0.3934\u001B[0m        \u001B[35m1.6375\u001B[0m  0.2418\n",
      "      2        \u001B[36m1.8995\u001B[0m       \u001B[32m0.4777\u001B[0m        \u001B[35m1.4261\u001B[0m  0.2381\n",
      "      3        \u001B[36m1.6752\u001B[0m       \u001B[32m0.5207\u001B[0m        \u001B[35m1.3065\u001B[0m  0.2383\n",
      "      4        \u001B[36m1.5900\u001B[0m       \u001B[32m0.5818\u001B[0m        \u001B[35m1.2210\u001B[0m  0.2370\n",
      "      5        \u001B[36m1.4774\u001B[0m       \u001B[32m0.6165\u001B[0m        \u001B[35m1.1660\u001B[0m  0.2382\n",
      "      6        \u001B[36m1.3540\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.1106\u001B[0m  0.2392\n",
      "      7        \u001B[36m1.2590\u001B[0m       \u001B[32m0.6744\u001B[0m        \u001B[35m1.0630\u001B[0m  0.2387\n",
      "      8        \u001B[36m1.2007\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m1.0254\u001B[0m  0.2393\n",
      "      9        \u001B[36m1.1594\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m1.0052\u001B[0m  0.2403\n",
      "     10        \u001B[36m1.1383\u001B[0m       \u001B[32m0.7008\u001B[0m        \u001B[35m0.9738\u001B[0m  0.2411\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2873\u001B[0m       \u001B[32m0.4017\u001B[0m        \u001B[35m1.5693\u001B[0m  0.2441\n",
      "      2        \u001B[36m1.8121\u001B[0m       \u001B[32m0.4992\u001B[0m        \u001B[35m1.3840\u001B[0m  0.2354\n",
      "      3        \u001B[36m1.6231\u001B[0m       \u001B[32m0.5587\u001B[0m        \u001B[35m1.2706\u001B[0m  0.2367\n",
      "      4        \u001B[36m1.4744\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.1933\u001B[0m  0.2374\n",
      "      5        \u001B[36m1.4109\u001B[0m       \u001B[32m0.6215\u001B[0m        \u001B[35m1.1260\u001B[0m  0.2389\n",
      "      6        \u001B[36m1.2548\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.0777\u001B[0m  0.2454\n",
      "      7        \u001B[36m1.1941\u001B[0m       \u001B[32m0.6727\u001B[0m        \u001B[35m1.0550\u001B[0m  0.2512\n",
      "      8        \u001B[36m1.1676\u001B[0m       \u001B[32m0.6810\u001B[0m        \u001B[35m1.0191\u001B[0m  0.2495\n",
      "      9        \u001B[36m1.0824\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9892\u001B[0m  0.2595\n",
      "     10        \u001B[36m1.0446\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9538\u001B[0m  0.2468\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1444\u001B[0m       \u001B[32m0.4231\u001B[0m        \u001B[35m1.4742\u001B[0m  0.2709\n",
      "      2        \u001B[36m1.7695\u001B[0m       \u001B[32m0.5124\u001B[0m        \u001B[35m1.3075\u001B[0m  0.2479\n",
      "      3        \u001B[36m1.6483\u001B[0m       \u001B[32m0.5702\u001B[0m        \u001B[35m1.2086\u001B[0m  0.2384\n",
      "      4        \u001B[36m1.4555\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.1300\u001B[0m  0.2385\n",
      "      5        \u001B[36m1.3442\u001B[0m       \u001B[32m0.6347\u001B[0m        \u001B[35m1.0740\u001B[0m  0.2365\n",
      "      6        \u001B[36m1.2436\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.0372\u001B[0m  0.2384\n",
      "      7        \u001B[36m1.2066\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m0.9976\u001B[0m  0.2430\n",
      "      8        \u001B[36m1.1006\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m0.9651\u001B[0m  0.2364\n",
      "      9        \u001B[36m1.0685\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9354\u001B[0m  0.2416\n",
      "     10        \u001B[36m1.0528\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.9160\u001B[0m  0.2396\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2416\u001B[0m       \u001B[32m0.4017\u001B[0m        \u001B[35m1.5917\u001B[0m  0.2473\n",
      "      2        \u001B[36m1.6612\u001B[0m       \u001B[32m0.5223\u001B[0m        \u001B[35m1.3108\u001B[0m  0.2390\n",
      "      3        \u001B[36m1.4307\u001B[0m       \u001B[32m0.6000\u001B[0m        \u001B[35m1.1910\u001B[0m  0.2427\n",
      "      4        \u001B[36m1.2754\u001B[0m       \u001B[32m0.6397\u001B[0m        \u001B[35m1.1095\u001B[0m  0.2398\n",
      "      5        \u001B[36m1.1820\u001B[0m       \u001B[32m0.6661\u001B[0m        \u001B[35m1.0538\u001B[0m  0.2407\n",
      "      6        \u001B[36m1.1060\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m1.0119\u001B[0m  0.2374\n",
      "      7        \u001B[36m1.0224\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m0.9748\u001B[0m  0.2396\n",
      "      8        \u001B[36m0.9904\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.9338\u001B[0m  0.2395\n",
      "      9        \u001B[36m0.9202\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.9157\u001B[0m  0.2408\n",
      "     10        \u001B[36m0.8509\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.8936\u001B[0m  0.2396\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0632\u001B[0m       \u001B[32m0.4579\u001B[0m        \u001B[35m1.5255\u001B[0m  0.2501\n",
      "      2        \u001B[36m1.5798\u001B[0m       \u001B[32m0.5289\u001B[0m        \u001B[35m1.3283\u001B[0m  0.2391\n",
      "      3        \u001B[36m1.3963\u001B[0m       \u001B[32m0.5702\u001B[0m        \u001B[35m1.2085\u001B[0m  0.2421\n",
      "      4        \u001B[36m1.2684\u001B[0m       \u001B[32m0.6116\u001B[0m        \u001B[35m1.1339\u001B[0m  0.2372\n",
      "      5        \u001B[36m1.1640\u001B[0m       \u001B[32m0.6430\u001B[0m        \u001B[35m1.0716\u001B[0m  0.2392\n",
      "      6        \u001B[36m1.0574\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.0214\u001B[0m  0.2383\n",
      "      7        \u001B[36m1.0205\u001B[0m       \u001B[32m0.6810\u001B[0m        \u001B[35m0.9752\u001B[0m  0.2670\n",
      "      8        \u001B[36m0.9624\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m0.9497\u001B[0m  0.2502\n",
      "      9        \u001B[36m0.9213\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9129\u001B[0m  0.2388\n",
      "     10        \u001B[36m0.8669\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.8963\u001B[0m  0.2395\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1046\u001B[0m       \u001B[32m0.4314\u001B[0m        \u001B[35m1.5529\u001B[0m  0.2468\n",
      "      2        \u001B[36m1.6047\u001B[0m       \u001B[32m0.5653\u001B[0m        \u001B[35m1.3114\u001B[0m  0.2417\n",
      "      3        \u001B[36m1.3946\u001B[0m       \u001B[32m0.6347\u001B[0m        \u001B[35m1.1966\u001B[0m  0.2401\n",
      "      4        \u001B[36m1.2500\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.1097\u001B[0m  0.2402\n",
      "      5        \u001B[36m1.1470\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m1.0465\u001B[0m  0.2420\n",
      "      6        \u001B[36m1.0714\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m0.9949\u001B[0m  0.2388\n",
      "      7        \u001B[36m0.9897\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.9579\u001B[0m  0.2425\n",
      "      8        \u001B[36m0.9412\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.9213\u001B[0m  0.2403\n",
      "      9        \u001B[36m0.8907\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.8923\u001B[0m  0.2398\n",
      "     10        \u001B[36m0.8812\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8684\u001B[0m  0.2418\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0482\u001B[0m       \u001B[32m0.4926\u001B[0m        \u001B[35m1.4317\u001B[0m  0.2512\n",
      "      2        \u001B[36m1.6009\u001B[0m       \u001B[32m0.5554\u001B[0m        \u001B[35m1.2518\u001B[0m  0.2429\n",
      "      3        \u001B[36m1.3678\u001B[0m       \u001B[32m0.6264\u001B[0m        \u001B[35m1.1539\u001B[0m  0.2481\n",
      "      4        \u001B[36m1.2464\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.0807\u001B[0m  0.2467\n",
      "      5        \u001B[36m1.1545\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m1.0284\u001B[0m  0.2455\n",
      "      6        \u001B[36m1.0714\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.9907\u001B[0m  0.2448\n",
      "      7        \u001B[36m1.0037\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.9513\u001B[0m  0.2424\n",
      "      8        \u001B[36m0.9728\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.9188\u001B[0m  0.2447\n",
      "      9        \u001B[36m0.9264\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.8999\u001B[0m  0.2420\n",
      "     10        \u001B[36m0.8697\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.8843\u001B[0m  0.2444\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0544\u001B[0m       \u001B[32m0.4397\u001B[0m        \u001B[35m1.5220\u001B[0m  0.2529\n",
      "      2        \u001B[36m1.6175\u001B[0m       \u001B[32m0.5322\u001B[0m        \u001B[35m1.3222\u001B[0m  0.2410\n",
      "      3        \u001B[36m1.4286\u001B[0m       \u001B[32m0.5950\u001B[0m        \u001B[35m1.1974\u001B[0m  0.2432\n",
      "      4        \u001B[36m1.2619\u001B[0m       \u001B[32m0.6165\u001B[0m        \u001B[35m1.1143\u001B[0m  0.2385\n",
      "      5        \u001B[36m1.2015\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.0455\u001B[0m  0.2431\n",
      "      6        \u001B[36m1.1029\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m1.0065\u001B[0m  0.2422\n",
      "      7        \u001B[36m1.0280\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9595\u001B[0m  0.2478\n",
      "      8        \u001B[36m0.9416\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.9190\u001B[0m  0.2421\n",
      "      9        \u001B[36m0.9189\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.8877\u001B[0m  0.2452\n",
      "     10        \u001B[36m0.8647\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.8611\u001B[0m  0.2479\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1209\u001B[0m       \u001B[32m0.4595\u001B[0m        \u001B[35m1.5124\u001B[0m  0.2615\n",
      "      2        \u001B[36m1.6766\u001B[0m       \u001B[32m0.5669\u001B[0m        \u001B[35m1.2884\u001B[0m  0.2611\n",
      "      3        \u001B[36m1.4714\u001B[0m       \u001B[32m0.6182\u001B[0m        \u001B[35m1.1727\u001B[0m  0.2486\n",
      "      4        \u001B[36m1.3181\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.1075\u001B[0m  0.2614\n",
      "      5        \u001B[36m1.1824\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0424\u001B[0m  0.2545\n",
      "      6        \u001B[36m1.1342\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m1.0047\u001B[0m  0.2436\n",
      "      7        \u001B[36m1.0461\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9682\u001B[0m  0.2450\n",
      "      8        \u001B[36m0.9632\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9273\u001B[0m  0.2441\n",
      "      9        \u001B[36m0.9280\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.9012\u001B[0m  0.2424\n",
      "     10        \u001B[36m0.9133\u001B[0m       0.7289        \u001B[35m0.8894\u001B[0m  0.2426\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0512\u001B[0m       \u001B[32m0.4793\u001B[0m        \u001B[35m1.3999\u001B[0m  0.2492\n",
      "      2        \u001B[36m1.5584\u001B[0m       \u001B[32m0.5934\u001B[0m        \u001B[35m1.2038\u001B[0m  0.2406\n",
      "      3        \u001B[36m1.3419\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.0921\u001B[0m  0.2429\n",
      "      4        \u001B[36m1.2065\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m1.0299\u001B[0m  0.2409\n",
      "      5        \u001B[36m1.1131\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9771\u001B[0m  0.2421\n",
      "      6        \u001B[36m1.0578\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.9403\u001B[0m  0.2381\n",
      "      7        \u001B[36m0.9703\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.9103\u001B[0m  0.2462\n",
      "      8        \u001B[36m0.8949\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8827\u001B[0m  0.2397\n",
      "      9        \u001B[36m0.8464\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.8547\u001B[0m  0.2444\n",
      "     10        \u001B[36m0.8285\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.8389\u001B[0m  0.2401\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0626\u001B[0m       \u001B[32m0.4959\u001B[0m        \u001B[35m1.4523\u001B[0m  0.2504\n",
      "      2        \u001B[36m1.5559\u001B[0m       \u001B[32m0.5818\u001B[0m        \u001B[35m1.2706\u001B[0m  0.2399\n",
      "      3        \u001B[36m1.4082\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.1555\u001B[0m  0.2493\n",
      "      4        \u001B[36m1.2460\u001B[0m       \u001B[32m0.6512\u001B[0m        \u001B[35m1.0819\u001B[0m  0.2456\n",
      "      5        \u001B[36m1.1262\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0273\u001B[0m  0.2755\n",
      "      6        \u001B[36m1.0473\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m0.9848\u001B[0m  0.2587\n",
      "      7        \u001B[36m0.9855\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9468\u001B[0m  0.2470\n",
      "      8        \u001B[36m0.9266\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.9223\u001B[0m  0.2473\n",
      "      9        \u001B[36m0.8759\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.8955\u001B[0m  0.2593\n",
      "     10        \u001B[36m0.8159\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8777\u001B[0m  0.2743\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0067\u001B[0m       \u001B[32m0.4810\u001B[0m        \u001B[35m1.3962\u001B[0m  0.2534\n",
      "      2        \u001B[36m1.5943\u001B[0m       \u001B[32m0.6000\u001B[0m        \u001B[35m1.2167\u001B[0m  0.2467\n",
      "      3        \u001B[36m1.3117\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.0969\u001B[0m  0.2429\n",
      "      4        \u001B[36m1.2108\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m1.0222\u001B[0m  0.2557\n",
      "      5        \u001B[36m1.1058\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m0.9677\u001B[0m  0.2472\n",
      "      6        \u001B[36m1.0430\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.9211\u001B[0m  0.2536\n",
      "      7        \u001B[36m0.9681\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.8888\u001B[0m  0.2478\n",
      "      8        \u001B[36m0.8892\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8567\u001B[0m  0.2532\n",
      "      9        \u001B[36m0.8492\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8320\u001B[0m  0.2486\n",
      "     10        \u001B[36m0.8477\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.8157\u001B[0m  0.2482\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3607\u001B[0m       \u001B[32m0.7026\u001B[0m        \u001B[35m0.8522\u001B[0m  0.6176\n",
      "      2        \u001B[36m0.8083\u001B[0m       \u001B[32m0.7974\u001B[0m        \u001B[35m0.7079\u001B[0m  0.3577\n",
      "      3        \u001B[36m0.6527\u001B[0m       0.7963        \u001B[35m0.6759\u001B[0m  0.3514\n",
      "      4        \u001B[36m0.5632\u001B[0m       \u001B[32m0.8051\u001B[0m        \u001B[35m0.6508\u001B[0m  0.3887\n",
      "      5        \u001B[36m0.5139\u001B[0m       0.7985        0.6713  0.5128\n",
      "      6        \u001B[36m0.4668\u001B[0m       0.8051        0.6683  0.4177\n",
      "      7        \u001B[36m0.4054\u001B[0m       \u001B[32m0.8073\u001B[0m        0.6546  0.3371\n",
      "      8        \u001B[36m0.3620\u001B[0m       \u001B[32m0.8117\u001B[0m        \u001B[35m0.6208\u001B[0m  0.3963\n",
      "      9        \u001B[36m0.3484\u001B[0m       \u001B[32m0.8128\u001B[0m        0.6386  0.3837\n",
      "     10        \u001B[36m0.3199\u001B[0m       0.8128        0.6528  0.3607\n",
      "Best parameters: {'batch_size': 64, 'lr': 0.001, 'module__dropout_rate': 0.4, 'module__hidden_dim1': 256, 'module__hidden_dim2': 128}\n",
      "Best cross-validation accuracy: 0.7997\n",
      "Validation accuracy: 0.8070\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "ea0a1190-2e88-45ab-9db1-f2a29d6794b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea0a1190-2e88-45ab-9db1-f2a29d6794b4",
    "outputId": "41b85032-e91d-440f-a64b-b46ea007dde6",
    "ExecuteTime": {
     "end_time": "2024-11-06T18:31:31.319551Z",
     "start_time": "2024-11-06T18:31:26.090793Z"
    }
   },
   "source": [
    "##########\n",
    "# Training\n",
    "##########\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim1 = 256\n",
    "hidden_dim2 = 128\n",
    "output_dim = 6\n",
    "drop_out = 0.4\n",
    "\n",
    "model = Classifier(input_dim, hidden_dim1, hidden_dim2, output_dim, drop_out)\n",
    "\n",
    "device = get_device()\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "max_grad_norm = 1.0\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in range(0, len(X_train), batch_size):\n",
    "        inputs = X_train[batch:batch + batch_size]\n",
    "        labels = y_train[batch:batch + batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f'Epoch: {epoch+1}, Loss: {epoch_loss/len(X_train):.4f}, Learning Rate: {scheduler.get_last_lr()[0]:.6f}')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fh/yf32rrls0pjbtmy317lvgthh0000gn/T/ipykernel_40421/3757100208.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32)\n",
      "/var/folders/fh/yf32rrls0pjbtmy317lvgthh0000gn/T/ipykernel_40421/3757100208.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device found, using MPS backend.\n",
      "\n",
      "Epoch: 1, Loss: 0.0188, Learning Rate: 0.001000\n",
      "Epoch: 2, Loss: 0.0115, Learning Rate: 0.001000\n",
      "Epoch: 3, Loss: 0.0094, Learning Rate: 0.001000\n",
      "Epoch: 4, Loss: 0.0080, Learning Rate: 0.001000\n",
      "Epoch: 5, Loss: 0.0073, Learning Rate: 0.000500\n",
      "Epoch: 6, Loss: 0.0060, Learning Rate: 0.000500\n",
      "Epoch: 7, Loss: 0.0054, Learning Rate: 0.000500\n",
      "Epoch: 8, Loss: 0.0051, Learning Rate: 0.000500\n",
      "Epoch: 9, Loss: 0.0049, Learning Rate: 0.000500\n",
      "Epoch: 10, Loss: 0.0045, Learning Rate: 0.000250\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "335503be-ea74-42b8-ab51-d4d80bc5f77b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "335503be-ea74-42b8-ab51-d4d80bc5f77b",
    "outputId": "68db4758-095a-4cae-e74e-c1d1ab814a0b",
    "ExecuteTime": {
     "end_time": "2024-11-06T18:36:19.324968Z",
     "start_time": "2024-11-06T18:36:19.141918Z"
    }
   },
   "source": [
    "############\n",
    "# Evaluation\n",
    "############\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "y_test = y_test.squeeze()\n",
    "\n",
    "device = get_device()\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in range(0, len(X_test), batch_size):\n",
    "        inputs = X_test[batch:batch + batch_size]\n",
    "        labels = y_test[batch:batch + batch_size]\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / y_test.shape[0]\n",
    "print(f'Accuracy on test data: {accuracy:.2f}%')\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[f'Class {i}' for i in range(output_dim)],\n",
    "            yticklabels=[f'Class {i}' for i in range(output_dim)])\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "print(f'Weighted F1-Score: {f1*100:.2f}%')\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "categories = ['Pump Announcement', 'Countdown', 'Coin Release', 'Pump Result', 'Delay/Cancellation', 'Other/Garbage']\n",
    "report = classification_report(all_labels, all_predictions, target_names=categories, output_dict=True)\n",
    "print(report)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device found, using MPS backend.\n",
      "\n",
      "Accuracy on test data: 83.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fh/yf32rrls0pjbtmy317lvgthh0000gn/T/ipykernel_40421/4084736554.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test, dtype=torch.float32)\n",
      "/var/folders/fh/yf32rrls0pjbtmy317lvgthh0000gn/T/ipykernel_40421/4084736554.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test, dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1-Score: 83.53%\n",
      "\n",
      "Classification Report:\n",
      "{'Pump Announcement': {'precision': 0.7572815533980582, 'recall': 0.9230769230769231, 'f1-score': 0.832, 'support': 169.0}, 'Countdown': {'precision': 0.8136482939632546, 'recall': 0.8985507246376812, 'f1-score': 0.8539944903581267, 'support': 345.0}, 'Coin Release': {'precision': 0.8226950354609929, 'recall': 0.7682119205298014, 'f1-score': 0.7945205479452054, 'support': 151.0}, 'Pump Result': {'precision': 0.8837209302325582, 'recall': 0.8702290076335878, 'f1-score': 0.8769230769230769, 'support': 131.0}, 'Delay/Cancellation': {'precision': 0.8533333333333334, 'recall': 0.7804878048780488, 'f1-score': 0.8152866242038217, 'support': 82.0}, 'Other/Garbage': {'precision': 0.8747433264887063, 'recall': 0.7874306839186691, 'f1-score': 0.8287937743190662, 'support': 541.0}, 'accuracy': 0.835799859055673, 'macro avg': {'precision': 0.8342370788128172, 'recall': 0.8379978441124519, 'f1-score': 0.8335864189582161, 'support': 1419.0}, 'weighted avg': {'precision': 0.8399528605499601, 'recall': 0.835799859055673, 'f1-score': 0.8353182241589365, 'support': 1419.0}}\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T18:30:05.829337Z",
     "start_time": "2024-11-06T18:30:05.827626Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1caff7de8524ad7a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
