{
 "cells": [
  {
   "cell_type": "code",
   "id": "67ab1ae5-218c-49f6-b80f-303aa10f2312",
   "metadata": {
    "id": "67ab1ae5-218c-49f6-b80f-303aa10f2312",
    "ExecuteTime": {
     "end_time": "2024-10-21T12:44:14.898764Z",
     "start_time": "2024-10-21T12:44:13.252352Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (confusion_matrix,\n",
    "                             classification_report,\n",
    "                             accuracy_score,\n",
    "                             f1_score,\n",
    "                             ConfusionMatrixDisplay)\n",
    "\n",
    "from sklearn.model_selection import (train_test_split,\n",
    "                                     GridSearchCV)\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "nltk.download('punkt')\n",
    "glove_filepath = 'glove.6B.300d.txt'"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kevinbrundler/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "kpGX2ejdKzK5",
   "metadata": {
    "id": "kpGX2ejdKzK5",
    "ExecuteTime": {
     "end_time": "2024-10-21T12:44:26.062015Z",
     "start_time": "2024-10-21T12:44:14.909002Z"
    }
   },
   "source": [
    "def load_glove_embeddings(filepath):\n",
    "    \"\"\"\n",
    "    Loads GloVe embeddings from a file and returns them as a dictionary.\n",
    "\n",
    "    The function reads the GloVe pre-trained embeddings from the specified file.\n",
    "    Each line in the GloVe file contains a word followed by its corresponding\n",
    "    vector of floating point numbers representing the word's embedding. The\n",
    "    function processes each line, extracts the word and its vector, and stores\n",
    "    them in a dictionary where the key is the word and the value is the corresponding\n",
    "    embedding vector.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The path to the GloVe embeddings file. Each line of the file should\n",
    "                        contain a word followed by its vector of embedding values.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are words (str) and values are their corresponding\n",
    "              embedding vectors (numpy.ndarray).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    embedding_dict = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embedding_dict[word] = vector\n",
    "    return embedding_dict\n",
    "\n",
    "\n",
    "embedding_dict = load_glove_embeddings(r\"glove/glove.6B.300d.txt\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "cb468562-0171-4a15-8001-6cbed6fe6d5f",
   "metadata": {
    "id": "cb468562-0171-4a15-8001-6cbed6fe6d5f",
    "ExecuteTime": {
     "end_time": "2024-10-21T12:44:26.298598Z",
     "start_time": "2024-10-21T12:44:26.294452Z"
    }
   },
   "source": [
    "def split_data(\n",
    "    df: pd.DataFrame,\n",
    "    label_col: str = 'label',\n",
    "    test_size: float = 0.3,\n",
    "    random_state: int = None\n",
    ") -> tuple[pd.DataFrame]:\n",
    "\n",
    "    def ensure_all_labels(original_df, train_df, test_df, label_col):\n",
    "        original_labels = set(original_df[label_col])\n",
    "        train_labels = set(train_df[label_col])\n",
    "        missing_labels = original_labels - train_labels\n",
    "\n",
    "        if missing_labels:\n",
    "            for label in missing_labels:\n",
    "                missing_sample = test_df[test_df[label_col] == label].sample(n=1)\n",
    "                test_df = test_df[~(test_df[label_col].isin(missing_sample.labels))]\n",
    "                train_df = pd.concat([train_df, missing_sample])\n",
    "        return train_df, test_df\n",
    "\n",
    "    try:\n",
    "        train_df, test_df = train_test_split(\n",
    "            df,\n",
    "            test_size=test_size,\n",
    "            stratify=df[label_col],\n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "        train_df, test_df = ensure_all_labels(df, train_df, test_df, label_col)\n",
    "\n",
    "    except ValueError as e:\n",
    "        warnings.warn(\n",
    "            f\"{e} --- Falling back to random split. Consider reviewing extremely small classes.\"\n",
    "        )\n",
    "\n",
    "        # Fallback to random split if stratified split fails\n",
    "        train_df, test_df = train_test_split(\n",
    "            df,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "        train_df, test_df = ensure_all_labels(df, train_df, test_df, label_col)\n",
    "\n",
    "    return train_df, test_df"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "97eae70d-b535-42b2-8a56-e2594e723296",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97eae70d-b535-42b2-8a56-e2594e723296",
    "outputId": "faba62f8-9c2f-44b8-8836-e5fbccaad91a",
    "ExecuteTime": {
     "end_time": "2024-10-21T12:44:26.466606Z",
     "start_time": "2024-10-21T12:44:26.463778Z"
    }
   },
   "source": [
    "def get_sentence_embedding(sentence, embedding_dict, embedding_dim=300):\n",
    "    \"\"\"\n",
    "    Converts a sentence into a fixed-size embedding by averaging the word embeddings.\n",
    "\n",
    "    This function takes a sentence, tokenizes it, and looks up each token's embedding\n",
    "    in the provided `embedding_dict`. If a word is not found in the embedding dictionary,\n",
    "    it assigns a random vector of the specified `embedding_dim`. The resulting sentence\n",
    "    embedding is the average of the word embeddings.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence to be converted into an embedding.\n",
    "        embedding_dict (dict): A dictionary where the keys are words and the values are\n",
    "                               their corresponding embedding vectors (typically from GloVe).\n",
    "        embedding_dim (int): The dimensionality of the embeddings (default is 300).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 1D NumPy array representing the averaged embedding of the input sentence.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = word_tokenize(sentence.lower())\n",
    "    embeddings = []\n",
    "    for token in tokens:\n",
    "        if token in embedding_dict:\n",
    "            embeddings.append(embedding_dict[token])\n",
    "        else:\n",
    "            embeddings.append(np.random.randn(embedding_dim))\n",
    "    return np.mean(embeddings, axis=0)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "d2662879-9e49-476f-860f-044ea9e666a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2662879-9e49-476f-860f-044ea9e666a9",
    "outputId": "02f3d048-5415-485e-a806-0b55fd84341c",
    "ExecuteTime": {
     "end_time": "2024-10-21T12:44:28.683899Z",
     "start_time": "2024-10-21T12:44:26.637710Z"
    }
   },
   "source": [
    "df = pd.read_csv(r'data/internal/training_data/training_data_no_duplicates_per_channel.csv')\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.array([get_sentence_embedding(str(message), embedding_dict) for message in train_df.message])\n",
    "y_train = np.array(train_df.label)\n",
    "\n",
    "X_test = np.array([get_sentence_embedding(str(message), embedding_dict) for message in test_df.message])\n",
    "y_test = np.array([test_df.label])"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "02d6d6cd-a00b-4d3c-bffb-23230f38120e",
   "metadata": {
    "id": "02d6d6cd-a00b-4d3c-bffb-23230f38120e",
    "ExecuteTime": {
     "end_time": "2024-10-21T12:44:28.858440Z",
     "start_time": "2024-10-21T12:44:28.855658Z"
    }
   },
   "source": [
    "def get_device():\n",
    "    \"\"\"\n",
    "    Determines the best available hardware device (MPS, CUDA, or CPU) to run PyTorch operations.\n",
    "\n",
    "    This function checks for the availability of hardware acceleration on the system and returns\n",
    "    the appropriate device for computation. It first checks for Metal Performance Shaders (MPS) on\n",
    "    Apple devices, then for CUDA (NVIDIA GPUs), and finally defaults to the CPU if no GPU is available.\n",
    "\n",
    "    Returns:\n",
    "        torch.device: The best available device ('mps', 'cuda', or 'cpu') for PyTorch computations.\n",
    "    \"\"\"\n",
    "\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"MPS device found, using MPS backend.\\n\")\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        print(f\"CUDA device found, using CUDA backend. Device: {torch.cuda.get_device_name(0)}\\n\")\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        print(\"Neither MPS nor CUDA found, using CPU.\\n\")\n",
    "        return torch.device(\"cpu\")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ySDJGFTRNYdO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ySDJGFTRNYdO",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c24c36ce-0362-49e5-d681-0368330f25e9",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-21T12:57:18.846921Z",
     "start_time": "2024-10-21T12:44:29.028577Z"
    }
   },
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim, dropout_rate=0.5):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, hidden_dim1)\n",
    "        self.fc4 = nn.Linear(hidden_dim1, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # Xavier Initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.leaky_relu(self.bn1(self.fc1(x)))\n",
    "        x1 = self.dropout(x1)\n",
    "\n",
    "        x2 = self.leaky_relu(self.bn2(self.fc2(x1)))\n",
    "        x2 = self.dropout(x2)\n",
    "\n",
    "        x_residual = self.fc3(x2) + x1\n",
    "\n",
    "        x_out = self.fc4(x_residual)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "#############\n",
    "# Grid Search\n",
    "#############\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_train_np, X_valid_np, y_train_np, y_valid_np = train_test_split(\n",
    "    X_train.numpy(), y_train.numpy(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    Classifier,\n",
    "    module__input_dim=X_train.shape[1],\n",
    "    module__output_dim=6,\n",
    "    max_epochs=10,\n",
    "    lr=5e-4,\n",
    "    optimizer=optim.Adam,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    batch_size=64,\n",
    "    device=get_device(),\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'lr': [1e-3, 1e-4],\n",
    "    'module__hidden_dim1': [128, 256, 512],\n",
    "    'module__hidden_dim2': [64, 128, 256],\n",
    "    'module__dropout_rate': [0.4, 0.5],\n",
    "    'batch_size': [32, 64]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(net, param_grid, refit=True, cv=3, scoring='f1_weighted', verbose=2)\n",
    "gs.fit(X_train_np, y_train_np)\n",
    "\n",
    "print(f\"Best parameters: {gs.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {gs.best_score_:.4f}\")\n",
    "\n",
    "best_net = gs.best_estimator_\n",
    "val_accuracy = best_net.score(X_valid_np, y_valid_np)\n",
    "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device found, using MPS backend.\n",
      "\n",
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinbrundler/Desktop/Master Project/Inference Final/Pipeline/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5226\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0036\u001B[0m  1.0056\n",
      "      2        \u001B[36m0.9951\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.8611\u001B[0m  0.5649\n",
      "      3        \u001B[36m0.8172\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7742\u001B[0m  0.5642\n",
      "      4        \u001B[36m0.7168\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7390\u001B[0m  0.5351\n",
      "      5        \u001B[36m0.6505\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.6905\u001B[0m  0.5060\n",
      "      6        \u001B[36m0.5733\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.6740\u001B[0m  0.5348\n",
      "      7        \u001B[36m0.5102\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6680\u001B[0m  0.4781\n",
      "      8        \u001B[36m0.4842\u001B[0m       \u001B[32m0.8083\u001B[0m        \u001B[35m0.6450\u001B[0m  0.4510\n",
      "      9        \u001B[36m0.4491\u001B[0m       0.7950        0.6680  0.4442\n",
      "     10        \u001B[36m0.4034\u001B[0m       0.8033        0.6546  0.5100\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   7.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5495\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.0555\u001B[0m  0.5442\n",
      "      2        \u001B[36m0.9996\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.8920\u001B[0m  0.4930\n",
      "      3        \u001B[36m0.7939\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7707\u001B[0m  0.5001\n",
      "      4        \u001B[36m0.6844\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7234\u001B[0m  0.4895\n",
      "      5        \u001B[36m0.6191\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6872\u001B[0m  0.4970\n",
      "      6        \u001B[36m0.5631\u001B[0m       \u001B[32m0.8165\u001B[0m        \u001B[35m0.6790\u001B[0m  0.5027\n",
      "      7        \u001B[36m0.4989\u001B[0m       0.8165        \u001B[35m0.6610\u001B[0m  0.5114\n",
      "      8        \u001B[36m0.4702\u001B[0m       0.8116        \u001B[35m0.6488\u001B[0m  0.4967\n",
      "      9        \u001B[36m0.4119\u001B[0m       0.8149        0.6505  0.5245\n",
      "     10        \u001B[36m0.3931\u001B[0m       \u001B[32m0.8215\u001B[0m        \u001B[35m0.6301\u001B[0m  0.5071\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   5.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5488\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0245\u001B[0m  0.4789\n",
      "      2        \u001B[36m0.9767\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.8792\u001B[0m  0.4707\n",
      "      3        \u001B[36m0.8190\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.7965\u001B[0m  0.4650\n",
      "      4        \u001B[36m0.6869\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7391\u001B[0m  0.4751\n",
      "      5        \u001B[36m0.5957\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.7157\u001B[0m  0.4738\n",
      "      6        \u001B[36m0.5296\u001B[0m       0.8017        \u001B[35m0.6883\u001B[0m  0.4688\n",
      "      7        \u001B[36m0.4834\u001B[0m       0.7917        \u001B[35m0.6790\u001B[0m  0.5128\n",
      "      8        \u001B[36m0.4421\u001B[0m       0.8000        0.6948  0.5447\n",
      "      9        \u001B[36m0.4116\u001B[0m       0.8000        0.6826  0.5415\n",
      "     10        \u001B[36m0.3907\u001B[0m       0.7851        0.6978  0.4859\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   5.1s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5486\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.0345\u001B[0m  0.5132\n",
      "      2        \u001B[36m1.0213\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8817\u001B[0m  0.5084\n",
      "      3        \u001B[36m0.8275\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.7750\u001B[0m  0.5350\n",
      "      4        \u001B[36m0.7346\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.7315\u001B[0m  0.6155\n",
      "      5        \u001B[36m0.6159\u001B[0m       \u001B[32m0.8083\u001B[0m        \u001B[35m0.6973\u001B[0m  0.5262\n",
      "      6        \u001B[36m0.5455\u001B[0m       \u001B[32m0.8132\u001B[0m        \u001B[35m0.6650\u001B[0m  0.5143\n",
      "      7        \u001B[36m0.5228\u001B[0m       \u001B[32m0.8149\u001B[0m        \u001B[35m0.6412\u001B[0m  0.4826\n",
      "      8        \u001B[36m0.4763\u001B[0m       0.8033        0.6743  0.5164\n",
      "      9        \u001B[36m0.4580\u001B[0m       0.8083        0.6469  0.5270\n",
      "     10        \u001B[36m0.4196\u001B[0m       0.8017        0.6699  0.4799\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   5.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4959\u001B[0m       \u001B[32m0.6661\u001B[0m        \u001B[35m1.0203\u001B[0m  0.5680\n",
      "      2        \u001B[36m0.9845\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.8718\u001B[0m  0.4656\n",
      "      3        \u001B[36m0.8064\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.7908\u001B[0m  0.4676\n",
      "      4        \u001B[36m0.7161\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7268\u001B[0m  0.4699\n",
      "      5        \u001B[36m0.6099\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.6897\u001B[0m  0.4742\n",
      "      6        \u001B[36m0.5643\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6686\u001B[0m  0.5455\n",
      "      7        \u001B[36m0.5211\u001B[0m       0.7884        \u001B[35m0.6672\u001B[0m  0.5633\n",
      "      8        \u001B[36m0.4667\u001B[0m       0.7884        0.6754  0.4568\n",
      "      9        \u001B[36m0.4256\u001B[0m       \u001B[32m0.8099\u001B[0m        \u001B[35m0.6609\u001B[0m  0.4495\n",
      "     10        \u001B[36m0.3893\u001B[0m       \u001B[32m0.8165\u001B[0m        \u001B[35m0.6528\u001B[0m  0.4518\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   5.1s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5891\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.0044\u001B[0m  0.4624\n",
      "      2        \u001B[36m1.0024\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8451\u001B[0m  0.4995\n",
      "      3        \u001B[36m0.8069\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.7816\u001B[0m  0.4515\n",
      "      4        \u001B[36m0.6951\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7313\u001B[0m  0.4681\n",
      "      5        \u001B[36m0.6022\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.6892\u001B[0m  0.4771\n",
      "      6        \u001B[36m0.5496\u001B[0m       0.7537        0.7167  0.4657\n",
      "      7        \u001B[36m0.5069\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.6851\u001B[0m  0.4652\n",
      "      8        \u001B[36m0.4344\u001B[0m       \u001B[32m0.7868\u001B[0m        0.7056  0.4562\n",
      "      9        \u001B[36m0.4011\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6819\u001B[0m  0.4602\n",
      "     10        \u001B[36m0.3581\u001B[0m       \u001B[32m0.7950\u001B[0m        0.6910  0.4663\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5753\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m0.9637\u001B[0m  0.6150\n",
      "      2        \u001B[36m0.9916\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.8473\u001B[0m  0.4842\n",
      "      3        \u001B[36m0.8477\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7402\u001B[0m  0.4693\n",
      "      4        \u001B[36m0.7309\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7287\u001B[0m  0.4745\n",
      "      5        \u001B[36m0.6402\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6618\u001B[0m  0.4763\n",
      "      6        \u001B[36m0.5906\u001B[0m       \u001B[32m0.8050\u001B[0m        0.6642  0.4731\n",
      "      7        \u001B[36m0.5170\u001B[0m       0.7934        0.6883  0.5434\n",
      "      8        \u001B[36m0.4867\u001B[0m       0.7884        0.7117  0.5555\n",
      "      9        \u001B[36m0.4411\u001B[0m       0.7802        0.7091  0.4608\n",
      "     10        \u001B[36m0.4062\u001B[0m       0.7802        0.7207  0.4555\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   5.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6060\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m0.9773\u001B[0m  0.4917\n",
      "      2        \u001B[36m1.0235\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.8290\u001B[0m  0.4834\n",
      "      3        \u001B[36m0.8736\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.7639\u001B[0m  0.4784\n",
      "      4        \u001B[36m0.7383\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7630\u001B[0m  0.4896\n",
      "      5        \u001B[36m0.6355\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7133\u001B[0m  0.4859\n",
      "      6        \u001B[36m0.5955\u001B[0m       0.7736        0.7148  0.4916\n",
      "      7        \u001B[36m0.5096\u001B[0m       0.7669        0.7137  0.4917\n",
      "      8        \u001B[36m0.4658\u001B[0m       0.7752        0.7420  0.4901\n",
      "      9        \u001B[36m0.4359\u001B[0m       0.7636        0.7186  0.4982\n",
      "     10        \u001B[36m0.4008\u001B[0m       0.7686        0.7372  0.4984\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   5.1s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5179\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m0.9693\u001B[0m  0.4863\n",
      "      2        \u001B[36m0.9765\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8218\u001B[0m  0.4963\n",
      "      3        \u001B[36m0.7990\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.7712\u001B[0m  0.4857\n",
      "      4        \u001B[36m0.6838\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7531\u001B[0m  0.5039\n",
      "      5        \u001B[36m0.6023\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7228\u001B[0m  0.4882\n",
      "      6        \u001B[36m0.5247\u001B[0m       0.7504        0.7416  0.4976\n",
      "      7        \u001B[36m0.4819\u001B[0m       0.7554        0.7616  0.5058\n",
      "      8        \u001B[36m0.4484\u001B[0m       0.7620        0.7529  0.4930\n",
      "      9        \u001B[36m0.4034\u001B[0m       0.7669        0.7646  0.4944\n",
      "     10        \u001B[36m0.3710\u001B[0m       \u001B[32m0.7851\u001B[0m        0.7505  0.4937\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   5.1s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3955\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9026\u001B[0m  0.6176\n",
      "      2        \u001B[36m0.8334\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.7364\u001B[0m  0.4801\n",
      "      3        \u001B[36m0.6533\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.6693\u001B[0m  0.4569\n",
      "      4        \u001B[36m0.5534\u001B[0m       \u001B[32m0.8116\u001B[0m        \u001B[35m0.6518\u001B[0m  0.4757\n",
      "      5        \u001B[36m0.4677\u001B[0m       0.8066        0.6551  0.4663\n",
      "      6        \u001B[36m0.4519\u001B[0m       \u001B[32m0.8132\u001B[0m        0.6555  0.4985\n",
      "      7        \u001B[36m0.3883\u001B[0m       0.8132        0.6611  0.4709\n",
      "      8        \u001B[36m0.3519\u001B[0m       \u001B[32m0.8165\u001B[0m        0.6613  0.4671\n",
      "      9        \u001B[36m0.3162\u001B[0m       0.7967        0.6585  0.4795\n",
      "     10        \u001B[36m0.2797\u001B[0m       0.8149        \u001B[35m0.6348\u001B[0m  0.4899\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   5.1s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4130\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m0.8960\u001B[0m  0.5028\n",
      "      2        \u001B[36m0.8000\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7884\u001B[0m  0.4791\n",
      "      3        \u001B[36m0.6538\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7286\u001B[0m  0.4756\n",
      "      4        \u001B[36m0.5543\u001B[0m       0.7785        \u001B[35m0.6880\u001B[0m  0.4772\n",
      "      5        \u001B[36m0.4706\u001B[0m       \u001B[32m0.8083\u001B[0m        0.6962  0.4907\n",
      "      6        \u001B[36m0.4126\u001B[0m       \u001B[32m0.8215\u001B[0m        0.6959  0.4670\n",
      "      7        \u001B[36m0.3528\u001B[0m       0.7868        \u001B[35m0.6731\u001B[0m  0.4738\n",
      "      8        \u001B[36m0.3282\u001B[0m       0.8198        \u001B[35m0.6422\u001B[0m  0.4609\n",
      "      9        \u001B[36m0.2816\u001B[0m       0.8000        0.6907  0.4895\n",
      "     10        \u001B[36m0.2806\u001B[0m       \u001B[32m0.8248\u001B[0m        \u001B[35m0.6263\u001B[0m  0.4741\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   5.0s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3341\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m0.9013\u001B[0m  0.5030\n",
      "      2        \u001B[36m0.8088\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8365\u001B[0m  0.4984\n",
      "      3        \u001B[36m0.6173\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.7678\u001B[0m  0.5025\n",
      "      4        \u001B[36m0.5149\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7289\u001B[0m  0.4740\n",
      "      5        \u001B[36m0.4526\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.6864\u001B[0m  0.4963\n",
      "      6        \u001B[36m0.4011\u001B[0m       0.7736        \u001B[35m0.6853\u001B[0m  0.4819\n",
      "      7        \u001B[36m0.3422\u001B[0m       0.7785        0.7202  0.4838\n",
      "      8        \u001B[36m0.2928\u001B[0m       0.7752        0.7135  0.4987\n",
      "      9        \u001B[36m0.2635\u001B[0m       0.7669        0.7207  0.5095\n",
      "     10        \u001B[36m0.2391\u001B[0m       0.7653        0.7786  0.4865\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   5.1s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4371\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.8905\u001B[0m  0.5028\n",
      "      2        \u001B[36m0.8693\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.7548\u001B[0m  0.5005\n",
      "      3        \u001B[36m0.6697\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.6966\u001B[0m  0.4954\n",
      "      4        \u001B[36m0.5817\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6578\u001B[0m  0.4947\n",
      "      5        \u001B[36m0.5041\u001B[0m       \u001B[32m0.8033\u001B[0m        0.6731  0.4868\n",
      "      6        \u001B[36m0.4549\u001B[0m       0.8000        0.6612  0.5037\n",
      "      7        \u001B[36m0.4040\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6424\u001B[0m  0.5285\n",
      "      8        \u001B[36m0.3476\u001B[0m       0.7934        0.6752  0.5154\n",
      "      9        \u001B[36m0.3005\u001B[0m       \u001B[32m0.8132\u001B[0m        0.6622  0.4820\n",
      "     10        \u001B[36m0.2780\u001B[0m       0.7983        0.7346  0.4831\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   5.1s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4150\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m0.9010\u001B[0m  0.4774\n",
      "      2        \u001B[36m0.8101\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.7894\u001B[0m  0.4903\n",
      "      3        \u001B[36m0.6564\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7395\u001B[0m  0.4894\n",
      "      4        \u001B[36m0.5621\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.7097\u001B[0m  0.4903\n",
      "      5        \u001B[36m0.4966\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6541\u001B[0m  0.4940\n",
      "      6        \u001B[36m0.4432\u001B[0m       0.7983        0.6919  0.4751\n",
      "      7        \u001B[36m0.3874\u001B[0m       0.7983        0.6626  0.4838\n",
      "      8        \u001B[36m0.3431\u001B[0m       0.7950        0.6639  0.4934\n",
      "      9        \u001B[36m0.3230\u001B[0m       0.7950        0.7312  0.5054\n",
      "     10        \u001B[36m0.2773\u001B[0m       0.7785        0.7277  0.4904\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   5.0s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3374\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.8729\u001B[0m  0.5051\n",
      "      2        \u001B[36m0.8451\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7802\u001B[0m  0.5159\n",
      "      3        \u001B[36m0.6252\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7008\u001B[0m  0.5320\n",
      "      4        \u001B[36m0.5321\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6672\u001B[0m  0.4733\n",
      "      5        \u001B[36m0.4507\u001B[0m       0.7785        \u001B[35m0.6658\u001B[0m  0.4743\n",
      "      6        \u001B[36m0.3983\u001B[0m       0.7868        0.6764  0.4788\n",
      "      7        \u001B[36m0.3765\u001B[0m       0.8033        0.6785  0.4728\n",
      "      8        \u001B[36m0.3153\u001B[0m       0.7769        0.7401  0.4890\n",
      "      9        \u001B[36m0.2789\u001B[0m       0.7868        0.7391  0.4730\n",
      "     10        \u001B[36m0.2421\u001B[0m       0.7736        0.7905  0.4863\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   5.0s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4720\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.9220\u001B[0m  0.5162\n",
      "      2        \u001B[36m0.9000\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.7657\u001B[0m  0.4760\n",
      "      3        \u001B[36m0.7484\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7183\u001B[0m  0.5059\n",
      "      4        \u001B[36m0.5986\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.6985\u001B[0m  0.4847\n",
      "      5        \u001B[36m0.5284\u001B[0m       0.7851        0.7165  0.4471\n",
      "      6        \u001B[36m0.4777\u001B[0m       \u001B[32m0.8017\u001B[0m        0.7027  0.4440\n",
      "      7        \u001B[36m0.4255\u001B[0m       0.7950        0.7308  0.4563\n",
      "      8        \u001B[36m0.3961\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6944\u001B[0m  0.4558\n",
      "      9        \u001B[36m0.3195\u001B[0m       0.8033        0.7141  0.4487\n",
      "     10        \u001B[36m0.2961\u001B[0m       0.8000        0.7524  0.4646\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3871\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.8843\u001B[0m  0.4654\n",
      "      2        \u001B[36m0.8999\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.7805\u001B[0m  0.4530\n",
      "      3        \u001B[36m0.6876\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7163\u001B[0m  0.4650\n",
      "      4        \u001B[36m0.5923\u001B[0m       \u001B[32m0.8165\u001B[0m        \u001B[35m0.6797\u001B[0m  0.4668\n",
      "      5        \u001B[36m0.4755\u001B[0m       0.7917        0.7095  0.4539\n",
      "      6        \u001B[36m0.4377\u001B[0m       0.8149        \u001B[35m0.6592\u001B[0m  0.4634\n",
      "      7        \u001B[36m0.3908\u001B[0m       0.7802        0.7658  0.4566\n",
      "      8        \u001B[36m0.3706\u001B[0m       0.7884        0.7486  0.4538\n",
      "      9        \u001B[36m0.3437\u001B[0m       0.7917        0.7078  0.4618\n",
      "     10        \u001B[36m0.2827\u001B[0m       0.7702        0.7847  0.4877\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3794\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m0.8714\u001B[0m  0.5112\n",
      "      2        \u001B[36m0.8370\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.8378\u001B[0m  0.5512\n",
      "      3        \u001B[36m0.6615\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7239\u001B[0m  0.4510\n",
      "      4        \u001B[36m0.5501\u001B[0m       0.7438        0.7487  0.4408\n",
      "      5        \u001B[36m0.4732\u001B[0m       0.7587        0.7326  0.4409\n",
      "      6        \u001B[36m0.4051\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7149\u001B[0m  0.4377\n",
      "      7        \u001B[36m0.3717\u001B[0m       0.7868        \u001B[35m0.6792\u001B[0m  0.4471\n",
      "      8        \u001B[36m0.3241\u001B[0m       0.7653        0.7444  0.4421\n",
      "      9        \u001B[36m0.2697\u001B[0m       0.7636        0.7715  0.4404\n",
      "     10        \u001B[36m0.2560\u001B[0m       0.7835        0.7958  0.4411\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.2529\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.7882\u001B[0m  0.7019\n",
      "      2        \u001B[36m0.7259\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.6769\u001B[0m  0.4612\n",
      "      3        \u001B[36m0.5306\u001B[0m       \u001B[32m0.7934\u001B[0m        0.7051  0.4493\n",
      "      4        \u001B[36m0.4443\u001B[0m       0.7802        0.7078  0.4516\n",
      "      5        \u001B[36m0.3697\u001B[0m       \u001B[32m0.8248\u001B[0m        \u001B[35m0.6119\u001B[0m  0.4856\n",
      "      6        \u001B[36m0.3223\u001B[0m       0.8083        0.6619  0.4514\n",
      "      7        \u001B[36m0.2802\u001B[0m       0.8132        0.6865  0.4697\n",
      "      8        \u001B[36m0.2349\u001B[0m       0.7967        0.7039  0.4501\n",
      "      9        \u001B[36m0.1970\u001B[0m       0.8000        0.7221  0.4562\n",
      "     10        \u001B[36m0.1732\u001B[0m       0.7587        0.8086  0.4645\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   5.0s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.2303\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.8396\u001B[0m  0.5241\n",
      "      2        \u001B[36m0.6768\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7135\u001B[0m  0.4825\n",
      "      3        \u001B[36m0.5323\u001B[0m       0.7736        0.7290  0.4913\n",
      "      4        \u001B[36m0.4240\u001B[0m       \u001B[32m0.7752\u001B[0m        0.7250  0.4844\n",
      "      5        \u001B[36m0.3621\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7059\u001B[0m  0.4743\n",
      "      6        \u001B[36m0.3147\u001B[0m       \u001B[32m0.7901\u001B[0m        0.7193  0.4800\n",
      "      7        \u001B[36m0.2622\u001B[0m       \u001B[32m0.8149\u001B[0m        \u001B[35m0.6630\u001B[0m  0.4907\n",
      "      8        \u001B[36m0.2218\u001B[0m       0.8000        0.6734  0.4963\n",
      "      9        \u001B[36m0.1890\u001B[0m       0.8000        0.7097  0.4848\n",
      "     10        \u001B[36m0.1850\u001B[0m       0.7868        0.8072  0.4803\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   5.1s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.2656\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8080\u001B[0m  0.4666\n",
      "      2        \u001B[36m0.6660\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7490\u001B[0m  0.4694\n",
      "      3        \u001B[36m0.5041\u001B[0m       0.7818        \u001B[35m0.7432\u001B[0m  0.4542\n",
      "      4        \u001B[36m0.3828\u001B[0m       0.7736        \u001B[35m0.7244\u001B[0m  0.4573\n",
      "      5        \u001B[36m0.3372\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6794\u001B[0m  0.4656\n",
      "      6        \u001B[36m0.2769\u001B[0m       \u001B[32m0.8050\u001B[0m        0.7022  0.4581\n",
      "      7        \u001B[36m0.2498\u001B[0m       0.7917        0.7147  0.4582\n",
      "      8        \u001B[36m0.2167\u001B[0m       \u001B[32m0.8066\u001B[0m        0.7507  0.4523\n",
      "      9        \u001B[36m0.1792\u001B[0m       0.7884        0.7343  0.4563\n",
      "     10        \u001B[36m0.1702\u001B[0m       0.7901        0.7950  0.4817\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3094\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8253\u001B[0m  0.5393\n",
      "      2        \u001B[36m0.7235\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.6806\u001B[0m  0.4771\n",
      "      3        \u001B[36m0.5693\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6701\u001B[0m  0.4604\n",
      "      4        \u001B[36m0.4643\u001B[0m       \u001B[32m0.8165\u001B[0m        \u001B[35m0.6596\u001B[0m  0.4740\n",
      "      5        \u001B[36m0.3849\u001B[0m       0.8066        0.6824  0.4699\n",
      "      6        \u001B[36m0.3533\u001B[0m       0.8066        0.7027  0.4735\n",
      "      7        \u001B[36m0.3045\u001B[0m       0.7901        0.7019  0.5282\n",
      "      8        \u001B[36m0.2623\u001B[0m       0.8149        0.6922  0.5256\n",
      "      9        \u001B[36m0.2303\u001B[0m       0.7736        0.7398  0.4551\n",
      "     10        \u001B[36m0.2112\u001B[0m       0.7802        0.7221  0.4430\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   5.0s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3316\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9115\u001B[0m  0.4683\n",
      "      2        \u001B[36m0.7314\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7141\u001B[0m  0.4438\n",
      "      3        \u001B[36m0.5498\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7119\u001B[0m  0.4475\n",
      "      4        \u001B[36m0.4476\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.6718\u001B[0m  0.4504\n",
      "      5        \u001B[36m0.3962\u001B[0m       \u001B[32m0.8099\u001B[0m        \u001B[35m0.6297\u001B[0m  0.4470\n",
      "      6        \u001B[36m0.3312\u001B[0m       0.7917        0.7111  0.4497\n",
      "      7        \u001B[36m0.2923\u001B[0m       0.7901        0.6733  0.4621\n",
      "      8        \u001B[36m0.2361\u001B[0m       0.7785        0.7787  0.4504\n",
      "      9        \u001B[36m0.2247\u001B[0m       0.8050        0.7301  0.4578\n",
      "     10        \u001B[36m0.2115\u001B[0m       0.7702        0.8187  0.4594\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.2048\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.8103\u001B[0m  0.4580\n",
      "      2        \u001B[36m0.6684\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.6603\u001B[0m  0.4802\n",
      "      3        \u001B[36m0.5106\u001B[0m       0.7917        0.7658  0.4543\n",
      "      4        \u001B[36m0.4309\u001B[0m       \u001B[32m0.8083\u001B[0m        0.6811  0.4673\n",
      "      5        \u001B[36m0.3411\u001B[0m       0.7934        0.7153  0.4497\n",
      "      6        \u001B[36m0.2960\u001B[0m       0.7851        0.7557  0.4620\n",
      "      7        \u001B[36m0.2551\u001B[0m       0.7736        0.8034  0.4760\n",
      "      8        \u001B[36m0.2068\u001B[0m       0.7950        0.8241  0.4489\n",
      "      9        \u001B[36m0.1846\u001B[0m       0.7620        0.9022  0.4675\n",
      "     10        \u001B[36m0.1698\u001B[0m       0.7504        0.9851  0.4556\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3418\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.7858\u001B[0m  0.6454\n",
      "      2        \u001B[36m0.8460\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.7043\u001B[0m  0.4640\n",
      "      3        \u001B[36m0.5935\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6537\u001B[0m  0.4622\n",
      "      4        \u001B[36m0.5070\u001B[0m       0.7917        0.6601  0.4576\n",
      "      5        \u001B[36m0.4157\u001B[0m       0.7917        \u001B[35m0.6324\u001B[0m  0.4415\n",
      "      6        \u001B[36m0.3716\u001B[0m       0.7851        0.7249  0.4618\n",
      "      7        \u001B[36m0.3187\u001B[0m       0.7769        0.7617  0.4528\n",
      "      8        \u001B[36m0.2935\u001B[0m       \u001B[32m0.8083\u001B[0m        0.6903  0.4566\n",
      "      9        \u001B[36m0.2599\u001B[0m       0.7967        0.7086  0.4671\n",
      "     10        \u001B[36m0.2404\u001B[0m       0.7884        0.8643  0.4683\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4109\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.8680\u001B[0m  0.4803\n",
      "      2        \u001B[36m0.8303\u001B[0m       0.7339        \u001B[35m0.8039\u001B[0m  0.4560\n",
      "      3        \u001B[36m0.6239\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.7764\u001B[0m  0.4691\n",
      "      4        \u001B[36m0.5346\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.7645\u001B[0m  0.4682\n",
      "      5        \u001B[36m0.4153\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7400\u001B[0m  0.4605\n",
      "      6        \u001B[36m0.3821\u001B[0m       0.7686        0.7671  0.4677\n",
      "      7        \u001B[36m0.2925\u001B[0m       \u001B[32m0.8066\u001B[0m        0.7822  0.4685\n",
      "      8        \u001B[36m0.2711\u001B[0m       0.7851        0.8787  0.4509\n",
      "      9        0.2874       0.7868        0.8128  0.4712\n",
      "     10        \u001B[36m0.2452\u001B[0m       0.7521        0.9715  0.4572\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3121\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.8345\u001B[0m  0.4537\n",
      "      2        \u001B[36m0.7655\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7265\u001B[0m  0.4596\n",
      "      3        \u001B[36m0.5889\u001B[0m       0.7686        0.7342  0.4667\n",
      "      4        \u001B[36m0.4491\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.6844\u001B[0m  0.4605\n",
      "      5        \u001B[36m0.3979\u001B[0m       0.7702        0.7789  0.4612\n",
      "      6        \u001B[36m0.3105\u001B[0m       \u001B[32m0.7884\u001B[0m        0.7560  0.4736\n",
      "      7        \u001B[36m0.2945\u001B[0m       0.7669        0.7575  0.4616\n",
      "      8        \u001B[36m0.2414\u001B[0m       0.7339        0.9057  0.4640\n",
      "      9        \u001B[36m0.2199\u001B[0m       0.7587        0.8866  0.4444\n",
      "     10        \u001B[36m0.2027\u001B[0m       0.7769        0.8625  0.4565\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6003\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.0590\u001B[0m  0.4772\n",
      "      2        \u001B[36m1.1081\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9056\u001B[0m  0.4591\n",
      "      3        \u001B[36m0.9097\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8245\u001B[0m  0.4858\n",
      "      4        \u001B[36m0.8094\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.7609\u001B[0m  0.4553\n",
      "      5        \u001B[36m0.7271\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.7219\u001B[0m  0.4531\n",
      "      6        \u001B[36m0.6558\u001B[0m       \u001B[32m0.7884\u001B[0m        0.7248  0.4566\n",
      "      7        \u001B[36m0.6254\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.6975\u001B[0m  0.4658\n",
      "      8        \u001B[36m0.5885\u001B[0m       0.7967        \u001B[35m0.6799\u001B[0m  0.4731\n",
      "      9        \u001B[36m0.5553\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6757\u001B[0m  0.4696\n",
      "     10        \u001B[36m0.5134\u001B[0m       \u001B[32m0.8116\u001B[0m        \u001B[35m0.6583\u001B[0m  0.4846\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6408\u001B[0m       \u001B[32m0.6446\u001B[0m        \u001B[35m1.1261\u001B[0m  0.5056\n",
      "      2        \u001B[36m1.0964\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.9320\u001B[0m  0.4925\n",
      "      3        \u001B[36m0.9136\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.8528\u001B[0m  0.4484\n",
      "      4        \u001B[36m0.7791\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8207\u001B[0m  0.4480\n",
      "      5        \u001B[36m0.7223\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7670\u001B[0m  0.4485\n",
      "      6        \u001B[36m0.6495\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.7532\u001B[0m  0.4490\n",
      "      7        \u001B[36m0.5928\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7360\u001B[0m  0.4509\n",
      "      8        \u001B[36m0.5528\u001B[0m       0.7719        \u001B[35m0.7204\u001B[0m  0.4736\n",
      "      9        \u001B[36m0.5144\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.7023\u001B[0m  0.4602\n",
      "     10        \u001B[36m0.4980\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.6970\u001B[0m  0.4543\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5658\u001B[0m       \u001B[32m0.6545\u001B[0m        \u001B[35m1.0983\u001B[0m  0.4621\n",
      "      2        \u001B[36m1.0910\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.9537\u001B[0m  0.4504\n",
      "      3        \u001B[36m0.8635\u001B[0m       \u001B[32m0.7587\u001B[0m        \u001B[35m0.8367\u001B[0m  0.4733\n",
      "      4        \u001B[36m0.7683\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7784\u001B[0m  0.4716\n",
      "      5        \u001B[36m0.6998\u001B[0m       0.7785        \u001B[35m0.7349\u001B[0m  0.4698\n",
      "      6        \u001B[36m0.6247\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.7160\u001B[0m  0.4577\n",
      "      7        \u001B[36m0.5681\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.6867\u001B[0m  0.4673\n",
      "      8        \u001B[36m0.5227\u001B[0m       0.7901        0.7185  0.4751\n",
      "      9        \u001B[36m0.4935\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6782\u001B[0m  0.4757\n",
      "     10        \u001B[36m0.4711\u001B[0m       0.7950        \u001B[35m0.6715\u001B[0m  0.4774\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7818\u001B[0m       \u001B[32m0.6182\u001B[0m        \u001B[35m1.1359\u001B[0m  0.5334\n",
      "      2        \u001B[36m1.1622\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m0.9993\u001B[0m  0.4590\n",
      "      3        \u001B[36m0.9859\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9021\u001B[0m  0.4411\n",
      "      4        \u001B[36m0.8779\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8365\u001B[0m  0.4408\n",
      "      5        \u001B[36m0.7781\u001B[0m       0.7471        \u001B[35m0.8092\u001B[0m  0.4444\n",
      "      6        \u001B[36m0.7277\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.7667\u001B[0m  0.4424\n",
      "      7        \u001B[36m0.6752\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7258\u001B[0m  0.4436\n",
      "      8        \u001B[36m0.6151\u001B[0m       0.7570        0.7620  0.4447\n",
      "      9        \u001B[36m0.5680\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.7123\u001B[0m  0.4432\n",
      "     10        \u001B[36m0.5383\u001B[0m       0.7818        \u001B[35m0.7107\u001B[0m  0.4570\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7330\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.0643\u001B[0m  0.4687\n",
      "      2        \u001B[36m1.1230\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9084\u001B[0m  0.4661\n",
      "      3        \u001B[36m0.9630\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8456\u001B[0m  0.4681\n",
      "      4        \u001B[36m0.8139\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7913\u001B[0m  0.4397\n",
      "      5        \u001B[36m0.7245\u001B[0m       0.7636        0.7925  0.4527\n",
      "      6        \u001B[36m0.7025\u001B[0m       0.7752        \u001B[35m0.7503\u001B[0m  0.4552\n",
      "      7        \u001B[36m0.6271\u001B[0m       0.7736        \u001B[35m0.7308\u001B[0m  0.4599\n",
      "      8        \u001B[36m0.5615\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.7279\u001B[0m  0.4685\n",
      "      9        \u001B[36m0.5417\u001B[0m       0.7769        \u001B[35m0.7172\u001B[0m  0.4590\n",
      "     10        \u001B[36m0.5083\u001B[0m       \u001B[32m0.7917\u001B[0m        0.7222  0.4655\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6284\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0672\u001B[0m  0.4678\n",
      "      2        \u001B[36m1.1099\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.8915\u001B[0m  0.4651\n",
      "      3        \u001B[36m0.9338\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.8214\u001B[0m  0.4636\n",
      "      4        \u001B[36m0.7910\u001B[0m       0.7620        \u001B[35m0.7925\u001B[0m  0.4515\n",
      "      5        \u001B[36m0.7062\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7487\u001B[0m  0.4631\n",
      "      6        \u001B[36m0.6553\u001B[0m       0.7603        \u001B[35m0.7331\u001B[0m  0.4530\n",
      "      7        \u001B[36m0.6005\u001B[0m       0.7686        \u001B[35m0.7205\u001B[0m  0.4569\n",
      "      8        \u001B[36m0.5840\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.7097\u001B[0m  0.4646\n",
      "      9        \u001B[36m0.5121\u001B[0m       0.7669        \u001B[35m0.7057\u001B[0m  0.4468\n",
      "     10        \u001B[36m0.4756\u001B[0m       0.7901        \u001B[35m0.6896\u001B[0m  0.4560\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7443\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m0.9952\u001B[0m  0.4657\n",
      "      2        \u001B[36m1.1403\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.8761\u001B[0m  0.4696\n",
      "      3        \u001B[36m0.9763\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.8252\u001B[0m  0.4605\n",
      "      4        \u001B[36m0.8060\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.7134\u001B[0m  0.4625\n",
      "      5        \u001B[36m0.7726\u001B[0m       \u001B[32m0.7719\u001B[0m        0.7291  0.4729\n",
      "      6        \u001B[36m0.7139\u001B[0m       0.7653        0.7156  0.4563\n",
      "      7        \u001B[36m0.6610\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7030\u001B[0m  0.4771\n",
      "      8        \u001B[36m0.5972\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.6567\u001B[0m  0.4626\n",
      "      9        \u001B[36m0.5776\u001B[0m       0.7818        0.6633  0.4751\n",
      "     10        \u001B[36m0.5251\u001B[0m       0.7917        \u001B[35m0.6443\u001B[0m  0.4755\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7601\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.0543\u001B[0m  0.4712\n",
      "      2        \u001B[36m1.1866\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9241\u001B[0m  0.4577\n",
      "      3        \u001B[36m0.9799\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.8802\u001B[0m  0.4718\n",
      "      4        \u001B[36m0.8872\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.8084\u001B[0m  0.4802\n",
      "      5        \u001B[36m0.8181\u001B[0m       0.7405        \u001B[35m0.8077\u001B[0m  0.4733\n",
      "      6        \u001B[36m0.6980\u001B[0m       0.7570        \u001B[35m0.7547\u001B[0m  0.4485\n",
      "      7        \u001B[36m0.6608\u001B[0m       0.7603        0.7678  0.4495\n",
      "      8        \u001B[36m0.5976\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7196\u001B[0m  0.4648\n",
      "      9        \u001B[36m0.5824\u001B[0m       0.7736        0.7296  0.4540\n",
      "     10        \u001B[36m0.5275\u001B[0m       \u001B[32m0.7802\u001B[0m        0.7366  0.4636\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6885\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m0.9836\u001B[0m  0.4829\n",
      "      2        \u001B[36m1.0747\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8407\u001B[0m  0.4624\n",
      "      3        \u001B[36m0.9200\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.7577\u001B[0m  0.4560\n",
      "      4        \u001B[36m0.8395\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7200\u001B[0m  0.4619\n",
      "      5        \u001B[36m0.7432\u001B[0m       0.7736        \u001B[35m0.6890\u001B[0m  0.4687\n",
      "      6        \u001B[36m0.6595\u001B[0m       0.7636        0.6979  0.4574\n",
      "      7        \u001B[36m0.6081\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.6702\u001B[0m  0.4588\n",
      "      8        \u001B[36m0.5436\u001B[0m       0.7769        \u001B[35m0.6585\u001B[0m  0.4522\n",
      "      9        \u001B[36m0.5330\u001B[0m       0.7719        0.6649  0.4611\n",
      "     10        \u001B[36m0.4961\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.6490\u001B[0m  0.4587\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4772\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m0.9529\u001B[0m  0.4647\n",
      "      2        \u001B[36m0.9264\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.7809\u001B[0m  0.4726\n",
      "      3        \u001B[36m0.7859\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.7213\u001B[0m  0.4555\n",
      "      4        \u001B[36m0.6594\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.6755\u001B[0m  0.4842\n",
      "      5        \u001B[36m0.5829\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6478\u001B[0m  0.4593\n",
      "      6        \u001B[36m0.5410\u001B[0m       0.8000        0.6585  0.4735\n",
      "      7        \u001B[36m0.4697\u001B[0m       0.8050        \u001B[35m0.6244\u001B[0m  0.4923\n",
      "      8        \u001B[36m0.4201\u001B[0m       0.8033        \u001B[35m0.6213\u001B[0m  0.4617\n",
      "      9        \u001B[36m0.3988\u001B[0m       \u001B[32m0.8198\u001B[0m        \u001B[35m0.6179\u001B[0m  0.4600\n",
      "     10        \u001B[36m0.3700\u001B[0m       0.8033        0.6525  0.4639\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4898\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.0163\u001B[0m  0.4769\n",
      "      2        \u001B[36m0.9411\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.8648\u001B[0m  0.4685\n",
      "      3        \u001B[36m0.7598\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7695\u001B[0m  0.4610\n",
      "      4        \u001B[36m0.6616\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7285\u001B[0m  0.4854\n",
      "      5        \u001B[36m0.5577\u001B[0m       \u001B[32m0.8099\u001B[0m        0.7329  0.5754\n",
      "      6        \u001B[36m0.5206\u001B[0m       \u001B[32m0.8182\u001B[0m        0.7623  0.4653\n",
      "      7        \u001B[36m0.4510\u001B[0m       0.8099        \u001B[35m0.7007\u001B[0m  0.4451\n",
      "      8        \u001B[36m0.4131\u001B[0m       0.8149        \u001B[35m0.6846\u001B[0m  0.4523\n",
      "      9        \u001B[36m0.4046\u001B[0m       \u001B[32m0.8198\u001B[0m        0.7045  0.4481\n",
      "     10        \u001B[36m0.3575\u001B[0m       0.8132        0.7250  0.4460\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4840\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m0.9447\u001B[0m  0.4567\n",
      "      2        \u001B[36m0.9207\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7878\u001B[0m  0.4393\n",
      "      3        \u001B[36m0.7393\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.7348\u001B[0m  0.4488\n",
      "      4        \u001B[36m0.6200\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7234\u001B[0m  0.4467\n",
      "      5        \u001B[36m0.5579\u001B[0m       0.7983        \u001B[35m0.7029\u001B[0m  0.4363\n",
      "      6        \u001B[36m0.5049\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6845\u001B[0m  0.4545\n",
      "      7        \u001B[36m0.4293\u001B[0m       0.7917        \u001B[35m0.6783\u001B[0m  0.4490\n",
      "      8        \u001B[36m0.3909\u001B[0m       0.7901        0.6843  0.4533\n",
      "      9        \u001B[36m0.3618\u001B[0m       0.7917        0.6853  0.4489\n",
      "     10        \u001B[36m0.3294\u001B[0m       \u001B[32m0.8116\u001B[0m        \u001B[35m0.6496\u001B[0m  0.4682\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5600\u001B[0m       \u001B[32m0.6777\u001B[0m        \u001B[35m0.9771\u001B[0m  0.4727\n",
      "      2        \u001B[36m0.9912\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.8432\u001B[0m  0.4441\n",
      "      3        \u001B[36m0.8131\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7625\u001B[0m  0.4479\n",
      "      4        \u001B[36m0.6856\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6850\u001B[0m  0.4411\n",
      "      5        \u001B[36m0.5987\u001B[0m       0.7917        0.7137  0.4402\n",
      "      6        \u001B[36m0.5582\u001B[0m       \u001B[32m0.8132\u001B[0m        \u001B[35m0.6729\u001B[0m  0.4344\n",
      "      7        \u001B[36m0.4988\u001B[0m       0.7851        0.6953  0.4388\n",
      "      8        \u001B[36m0.4517\u001B[0m       0.7983        \u001B[35m0.6518\u001B[0m  0.4426\n",
      "      9        \u001B[36m0.4200\u001B[0m       0.8099        0.6519  0.4549\n",
      "     10        \u001B[36m0.3960\u001B[0m       0.8083        0.6699  0.4409\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5056\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m0.9305\u001B[0m  0.4432\n",
      "      2        \u001B[36m0.9718\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7700\u001B[0m  0.4512\n",
      "      3        \u001B[36m0.7557\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.6991\u001B[0m  0.4675\n",
      "      4        \u001B[36m0.6959\u001B[0m       0.7917        0.7082  0.4788\n",
      "      5        \u001B[36m0.5926\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6855\u001B[0m  0.4749\n",
      "      6        \u001B[36m0.5237\u001B[0m       0.8033        \u001B[35m0.6762\u001B[0m  0.4495\n",
      "      7        \u001B[36m0.4926\u001B[0m       0.8066        \u001B[35m0.6483\u001B[0m  0.4495\n",
      "      8        \u001B[36m0.4664\u001B[0m       0.8066        0.6681  0.4525\n",
      "      9        \u001B[36m0.4275\u001B[0m       \u001B[32m0.8099\u001B[0m        0.6597  0.4586\n",
      "     10        \u001B[36m0.3805\u001B[0m       0.7851        0.6860  0.4416\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5326\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.8799\u001B[0m  0.4323\n",
      "      2        \u001B[36m0.9575\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.7847\u001B[0m  0.4473\n",
      "      3        \u001B[36m0.7615\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7092\u001B[0m  0.4658\n",
      "      4        \u001B[36m0.6551\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.6684\u001B[0m  0.4521\n",
      "      5        \u001B[36m0.5589\u001B[0m       0.7802        0.6723  0.4487\n",
      "      6        \u001B[36m0.5140\u001B[0m       0.7785        \u001B[35m0.6543\u001B[0m  0.4372\n",
      "      7        \u001B[36m0.4650\u001B[0m       0.7769        \u001B[35m0.6477\u001B[0m  0.4529\n",
      "      8        \u001B[36m0.4321\u001B[0m       0.7702        0.6754  0.4596\n",
      "      9        \u001B[36m0.3888\u001B[0m       0.7950        0.6545  0.4581\n",
      "     10        \u001B[36m0.3613\u001B[0m       0.7719        0.6813  0.4444\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6855\u001B[0m       \u001B[32m0.6545\u001B[0m        \u001B[35m0.9924\u001B[0m  0.4321\n",
      "      2        \u001B[36m1.1033\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.8534\u001B[0m  0.4509\n",
      "      3        \u001B[36m0.8556\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.7632\u001B[0m  0.4510\n",
      "      4        \u001B[36m0.7629\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7442\u001B[0m  0.4555\n",
      "      5        \u001B[36m0.6707\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7108\u001B[0m  0.4270\n",
      "      6        \u001B[36m0.6103\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.6818\u001B[0m  0.4427\n",
      "      7        \u001B[36m0.5300\u001B[0m       0.7851        \u001B[35m0.6602\u001B[0m  0.4412\n",
      "      8        \u001B[36m0.4765\u001B[0m       0.7785        0.6963  0.4498\n",
      "      9        0.4899       0.7818        0.6870  0.4643\n",
      "     10        \u001B[36m0.4434\u001B[0m       0.7620        0.7117  0.4306\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5330\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m0.9199\u001B[0m  0.4496\n",
      "      2        \u001B[36m1.0050\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.8270\u001B[0m  0.4374\n",
      "      3        \u001B[36m0.8415\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.7547\u001B[0m  0.4498\n",
      "      4        \u001B[36m0.7277\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.7054\u001B[0m  0.4625\n",
      "      5        \u001B[36m0.6393\u001B[0m       0.7587        0.7274  0.4358\n",
      "      6        \u001B[36m0.5710\u001B[0m       0.7570        0.7156  0.4561\n",
      "      7        \u001B[36m0.5205\u001B[0m       0.7372        0.7470  0.4337\n",
      "      8        \u001B[36m0.4698\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.6572\u001B[0m  0.4495\n",
      "      9        \u001B[36m0.4475\u001B[0m       0.7620        0.7088  0.4558\n",
      "     10        \u001B[36m0.4154\u001B[0m       0.7736        0.7186  0.4496\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6269\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m0.9250\u001B[0m  0.4465\n",
      "      2        \u001B[36m0.9890\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.8302\u001B[0m  0.4415\n",
      "      3        \u001B[36m0.8305\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7711\u001B[0m  0.4474\n",
      "      4        \u001B[36m0.6804\u001B[0m       0.7537        \u001B[35m0.7563\u001B[0m  0.4543\n",
      "      5        \u001B[36m0.6100\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7079\u001B[0m  0.4502\n",
      "      6        \u001B[36m0.5591\u001B[0m       0.7686        0.7081  0.4383\n",
      "      7        \u001B[36m0.5027\u001B[0m       0.7702        0.7233  0.4339\n",
      "      8        \u001B[36m0.4709\u001B[0m       0.7835        \u001B[35m0.6998\u001B[0m  0.4485\n",
      "      9        \u001B[36m0.4123\u001B[0m       0.7570        0.7304  0.4530\n",
      "     10        \u001B[36m0.3694\u001B[0m       0.7785        0.7143  0.4319\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4284\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.8149\u001B[0m  0.4561\n",
      "      2        \u001B[36m0.7926\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7015\u001B[0m  0.4357\n",
      "      3        \u001B[36m0.6102\u001B[0m       0.7967        \u001B[35m0.6731\u001B[0m  0.4471\n",
      "      4        \u001B[36m0.5492\u001B[0m       \u001B[32m0.8149\u001B[0m        0.6828  0.4573\n",
      "      5        \u001B[36m0.4524\u001B[0m       \u001B[32m0.8182\u001B[0m        \u001B[35m0.6416\u001B[0m  0.4471\n",
      "      6        \u001B[36m0.4109\u001B[0m       \u001B[32m0.8198\u001B[0m        0.6530  0.4366\n",
      "      7        \u001B[36m0.3581\u001B[0m       0.8066        \u001B[35m0.6338\u001B[0m  0.4374\n",
      "      8        \u001B[36m0.3059\u001B[0m       0.8165        0.6707  0.4407\n",
      "      9        \u001B[36m0.2808\u001B[0m       0.7983        0.6749  0.4503\n",
      "     10        \u001B[36m0.2534\u001B[0m       0.8149        0.6424  0.4580\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3971\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.8333\u001B[0m  0.4321\n",
      "      2        \u001B[36m0.7873\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.7672\u001B[0m  0.4404\n",
      "      3        \u001B[36m0.6047\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7050\u001B[0m  0.4404\n",
      "      4        \u001B[36m0.5167\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6673\u001B[0m  0.4537\n",
      "      5        \u001B[36m0.4260\u001B[0m       0.8000        \u001B[35m0.6632\u001B[0m  0.4349\n",
      "      6        \u001B[36m0.3831\u001B[0m       0.7967        0.6869  0.4550\n",
      "      7        \u001B[36m0.3356\u001B[0m       \u001B[32m0.8215\u001B[0m        \u001B[35m0.6383\u001B[0m  0.4317\n",
      "      8        \u001B[36m0.3220\u001B[0m       0.8215        0.6852  0.4488\n",
      "      9        \u001B[36m0.2921\u001B[0m       0.8116        0.6503  0.4530\n",
      "     10        \u001B[36m0.2675\u001B[0m       0.8132        0.7316  0.4405\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3688\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8742\u001B[0m  0.4572\n",
      "      2        \u001B[36m0.7566\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7435\u001B[0m  0.4385\n",
      "      3        \u001B[36m0.5976\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.6956\u001B[0m  0.4414\n",
      "      4        \u001B[36m0.4864\u001B[0m       \u001B[32m0.8099\u001B[0m        \u001B[35m0.6857\u001B[0m  0.4492\n",
      "      5        \u001B[36m0.4041\u001B[0m       \u001B[32m0.8231\u001B[0m        0.6925  0.4571\n",
      "      6        \u001B[36m0.3730\u001B[0m       0.8066        0.6950  0.4341\n",
      "      7        \u001B[36m0.3048\u001B[0m       0.8132        0.6882  0.4422\n",
      "      8        \u001B[36m0.2708\u001B[0m       0.8149        0.7111  0.4326\n",
      "      9        \u001B[36m0.2634\u001B[0m       0.8000        0.7729  0.4415\n",
      "     10        \u001B[36m0.2292\u001B[0m       0.7934        0.8010  0.4447\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4601\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8711\u001B[0m  0.4659\n",
      "      2        \u001B[36m0.8619\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7669\u001B[0m  0.4896\n",
      "      3        \u001B[36m0.6757\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6695\u001B[0m  0.4569\n",
      "      4        \u001B[36m0.5742\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.6532\u001B[0m  0.4309\n",
      "      5        \u001B[36m0.4770\u001B[0m       \u001B[32m0.8033\u001B[0m        0.6760  0.4261\n",
      "      6        \u001B[36m0.4653\u001B[0m       0.7983        0.6903  0.4246\n",
      "      7        \u001B[36m0.3951\u001B[0m       0.7967        0.6747  0.4296\n",
      "      8        \u001B[36m0.3563\u001B[0m       \u001B[32m0.8116\u001B[0m        0.6883  0.4469\n",
      "      9        \u001B[36m0.3199\u001B[0m       0.8066        0.6949  0.4320\n",
      "     10        \u001B[36m0.2900\u001B[0m       0.7983        0.7996  0.4450\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4010\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.8472\u001B[0m  0.4750\n",
      "      2        \u001B[36m0.8537\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7714\u001B[0m  0.4382\n",
      "      3        \u001B[36m0.6915\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6882\u001B[0m  0.4426\n",
      "      4        \u001B[36m0.5633\u001B[0m       0.7884        \u001B[35m0.6844\u001B[0m  0.4328\n",
      "      5        \u001B[36m0.4902\u001B[0m       0.7818        \u001B[35m0.6513\u001B[0m  0.4511\n",
      "      6        \u001B[36m0.4370\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6104\u001B[0m  0.4556\n",
      "      7        \u001B[36m0.3983\u001B[0m       0.7983        0.6485  0.4470\n",
      "      8        \u001B[36m0.3541\u001B[0m       0.7983        0.6391  0.4421\n",
      "      9        \u001B[36m0.3245\u001B[0m       0.7785        0.6772  0.4225\n",
      "     10        \u001B[36m0.3015\u001B[0m       0.7818        0.6910  0.4389\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3837\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8438\u001B[0m  0.4432\n",
      "      2        \u001B[36m0.7743\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.8013\u001B[0m  0.4395\n",
      "      3        \u001B[36m0.6195\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.7245\u001B[0m  0.4453\n",
      "      4        \u001B[36m0.4964\u001B[0m       0.7835        0.7304  0.4610\n",
      "      5        \u001B[36m0.4294\u001B[0m       0.7851        \u001B[35m0.7157\u001B[0m  0.4537\n",
      "      6        \u001B[36m0.3843\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7016\u001B[0m  0.4264\n",
      "      7        \u001B[36m0.3385\u001B[0m       0.7802        0.7622  0.4435\n",
      "      8        \u001B[36m0.2855\u001B[0m       0.7686        0.7732  0.4332\n",
      "      9        0.2906       \u001B[32m0.8000\u001B[0m        0.7224  0.4425\n",
      "     10        \u001B[36m0.2653\u001B[0m       0.7785        0.8909  0.4529\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5193\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.8681\u001B[0m  0.4539\n",
      "      2        \u001B[36m0.9700\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.8249\u001B[0m  0.4394\n",
      "      3        \u001B[36m0.7434\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.7469\u001B[0m  0.4459\n",
      "      4        \u001B[36m0.6206\u001B[0m       \u001B[32m0.8099\u001B[0m        \u001B[35m0.6787\u001B[0m  0.4401\n",
      "      5        \u001B[36m0.5344\u001B[0m       0.7983        0.6999  0.4417\n",
      "      6        \u001B[36m0.4789\u001B[0m       0.8099        0.7099  0.4676\n",
      "      7        \u001B[36m0.4206\u001B[0m       \u001B[32m0.8198\u001B[0m        0.6959  0.4237\n",
      "      8        \u001B[36m0.3740\u001B[0m       0.7934        0.7328  0.4586\n",
      "      9        \u001B[36m0.3354\u001B[0m       0.7983        0.7752  0.4330\n",
      "     10        \u001B[36m0.3024\u001B[0m       0.8017        0.7445  0.4486\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4336\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m0.9050\u001B[0m  0.4536\n",
      "      2        \u001B[36m0.9590\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.8591\u001B[0m  0.4341\n",
      "      3        \u001B[36m0.7306\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7663\u001B[0m  0.4440\n",
      "      4        \u001B[36m0.6220\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.7232\u001B[0m  0.4324\n",
      "      5        \u001B[36m0.5392\u001B[0m       0.7471        0.7882  0.4614\n",
      "      6        \u001B[36m0.4759\u001B[0m       0.7835        \u001B[35m0.7139\u001B[0m  0.4324\n",
      "      7        \u001B[36m0.4186\u001B[0m       0.7835        \u001B[35m0.7118\u001B[0m  0.4407\n",
      "      8        \u001B[36m0.3750\u001B[0m       0.7669        0.7537  0.4616\n",
      "      9        \u001B[36m0.3454\u001B[0m       0.7521        0.8209  0.4324\n",
      "     10        \u001B[36m0.3166\u001B[0m       0.7355        0.8558  0.4370\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4809\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.8792\u001B[0m  0.4528\n",
      "      2        \u001B[36m0.8972\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7600\u001B[0m  0.4445\n",
      "      3        \u001B[36m0.7184\u001B[0m       0.7636        0.8242  0.4571\n",
      "      4        \u001B[36m0.5682\u001B[0m       \u001B[32m0.7785\u001B[0m        0.7909  0.5234\n",
      "      5        \u001B[36m0.5050\u001B[0m       0.7587        0.7866  0.5298\n",
      "      6        \u001B[36m0.4335\u001B[0m       0.7421        0.7911  0.4963\n",
      "      7        \u001B[36m0.4049\u001B[0m       0.7554        0.8163  0.4635\n",
      "      8        \u001B[36m0.3512\u001B[0m       \u001B[32m0.7835\u001B[0m        0.7737  0.4917\n",
      "      9        \u001B[36m0.3073\u001B[0m       0.7769        0.7652  0.4405\n",
      "     10        \u001B[36m0.2945\u001B[0m       0.7818        0.8804  0.4666\n",
      "[CV] END batch_size=32, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1369\u001B[0m       \u001B[32m0.3835\u001B[0m        \u001B[35m1.6519\u001B[0m  0.4457\n",
      "      2        \u001B[36m1.8246\u001B[0m       \u001B[32m0.4298\u001B[0m        \u001B[35m1.4743\u001B[0m  0.4400\n",
      "      3        \u001B[36m1.6136\u001B[0m       \u001B[32m0.4926\u001B[0m        \u001B[35m1.3683\u001B[0m  0.4947\n",
      "      4        \u001B[36m1.5110\u001B[0m       \u001B[32m0.5372\u001B[0m        \u001B[35m1.2915\u001B[0m  0.5098\n",
      "      5        \u001B[36m1.3934\u001B[0m       \u001B[32m0.5537\u001B[0m        \u001B[35m1.2362\u001B[0m  0.4823\n",
      "      6        \u001B[36m1.3166\u001B[0m       \u001B[32m0.5736\u001B[0m        \u001B[35m1.1926\u001B[0m  0.4828\n",
      "      7        \u001B[36m1.2750\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.1501\u001B[0m  0.4498\n",
      "      8        \u001B[36m1.2033\u001B[0m       \u001B[32m0.6215\u001B[0m        \u001B[35m1.1099\u001B[0m  0.4548\n",
      "      9        \u001B[36m1.1674\u001B[0m       \u001B[32m0.6479\u001B[0m        \u001B[35m1.0840\u001B[0m  0.5012\n",
      "     10        \u001B[36m1.1122\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.0548\u001B[0m  0.4632\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2199\u001B[0m       \u001B[32m0.3124\u001B[0m        \u001B[35m1.6876\u001B[0m  0.5400\n",
      "      2        \u001B[36m1.8402\u001B[0m       \u001B[32m0.4231\u001B[0m        \u001B[35m1.5100\u001B[0m  0.4628\n",
      "      3        \u001B[36m1.6123\u001B[0m       \u001B[32m0.4645\u001B[0m        \u001B[35m1.4084\u001B[0m  0.4517\n",
      "      4        \u001B[36m1.4745\u001B[0m       \u001B[32m0.5041\u001B[0m        \u001B[35m1.3347\u001B[0m  0.4526\n",
      "      5        \u001B[36m1.3933\u001B[0m       \u001B[32m0.5355\u001B[0m        \u001B[35m1.2694\u001B[0m  0.4418\n",
      "      6        \u001B[36m1.3027\u001B[0m       \u001B[32m0.5785\u001B[0m        \u001B[35m1.2343\u001B[0m  0.4563\n",
      "      7        \u001B[36m1.2525\u001B[0m       \u001B[32m0.6017\u001B[0m        \u001B[35m1.1845\u001B[0m  0.4448\n",
      "      8        \u001B[36m1.1640\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.1465\u001B[0m  0.4508\n",
      "      9        \u001B[36m1.1427\u001B[0m       \u001B[32m0.6347\u001B[0m        \u001B[35m1.1028\u001B[0m  0.4484\n",
      "     10        \u001B[36m1.0985\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.0843\u001B[0m  0.4369\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2485\u001B[0m       \u001B[32m0.3587\u001B[0m        \u001B[35m1.6965\u001B[0m  0.4484\n",
      "      2        \u001B[36m1.8486\u001B[0m       \u001B[32m0.4579\u001B[0m        \u001B[35m1.4926\u001B[0m  0.4404\n",
      "      3        \u001B[36m1.6647\u001B[0m       \u001B[32m0.5174\u001B[0m        \u001B[35m1.3763\u001B[0m  0.4500\n",
      "      4        \u001B[36m1.5338\u001B[0m       \u001B[32m0.5388\u001B[0m        \u001B[35m1.2997\u001B[0m  0.4521\n",
      "      5        \u001B[36m1.3954\u001B[0m       \u001B[32m0.5702\u001B[0m        \u001B[35m1.2462\u001B[0m  0.5084\n",
      "      6        \u001B[36m1.3325\u001B[0m       \u001B[32m0.5818\u001B[0m        \u001B[35m1.1976\u001B[0m  0.4455\n",
      "      7        \u001B[36m1.2550\u001B[0m       \u001B[32m0.6017\u001B[0m        \u001B[35m1.1488\u001B[0m  0.4457\n",
      "      8        \u001B[36m1.2028\u001B[0m       \u001B[32m0.6198\u001B[0m        \u001B[35m1.1178\u001B[0m  0.4595\n",
      "      9        \u001B[36m1.1443\u001B[0m       \u001B[32m0.6364\u001B[0m        \u001B[35m1.0874\u001B[0m  0.5003\n",
      "     10        \u001B[36m1.0714\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.0621\u001B[0m  0.4548\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3602\u001B[0m       \u001B[32m0.2744\u001B[0m        \u001B[35m1.7524\u001B[0m  0.4337\n",
      "      2        \u001B[36m1.8119\u001B[0m       \u001B[32m0.3934\u001B[0m        \u001B[35m1.4923\u001B[0m  0.4495\n",
      "      3        \u001B[36m1.6679\u001B[0m       \u001B[32m0.4678\u001B[0m        \u001B[35m1.3713\u001B[0m  0.4355\n",
      "      4        \u001B[36m1.5035\u001B[0m       \u001B[32m0.5455\u001B[0m        \u001B[35m1.2793\u001B[0m  0.4524\n",
      "      5        \u001B[36m1.3873\u001B[0m       \u001B[32m0.5983\u001B[0m        \u001B[35m1.2166\u001B[0m  0.4404\n",
      "      6        \u001B[36m1.3196\u001B[0m       \u001B[32m0.6298\u001B[0m        \u001B[35m1.1703\u001B[0m  0.4351\n",
      "      7        \u001B[36m1.2386\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.1376\u001B[0m  0.4353\n",
      "      8        \u001B[36m1.1727\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0985\u001B[0m  0.4579\n",
      "      9        \u001B[36m1.1188\u001B[0m       \u001B[32m0.6777\u001B[0m        \u001B[35m1.0660\u001B[0m  0.4301\n",
      "     10        \u001B[36m1.0884\u001B[0m       \u001B[32m0.6810\u001B[0m        \u001B[35m1.0400\u001B[0m  0.4775\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2391\u001B[0m       \u001B[32m0.3388\u001B[0m        \u001B[35m1.6169\u001B[0m  0.4969\n",
      "      2        \u001B[36m1.8199\u001B[0m       \u001B[32m0.4364\u001B[0m        \u001B[35m1.4194\u001B[0m  0.4236\n",
      "      3        \u001B[36m1.6106\u001B[0m       \u001B[32m0.5107\u001B[0m        \u001B[35m1.3052\u001B[0m  0.4253\n",
      "      4        \u001B[36m1.5081\u001B[0m       \u001B[32m0.5818\u001B[0m        \u001B[35m1.2276\u001B[0m  0.4223\n",
      "      5        \u001B[36m1.4000\u001B[0m       \u001B[32m0.6050\u001B[0m        \u001B[35m1.1785\u001B[0m  0.4240\n",
      "      6        \u001B[36m1.2819\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.1320\u001B[0m  0.4214\n",
      "      7        \u001B[36m1.2245\u001B[0m       \u001B[32m0.6264\u001B[0m        \u001B[35m1.0946\u001B[0m  0.4222\n",
      "      8        \u001B[36m1.1939\u001B[0m       \u001B[32m0.6479\u001B[0m        \u001B[35m1.0636\u001B[0m  0.4452\n",
      "      9        \u001B[36m1.1159\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.0403\u001B[0m  0.4261\n",
      "     10        \u001B[36m1.0854\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0165\u001B[0m  0.4463\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.5224\u001B[0m       \u001B[32m0.2727\u001B[0m        \u001B[35m1.7448\u001B[0m  0.4408\n",
      "      2        \u001B[36m1.9117\u001B[0m       \u001B[32m0.4132\u001B[0m        \u001B[35m1.4979\u001B[0m  0.4338\n",
      "      3        \u001B[36m1.6599\u001B[0m       \u001B[32m0.5074\u001B[0m        \u001B[35m1.3853\u001B[0m  0.4386\n",
      "      4        \u001B[36m1.5712\u001B[0m       \u001B[32m0.5521\u001B[0m        \u001B[35m1.2960\u001B[0m  0.4443\n",
      "      5        \u001B[36m1.4535\u001B[0m       \u001B[32m0.5669\u001B[0m        \u001B[35m1.2403\u001B[0m  0.4379\n",
      "      6        \u001B[36m1.3194\u001B[0m       \u001B[32m0.5917\u001B[0m        \u001B[35m1.1872\u001B[0m  0.4391\n",
      "      7        \u001B[36m1.2641\u001B[0m       \u001B[32m0.6066\u001B[0m        \u001B[35m1.1516\u001B[0m  0.4531\n",
      "      8        \u001B[36m1.2477\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1057\u001B[0m  0.4338\n",
      "      9        \u001B[36m1.1636\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.0712\u001B[0m  0.4336\n",
      "     10        \u001B[36m1.1089\u001B[0m       \u001B[32m0.6777\u001B[0m        \u001B[35m1.0377\u001B[0m  0.4465\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3056\u001B[0m       \u001B[32m0.4182\u001B[0m        \u001B[35m1.5552\u001B[0m  0.4520\n",
      "      2        \u001B[36m1.8712\u001B[0m       \u001B[32m0.5025\u001B[0m        \u001B[35m1.3781\u001B[0m  0.4391\n",
      "      3        \u001B[36m1.6430\u001B[0m       \u001B[32m0.5570\u001B[0m        \u001B[35m1.2498\u001B[0m  0.4715\n",
      "      4        \u001B[36m1.4696\u001B[0m       \u001B[32m0.6066\u001B[0m        \u001B[35m1.1721\u001B[0m  0.4343\n",
      "      5        \u001B[36m1.3798\u001B[0m       \u001B[32m0.6512\u001B[0m        \u001B[35m1.1046\u001B[0m  0.4585\n",
      "      6        \u001B[36m1.2816\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0655\u001B[0m  0.4404\n",
      "      7        \u001B[36m1.2343\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m1.0318\u001B[0m  0.4477\n",
      "      8        \u001B[36m1.1659\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m0.9882\u001B[0m  0.4569\n",
      "      9        \u001B[36m1.0872\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9735\u001B[0m  0.4382\n",
      "     10        \u001B[36m1.0585\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.9469\u001B[0m  0.4391\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3129\u001B[0m       \u001B[32m0.3802\u001B[0m        \u001B[35m1.6125\u001B[0m  0.4338\n",
      "      2        \u001B[36m1.7527\u001B[0m       \u001B[32m0.4810\u001B[0m        \u001B[35m1.4168\u001B[0m  0.4374\n",
      "      3        \u001B[36m1.5602\u001B[0m       \u001B[32m0.5455\u001B[0m        \u001B[35m1.3122\u001B[0m  0.4444\n",
      "      4        \u001B[36m1.4467\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.2170\u001B[0m  0.4457\n",
      "      5        \u001B[36m1.3511\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.1648\u001B[0m  0.4368\n",
      "      6        \u001B[36m1.2558\u001B[0m       \u001B[32m0.6364\u001B[0m        \u001B[35m1.1111\u001B[0m  0.4580\n",
      "      7        \u001B[36m1.1846\u001B[0m       \u001B[32m0.6562\u001B[0m        \u001B[35m1.0752\u001B[0m  0.4419\n",
      "      8        \u001B[36m1.1228\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0457\u001B[0m  0.4467\n",
      "      9        \u001B[36m1.0803\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m1.0073\u001B[0m  0.4367\n",
      "     10        \u001B[36m1.0323\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m0.9788\u001B[0m  0.4352\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1601\u001B[0m       \u001B[32m0.4116\u001B[0m        \u001B[35m1.6287\u001B[0m  0.4466\n",
      "      2        \u001B[36m1.7454\u001B[0m       \u001B[32m0.4810\u001B[0m        \u001B[35m1.4420\u001B[0m  0.4407\n",
      "      3        \u001B[36m1.5974\u001B[0m       \u001B[32m0.5405\u001B[0m        \u001B[35m1.3391\u001B[0m  0.4493\n",
      "      4        \u001B[36m1.4177\u001B[0m       \u001B[32m0.5818\u001B[0m        \u001B[35m1.2580\u001B[0m  0.4228\n",
      "      5        \u001B[36m1.3304\u001B[0m       \u001B[32m0.6198\u001B[0m        \u001B[35m1.1947\u001B[0m  0.4274\n",
      "      6        \u001B[36m1.2307\u001B[0m       \u001B[32m0.6347\u001B[0m        \u001B[35m1.1348\u001B[0m  0.4403\n",
      "      7        \u001B[36m1.1507\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0902\u001B[0m  0.4238\n",
      "      8        \u001B[36m1.0947\u001B[0m       \u001B[32m0.6727\u001B[0m        \u001B[35m1.0454\u001B[0m  0.4366\n",
      "      9        \u001B[36m1.0477\u001B[0m       \u001B[32m0.6760\u001B[0m        \u001B[35m1.0265\u001B[0m  0.4247\n",
      "     10        \u001B[36m0.9994\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m1.0032\u001B[0m  0.4278\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2984\u001B[0m       \u001B[32m0.3140\u001B[0m        \u001B[35m1.6902\u001B[0m  0.4171\n",
      "      2        \u001B[36m1.6849\u001B[0m       \u001B[32m0.4876\u001B[0m        \u001B[35m1.4269\u001B[0m  0.4296\n",
      "      3        \u001B[36m1.4535\u001B[0m       \u001B[32m0.5636\u001B[0m        \u001B[35m1.3140\u001B[0m  0.4394\n",
      "      4        \u001B[36m1.3270\u001B[0m       \u001B[32m0.6165\u001B[0m        \u001B[35m1.2240\u001B[0m  0.4365\n",
      "      5        \u001B[36m1.2167\u001B[0m       \u001B[32m0.6347\u001B[0m        \u001B[35m1.1644\u001B[0m  0.4395\n",
      "      6        \u001B[36m1.1392\u001B[0m       \u001B[32m0.6678\u001B[0m        \u001B[35m1.1131\u001B[0m  0.4953\n",
      "      7        \u001B[36m1.0485\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m1.0703\u001B[0m  0.5009\n",
      "      8        \u001B[36m0.9941\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m1.0410\u001B[0m  0.4192\n",
      "      9        \u001B[36m0.9474\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m1.0096\u001B[0m  0.4161\n",
      "     10        \u001B[36m0.8857\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9817\u001B[0m  0.4181\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1498\u001B[0m       \u001B[32m0.3983\u001B[0m        \u001B[35m1.5970\u001B[0m  0.4158\n",
      "      2        \u001B[36m1.6668\u001B[0m       \u001B[32m0.4727\u001B[0m        \u001B[35m1.3898\u001B[0m  0.4179\n",
      "      3        \u001B[36m1.4422\u001B[0m       \u001B[32m0.5240\u001B[0m        \u001B[35m1.2610\u001B[0m  0.4177\n",
      "      4        \u001B[36m1.3039\u001B[0m       \u001B[32m0.5653\u001B[0m        \u001B[35m1.1775\u001B[0m  0.4165\n",
      "      5        \u001B[36m1.1983\u001B[0m       \u001B[32m0.6099\u001B[0m        \u001B[35m1.1173\u001B[0m  0.4192\n",
      "      6        \u001B[36m1.1193\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.0654\u001B[0m  0.4382\n",
      "      7        \u001B[36m1.0707\u001B[0m       \u001B[32m0.6446\u001B[0m        \u001B[35m1.0259\u001B[0m  0.4401\n",
      "      8        \u001B[36m1.0001\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m0.9949\u001B[0m  0.4478\n",
      "      9        \u001B[36m0.9394\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m0.9625\u001B[0m  0.4372\n",
      "     10        \u001B[36m0.8833\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9353\u001B[0m  0.4424\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9839\u001B[0m       \u001B[32m0.4198\u001B[0m        \u001B[35m1.5560\u001B[0m  0.4378\n",
      "      2        \u001B[36m1.5597\u001B[0m       \u001B[32m0.5355\u001B[0m        \u001B[35m1.3516\u001B[0m  0.4430\n",
      "      3        \u001B[36m1.3736\u001B[0m       \u001B[32m0.5917\u001B[0m        \u001B[35m1.2320\u001B[0m  0.4302\n",
      "      4        \u001B[36m1.2352\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1498\u001B[0m  0.4392\n",
      "      5        \u001B[36m1.1637\u001B[0m       \u001B[32m0.6479\u001B[0m        \u001B[35m1.0942\u001B[0m  0.4270\n",
      "      6        \u001B[36m1.0545\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m1.0445\u001B[0m  0.4323\n",
      "      7        \u001B[36m0.9958\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m0.9968\u001B[0m  0.4596\n",
      "      8        \u001B[36m0.9496\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9690\u001B[0m  0.4346\n",
      "      9        \u001B[36m0.8898\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.9356\u001B[0m  0.4302\n",
      "     10        \u001B[36m0.8440\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.9096\u001B[0m  0.4387\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9982\u001B[0m       \u001B[32m0.4645\u001B[0m        \u001B[35m1.4586\u001B[0m  0.4250\n",
      "      2        \u001B[36m1.5785\u001B[0m       \u001B[32m0.5669\u001B[0m        \u001B[35m1.2679\u001B[0m  0.4349\n",
      "      3        \u001B[36m1.3836\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1619\u001B[0m  0.4310\n",
      "      4        \u001B[36m1.2634\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m1.0839\u001B[0m  0.4538\n",
      "      5        \u001B[36m1.1580\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m1.0288\u001B[0m  0.4496\n",
      "      6        \u001B[36m1.0688\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9776\u001B[0m  0.4224\n",
      "      7        \u001B[36m1.0184\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.9438\u001B[0m  0.4456\n",
      "      8        \u001B[36m0.9534\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.9136\u001B[0m  0.4375\n",
      "      9        \u001B[36m0.9036\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8856\u001B[0m  0.4377\n",
      "     10        \u001B[36m0.8695\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.8572\u001B[0m  0.4376\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1016\u001B[0m       \u001B[32m0.4215\u001B[0m        \u001B[35m1.6225\u001B[0m  0.4335\n",
      "      2        \u001B[36m1.5836\u001B[0m       \u001B[32m0.5256\u001B[0m        \u001B[35m1.4026\u001B[0m  0.4270\n",
      "      3        \u001B[36m1.4173\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.2600\u001B[0m  0.4342\n",
      "      4        \u001B[36m1.2677\u001B[0m       \u001B[32m0.6198\u001B[0m        \u001B[35m1.1711\u001B[0m  0.4364\n",
      "      5        \u001B[36m1.1382\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.1048\u001B[0m  0.4354\n",
      "      6        \u001B[36m1.0634\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0557\u001B[0m  0.4386\n",
      "      7        \u001B[36m1.0276\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m1.0026\u001B[0m  0.4282\n",
      "      8        \u001B[36m0.9498\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m0.9646\u001B[0m  0.4503\n",
      "      9        \u001B[36m0.9020\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9454\u001B[0m  0.4173\n",
      "     10        \u001B[36m0.8719\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9085\u001B[0m  0.4366\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9069\u001B[0m       \u001B[32m0.4777\u001B[0m        \u001B[35m1.5045\u001B[0m  0.4493\n",
      "      2        \u001B[36m1.5290\u001B[0m       \u001B[32m0.5388\u001B[0m        \u001B[35m1.3096\u001B[0m  0.4188\n",
      "      3        \u001B[36m1.3760\u001B[0m       \u001B[32m0.6017\u001B[0m        \u001B[35m1.2061\u001B[0m  0.4304\n",
      "      4        \u001B[36m1.1962\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.1180\u001B[0m  0.4457\n",
      "      5        \u001B[36m1.1084\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0604\u001B[0m  0.4365\n",
      "      6        \u001B[36m1.0540\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m1.0129\u001B[0m  0.4996\n",
      "      7        \u001B[36m0.9776\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9743\u001B[0m  0.4873\n",
      "      8        \u001B[36m0.8840\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.9433\u001B[0m  0.4886\n",
      "      9        \u001B[36m0.8703\u001B[0m       0.7240        \u001B[35m0.9146\u001B[0m  0.5407\n",
      "     10        \u001B[36m0.8340\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8847\u001B[0m  0.4936\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0087\u001B[0m       \u001B[32m0.4843\u001B[0m        \u001B[35m1.3711\u001B[0m  0.5087\n",
      "      2        \u001B[36m1.5496\u001B[0m       \u001B[32m0.5785\u001B[0m        \u001B[35m1.1993\u001B[0m  0.4709\n",
      "      3        \u001B[36m1.3446\u001B[0m       \u001B[32m0.6347\u001B[0m        \u001B[35m1.0962\u001B[0m  0.4132\n",
      "      4        \u001B[36m1.1940\u001B[0m       \u001B[32m0.6678\u001B[0m        \u001B[35m1.0228\u001B[0m  0.4332\n",
      "      5        \u001B[36m1.0935\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m0.9712\u001B[0m  0.4652\n",
      "      6        \u001B[36m1.0269\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9504\u001B[0m  0.4361\n",
      "      7        \u001B[36m0.9435\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.9064\u001B[0m  0.4149\n",
      "      8        \u001B[36m0.9031\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.8805\u001B[0m  0.4307\n",
      "      9        \u001B[36m0.8440\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8490\u001B[0m  0.4312\n",
      "     10        \u001B[36m0.8177\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8402\u001B[0m  0.4396\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0467\u001B[0m       \u001B[32m0.4562\u001B[0m        \u001B[35m1.4167\u001B[0m  0.4241\n",
      "      2        \u001B[36m1.5299\u001B[0m       \u001B[32m0.6000\u001B[0m        \u001B[35m1.2246\u001B[0m  0.4535\n",
      "      3        \u001B[36m1.3300\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.1246\u001B[0m  0.4681\n",
      "      4        \u001B[36m1.1882\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.0540\u001B[0m  0.4252\n",
      "      5        \u001B[36m1.1286\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0014\u001B[0m  0.4378\n",
      "      6        \u001B[36m1.0179\u001B[0m       \u001B[32m0.7008\u001B[0m        \u001B[35m0.9508\u001B[0m  0.4232\n",
      "      7        \u001B[36m0.9744\u001B[0m       0.6975        \u001B[35m0.9247\u001B[0m  0.4263\n",
      "      8        \u001B[36m0.8818\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.8872\u001B[0m  0.4429\n",
      "      9        \u001B[36m0.8376\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.8608\u001B[0m  0.4263\n",
      "     10        \u001B[36m0.8106\u001B[0m       0.7240        \u001B[35m0.8469\u001B[0m  0.4339\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0050\u001B[0m       \u001B[32m0.4760\u001B[0m        \u001B[35m1.4700\u001B[0m  0.4632\n",
      "      2        \u001B[36m1.5290\u001B[0m       \u001B[32m0.5934\u001B[0m        \u001B[35m1.2652\u001B[0m  0.4226\n",
      "      3        \u001B[36m1.3445\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.1562\u001B[0m  0.4741\n",
      "      4        \u001B[36m1.1754\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0708\u001B[0m  0.4526\n",
      "      5        \u001B[36m1.0756\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m1.0170\u001B[0m  0.4220\n",
      "      6        \u001B[36m1.0080\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m0.9718\u001B[0m  0.4407\n",
      "      7        \u001B[36m0.9401\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.9234\u001B[0m  0.4356\n",
      "      8        \u001B[36m0.8500\u001B[0m       0.7289        \u001B[35m0.8983\u001B[0m  0.4321\n",
      "      9        \u001B[36m0.8244\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.8742\u001B[0m  0.4387\n",
      "     10        \u001B[36m0.8027\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8432\u001B[0m  0.4268\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9250\u001B[0m       \u001B[32m0.5091\u001B[0m        \u001B[35m1.4122\u001B[0m  0.4709\n",
      "      2        \u001B[36m1.4016\u001B[0m       \u001B[32m0.5835\u001B[0m        \u001B[35m1.2192\u001B[0m  0.5309\n",
      "      3        \u001B[36m1.1894\u001B[0m       \u001B[32m0.6347\u001B[0m        \u001B[35m1.1061\u001B[0m  0.4812\n",
      "      4        \u001B[36m1.0622\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.0245\u001B[0m  0.4823\n",
      "      5        \u001B[36m0.9544\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m0.9758\u001B[0m  0.5098\n",
      "      6        \u001B[36m0.8808\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9248\u001B[0m  0.4728\n",
      "      7        \u001B[36m0.8212\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.8913\u001B[0m  0.4144\n",
      "      8        \u001B[36m0.7673\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.8586\u001B[0m  0.4337\n",
      "      9        \u001B[36m0.7282\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8338\u001B[0m  0.4436\n",
      "     10        \u001B[36m0.6895\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.8102\u001B[0m  0.4539\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8427\u001B[0m       \u001B[32m0.5058\u001B[0m        \u001B[35m1.4234\u001B[0m  0.4743\n",
      "      2        \u001B[36m1.3744\u001B[0m       \u001B[32m0.6000\u001B[0m        \u001B[35m1.2220\u001B[0m  0.4664\n",
      "      3        \u001B[36m1.1498\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.1164\u001B[0m  0.4337\n",
      "      4        \u001B[36m1.0431\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m1.0317\u001B[0m  0.4385\n",
      "      5        \u001B[36m0.9261\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9753\u001B[0m  0.4297\n",
      "      6        \u001B[36m0.8429\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.9381\u001B[0m  0.4448\n",
      "      7        \u001B[36m0.7951\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8999\u001B[0m  0.4426\n",
      "      8        \u001B[36m0.7157\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.8770\u001B[0m  0.4226\n",
      "      9        \u001B[36m0.6827\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8497\u001B[0m  0.4331\n",
      "     10        \u001B[36m0.6525\u001B[0m       \u001B[32m0.7587\u001B[0m        \u001B[35m0.8263\u001B[0m  0.4551\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8736\u001B[0m       \u001B[32m0.5322\u001B[0m        \u001B[35m1.4284\u001B[0m  0.4426\n",
      "      2        \u001B[36m1.3400\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.2309\u001B[0m  0.4419\n",
      "      3        \u001B[36m1.1398\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m1.1297\u001B[0m  0.4309\n",
      "      4        \u001B[36m1.0336\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m1.0482\u001B[0m  0.4466\n",
      "      5        \u001B[36m0.9203\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.9971\u001B[0m  0.4454\n",
      "      6        \u001B[36m0.8199\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.9433\u001B[0m  0.4353\n",
      "      7        \u001B[36m0.7622\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.9099\u001B[0m  0.4420\n",
      "      8        \u001B[36m0.7022\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.8903\u001B[0m  0.4599\n",
      "      9        \u001B[36m0.6846\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.8606\u001B[0m  0.4580\n",
      "     10        \u001B[36m0.6439\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8429\u001B[0m  0.4332\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8467\u001B[0m       \u001B[32m0.5306\u001B[0m        \u001B[35m1.3122\u001B[0m  0.4428\n",
      "      2        \u001B[36m1.3689\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.1138\u001B[0m  0.4267\n",
      "      3        \u001B[36m1.1325\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m1.0141\u001B[0m  0.4410\n",
      "      4        \u001B[36m1.0166\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m0.9459\u001B[0m  0.4431\n",
      "      5        \u001B[36m0.9136\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.9007\u001B[0m  0.4314\n",
      "      6        \u001B[36m0.8500\u001B[0m       0.7273        \u001B[35m0.8631\u001B[0m  0.4632\n",
      "      7        \u001B[36m0.8077\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8287\u001B[0m  0.4445\n",
      "      8        \u001B[36m0.7271\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.7999\u001B[0m  0.4423\n",
      "      9        \u001B[36m0.6988\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.7889\u001B[0m  0.4498\n",
      "     10        \u001B[36m0.6424\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.7639\u001B[0m  0.4416\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8730\u001B[0m       \u001B[32m0.5091\u001B[0m        \u001B[35m1.3301\u001B[0m  0.4462\n",
      "      2        \u001B[36m1.3610\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.1630\u001B[0m  0.4574\n",
      "      3        \u001B[36m1.1743\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0510\u001B[0m  0.4390\n",
      "      4        \u001B[36m1.0114\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m0.9729\u001B[0m  0.4599\n",
      "      5        \u001B[36m0.9273\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.9074\u001B[0m  0.4464\n",
      "      6        \u001B[36m0.8233\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8709\u001B[0m  0.4328\n",
      "      7        \u001B[36m0.8004\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.8471\u001B[0m  0.4892\n",
      "      8        \u001B[36m0.7297\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.8147\u001B[0m  0.5299\n",
      "      9        \u001B[36m0.6869\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.7928\u001B[0m  0.4674\n",
      "     10        \u001B[36m0.6358\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7669\u001B[0m  0.4498\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7933\u001B[0m       \u001B[32m0.5421\u001B[0m        \u001B[35m1.3994\u001B[0m  0.4972\n",
      "      2        \u001B[36m1.3233\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.1871\u001B[0m  0.4973\n",
      "      3        \u001B[36m1.1157\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m1.0725\u001B[0m  0.4786\n",
      "      4        \u001B[36m0.9728\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m1.0049\u001B[0m  0.4346\n",
      "      5        \u001B[36m0.8767\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.9383\u001B[0m  0.4429\n",
      "      6        \u001B[36m0.8191\u001B[0m       0.7554        \u001B[35m0.8813\u001B[0m  0.4467\n",
      "      7        \u001B[36m0.7562\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.8504\u001B[0m  0.4308\n",
      "      8        \u001B[36m0.6814\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.8269\u001B[0m  0.4465\n",
      "      9        \u001B[36m0.6410\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.8068\u001B[0m  0.4846\n",
      "     10        \u001B[36m0.6055\u001B[0m       0.7736        \u001B[35m0.8055\u001B[0m  0.4407\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.7s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7755\u001B[0m       \u001B[32m0.5802\u001B[0m        \u001B[35m1.2236\u001B[0m  0.4886\n",
      "      2        \u001B[36m1.2658\u001B[0m       \u001B[32m0.6810\u001B[0m        \u001B[35m1.0462\u001B[0m  0.5035\n",
      "      3        \u001B[36m1.0601\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.9564\u001B[0m  0.4493\n",
      "      4        \u001B[36m0.9609\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.8890\u001B[0m  0.4817\n",
      "      5        \u001B[36m0.8474\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.8425\u001B[0m  0.4990\n",
      "      6        \u001B[36m0.7966\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.8191\u001B[0m  0.4858\n",
      "      7        \u001B[36m0.7152\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.7940\u001B[0m  0.4304\n",
      "      8        \u001B[36m0.6922\u001B[0m       0.7686        \u001B[35m0.7695\u001B[0m  0.4298\n",
      "      9        \u001B[36m0.6244\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7555\u001B[0m  0.5033\n",
      "     10        \u001B[36m0.6151\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7367\u001B[0m  0.4824\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8318\u001B[0m       \u001B[32m0.5521\u001B[0m        \u001B[35m1.3020\u001B[0m  0.5011\n",
      "      2        \u001B[36m1.2625\u001B[0m       \u001B[32m0.6397\u001B[0m        \u001B[35m1.1048\u001B[0m  0.5071\n",
      "      3        \u001B[36m1.0956\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m1.0132\u001B[0m  0.4879\n",
      "      4        \u001B[36m0.9533\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.9277\u001B[0m  0.4650\n",
      "      5        \u001B[36m0.8915\u001B[0m       0.7256        \u001B[35m0.9029\u001B[0m  0.4677\n",
      "      6        \u001B[36m0.7828\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.8559\u001B[0m  0.4288\n",
      "      7        \u001B[36m0.7367\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.8302\u001B[0m  0.4911\n",
      "      8        \u001B[36m0.6982\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.8109\u001B[0m  0.4979\n",
      "      9        \u001B[36m0.6300\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7942\u001B[0m  0.4832\n",
      "     10        \u001B[36m0.6078\u001B[0m       0.7570        \u001B[35m0.7771\u001B[0m  0.4336\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.9s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8557\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.1944\u001B[0m  0.4333\n",
      "      2        \u001B[36m1.3352\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0299\u001B[0m  0.4438\n",
      "      3        \u001B[36m1.1521\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9239\u001B[0m  0.4357\n",
      "      4        \u001B[36m0.9721\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.8673\u001B[0m  0.4233\n",
      "      5        \u001B[36m0.8858\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.8192\u001B[0m  0.4432\n",
      "      6        \u001B[36m0.8141\u001B[0m       0.7488        \u001B[35m0.8042\u001B[0m  0.4313\n",
      "      7        \u001B[36m0.7670\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.7630\u001B[0m  0.4331\n",
      "      8        \u001B[36m0.7037\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.7563\u001B[0m  0.4351\n",
      "      9        \u001B[36m0.6694\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7350\u001B[0m  0.4224\n",
      "     10        \u001B[36m0.6074\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.7090\u001B[0m  0.4396\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2758\u001B[0m       \u001B[32m0.3570\u001B[0m        \u001B[35m1.6904\u001B[0m  0.4305\n",
      "      2        \u001B[36m1.8703\u001B[0m       \u001B[32m0.4264\u001B[0m        \u001B[35m1.4922\u001B[0m  0.4370\n",
      "      3        \u001B[36m1.7194\u001B[0m       \u001B[32m0.4893\u001B[0m        \u001B[35m1.3901\u001B[0m  0.4478\n",
      "      4        \u001B[36m1.5888\u001B[0m       \u001B[32m0.5157\u001B[0m        \u001B[35m1.3182\u001B[0m  0.4302\n",
      "      5        \u001B[36m1.4647\u001B[0m       \u001B[32m0.5372\u001B[0m        \u001B[35m1.2648\u001B[0m  0.4458\n",
      "      6        \u001B[36m1.3992\u001B[0m       \u001B[32m0.5537\u001B[0m        \u001B[35m1.2169\u001B[0m  0.4338\n",
      "      7        \u001B[36m1.3296\u001B[0m       \u001B[32m0.5901\u001B[0m        \u001B[35m1.1774\u001B[0m  0.4329\n",
      "      8        \u001B[36m1.2930\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.1439\u001B[0m  0.4460\n",
      "      9        \u001B[36m1.2270\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1200\u001B[0m  0.4503\n",
      "     10        \u001B[36m1.1889\u001B[0m       \u001B[32m0.6545\u001B[0m        \u001B[35m1.0914\u001B[0m  0.4342\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4552\u001B[0m       \u001B[32m0.2579\u001B[0m        \u001B[35m1.7881\u001B[0m  0.4534\n",
      "      2        \u001B[36m1.9857\u001B[0m       \u001B[32m0.3967\u001B[0m        \u001B[35m1.5918\u001B[0m  0.4233\n",
      "      3        \u001B[36m1.7811\u001B[0m       \u001B[32m0.4579\u001B[0m        \u001B[35m1.4798\u001B[0m  0.4352\n",
      "      4        \u001B[36m1.5961\u001B[0m       \u001B[32m0.4959\u001B[0m        \u001B[35m1.3945\u001B[0m  0.4529\n",
      "      5        \u001B[36m1.5409\u001B[0m       \u001B[32m0.5388\u001B[0m        \u001B[35m1.3265\u001B[0m  0.4329\n",
      "      6        \u001B[36m1.4616\u001B[0m       \u001B[32m0.5702\u001B[0m        \u001B[35m1.2767\u001B[0m  0.4376\n",
      "      7        \u001B[36m1.3755\u001B[0m       \u001B[32m0.5868\u001B[0m        \u001B[35m1.2259\u001B[0m  0.4460\n",
      "      8        \u001B[36m1.2914\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.1947\u001B[0m  0.4350\n",
      "      9        \u001B[36m1.2626\u001B[0m       \u001B[32m0.6397\u001B[0m        \u001B[35m1.1636\u001B[0m  0.4342\n",
      "     10        \u001B[36m1.2078\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.1410\u001B[0m  0.4444\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3991\u001B[0m       \u001B[32m0.2909\u001B[0m        \u001B[35m1.8403\u001B[0m  0.4334\n",
      "      2        \u001B[36m2.0485\u001B[0m       \u001B[32m0.4165\u001B[0m        \u001B[35m1.6583\u001B[0m  0.4359\n",
      "      3        \u001B[36m1.8348\u001B[0m       \u001B[32m0.4678\u001B[0m        \u001B[35m1.5355\u001B[0m  0.4387\n",
      "      4        \u001B[36m1.6689\u001B[0m       \u001B[32m0.4975\u001B[0m        \u001B[35m1.4369\u001B[0m  0.4293\n",
      "      5        \u001B[36m1.5887\u001B[0m       \u001B[32m0.5174\u001B[0m        \u001B[35m1.3647\u001B[0m  0.4490\n",
      "      6        \u001B[36m1.4679\u001B[0m       \u001B[32m0.5455\u001B[0m        \u001B[35m1.3065\u001B[0m  0.4363\n",
      "      7        \u001B[36m1.4075\u001B[0m       \u001B[32m0.5719\u001B[0m        \u001B[35m1.2487\u001B[0m  0.4283\n",
      "      8        \u001B[36m1.3244\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.2144\u001B[0m  0.4503\n",
      "      9        \u001B[36m1.2775\u001B[0m       \u001B[32m0.6182\u001B[0m        \u001B[35m1.1757\u001B[0m  0.4315\n",
      "     10        \u001B[36m1.2115\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.1393\u001B[0m  0.4387\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.5372\u001B[0m       \u001B[32m0.3405\u001B[0m        \u001B[35m1.7945\u001B[0m  0.4467\n",
      "      2        \u001B[36m2.0758\u001B[0m       \u001B[32m0.4397\u001B[0m        \u001B[35m1.5434\u001B[0m  0.4355\n",
      "      3        \u001B[36m1.8662\u001B[0m       \u001B[32m0.4975\u001B[0m        \u001B[35m1.4099\u001B[0m  0.4276\n",
      "      4        \u001B[36m1.7116\u001B[0m       \u001B[32m0.5504\u001B[0m        \u001B[35m1.3239\u001B[0m  0.4380\n",
      "      5        \u001B[36m1.5926\u001B[0m       \u001B[32m0.5802\u001B[0m        \u001B[35m1.2595\u001B[0m  0.4377\n",
      "      6        \u001B[36m1.4950\u001B[0m       \u001B[32m0.5983\u001B[0m        \u001B[35m1.2139\u001B[0m  0.4280\n",
      "      7        \u001B[36m1.3823\u001B[0m       \u001B[32m0.6397\u001B[0m        \u001B[35m1.1844\u001B[0m  0.4399\n",
      "      8        \u001B[36m1.3799\u001B[0m       \u001B[32m0.6545\u001B[0m        \u001B[35m1.1515\u001B[0m  0.4502\n",
      "      9        \u001B[36m1.2937\u001B[0m       \u001B[32m0.6678\u001B[0m        \u001B[35m1.1235\u001B[0m  0.4186\n",
      "     10        \u001B[36m1.2687\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m1.0904\u001B[0m  0.4347\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3728\u001B[0m       \u001B[32m0.3702\u001B[0m        \u001B[35m1.6761\u001B[0m  0.4260\n",
      "      2        \u001B[36m1.9870\u001B[0m       \u001B[32m0.4860\u001B[0m        \u001B[35m1.4922\u001B[0m  0.4359\n",
      "      3        \u001B[36m1.7584\u001B[0m       \u001B[32m0.5405\u001B[0m        \u001B[35m1.3849\u001B[0m  0.4430\n",
      "      4        \u001B[36m1.5797\u001B[0m       \u001B[32m0.5736\u001B[0m        \u001B[35m1.3126\u001B[0m  0.4324\n",
      "      5        \u001B[36m1.4903\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.2526\u001B[0m  0.4330\n",
      "      6        \u001B[36m1.4220\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.2047\u001B[0m  0.4349\n",
      "      7        \u001B[36m1.3427\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.1555\u001B[0m  0.4356\n",
      "      8        \u001B[36m1.2977\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.1227\u001B[0m  0.4453\n",
      "      9        \u001B[36m1.2391\u001B[0m       \u001B[32m0.6744\u001B[0m        \u001B[35m1.0958\u001B[0m  0.4536\n",
      "     10        \u001B[36m1.1564\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m1.0690\u001B[0m  0.4386\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4029\u001B[0m       \u001B[32m0.3504\u001B[0m        \u001B[35m1.7226\u001B[0m  0.4353\n",
      "      2        \u001B[36m2.0606\u001B[0m       \u001B[32m0.4231\u001B[0m        \u001B[35m1.5403\u001B[0m  0.4492\n",
      "      3        \u001B[36m1.8144\u001B[0m       \u001B[32m0.4744\u001B[0m        \u001B[35m1.4300\u001B[0m  0.4350\n",
      "      4        \u001B[36m1.7014\u001B[0m       \u001B[32m0.5190\u001B[0m        \u001B[35m1.3314\u001B[0m  0.4295\n",
      "      5        \u001B[36m1.5697\u001B[0m       \u001B[32m0.5669\u001B[0m        \u001B[35m1.2695\u001B[0m  0.4415\n",
      "      6        \u001B[36m1.4514\u001B[0m       \u001B[32m0.5884\u001B[0m        \u001B[35m1.2263\u001B[0m  0.4427\n",
      "      7        \u001B[36m1.3777\u001B[0m       \u001B[32m0.6099\u001B[0m        \u001B[35m1.1762\u001B[0m  0.4244\n",
      "      8        \u001B[36m1.3035\u001B[0m       \u001B[32m0.6215\u001B[0m        \u001B[35m1.1454\u001B[0m  0.4422\n",
      "      9        \u001B[36m1.2591\u001B[0m       \u001B[32m0.6430\u001B[0m        \u001B[35m1.1058\u001B[0m  0.4393\n",
      "     10        1.2646       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0849\u001B[0m  0.4262\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3198\u001B[0m       \u001B[32m0.4132\u001B[0m        \u001B[35m1.6455\u001B[0m  0.4396\n",
      "      2        \u001B[36m1.8846\u001B[0m       \u001B[32m0.5025\u001B[0m        \u001B[35m1.4605\u001B[0m  0.4282\n",
      "      3        \u001B[36m1.7174\u001B[0m       \u001B[32m0.5521\u001B[0m        \u001B[35m1.3610\u001B[0m  0.4414\n",
      "      4        \u001B[36m1.5806\u001B[0m       \u001B[32m0.5835\u001B[0m        \u001B[35m1.2957\u001B[0m  0.4381\n",
      "      5        \u001B[36m1.4853\u001B[0m       \u001B[32m0.6116\u001B[0m        \u001B[35m1.2344\u001B[0m  0.4200\n",
      "      6        \u001B[36m1.4033\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.1896\u001B[0m  0.4367\n",
      "      7        \u001B[36m1.3109\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.1420\u001B[0m  0.4485\n",
      "      8        \u001B[36m1.2705\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.1178\u001B[0m  0.4542\n",
      "      9        \u001B[36m1.2391\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m1.0831\u001B[0m  0.4734\n",
      "     10        \u001B[36m1.2114\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m1.0657\u001B[0m  0.4499\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3631\u001B[0m       \u001B[32m0.3702\u001B[0m        \u001B[35m1.6158\u001B[0m  0.4301\n",
      "      2        \u001B[36m1.9028\u001B[0m       \u001B[32m0.4661\u001B[0m        \u001B[35m1.4254\u001B[0m  0.4375\n",
      "      3        \u001B[36m1.7733\u001B[0m       \u001B[32m0.5223\u001B[0m        \u001B[35m1.3276\u001B[0m  0.4379\n",
      "      4        \u001B[36m1.5782\u001B[0m       \u001B[32m0.5769\u001B[0m        \u001B[35m1.2558\u001B[0m  0.4644\n",
      "      5        \u001B[36m1.4301\u001B[0m       \u001B[32m0.5950\u001B[0m        \u001B[35m1.1978\u001B[0m  0.4667\n",
      "      6        1.4327       \u001B[32m0.6182\u001B[0m        \u001B[35m1.1649\u001B[0m  0.4454\n",
      "      7        \u001B[36m1.3160\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.1197\u001B[0m  0.4343\n",
      "      8        \u001B[36m1.2776\u001B[0m       \u001B[32m0.6512\u001B[0m        \u001B[35m1.0904\u001B[0m  0.4359\n",
      "      9        \u001B[36m1.2118\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0727\u001B[0m  0.4370\n",
      "     10        \u001B[36m1.1425\u001B[0m       \u001B[32m0.6727\u001B[0m        \u001B[35m1.0465\u001B[0m  0.4274\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4614\u001B[0m       \u001B[32m0.3488\u001B[0m        \u001B[35m1.6991\u001B[0m  0.4324\n",
      "      2        \u001B[36m1.9731\u001B[0m       \u001B[32m0.4347\u001B[0m        \u001B[35m1.4786\u001B[0m  0.4283\n",
      "      3        \u001B[36m1.7708\u001B[0m       \u001B[32m0.5124\u001B[0m        \u001B[35m1.3495\u001B[0m  0.4423\n",
      "      4        \u001B[36m1.5974\u001B[0m       \u001B[32m0.5669\u001B[0m        \u001B[35m1.2777\u001B[0m  0.4449\n",
      "      5        \u001B[36m1.5200\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.2304\u001B[0m  0.4260\n",
      "      6        \u001B[36m1.4291\u001B[0m       \u001B[32m0.6198\u001B[0m        \u001B[35m1.1770\u001B[0m  0.4714\n",
      "      7        \u001B[36m1.3289\u001B[0m       \u001B[32m0.6298\u001B[0m        \u001B[35m1.1404\u001B[0m  0.4574\n",
      "      8        \u001B[36m1.2741\u001B[0m       \u001B[32m0.6479\u001B[0m        \u001B[35m1.0972\u001B[0m  0.4521\n",
      "      9        \u001B[36m1.2402\u001B[0m       0.6331        \u001B[35m1.0884\u001B[0m  0.4499\n",
      "     10        \u001B[36m1.2227\u001B[0m       0.6364        \u001B[35m1.0749\u001B[0m  0.4414\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2592\u001B[0m       \u001B[32m0.3653\u001B[0m        \u001B[35m1.6426\u001B[0m  0.4311\n",
      "      2        \u001B[36m1.7228\u001B[0m       \u001B[32m0.4959\u001B[0m        \u001B[35m1.4083\u001B[0m  0.4464\n",
      "      3        \u001B[36m1.5623\u001B[0m       \u001B[32m0.5438\u001B[0m        \u001B[35m1.2906\u001B[0m  0.4432\n",
      "      4        \u001B[36m1.4613\u001B[0m       \u001B[32m0.5736\u001B[0m        \u001B[35m1.2075\u001B[0m  0.4309\n",
      "      5        \u001B[36m1.3139\u001B[0m       \u001B[32m0.6182\u001B[0m        \u001B[35m1.1453\u001B[0m  0.4467\n",
      "      6        \u001B[36m1.2304\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.0960\u001B[0m  0.4431\n",
      "      7        \u001B[36m1.1917\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0525\u001B[0m  0.4347\n",
      "      8        \u001B[36m1.0855\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0217\u001B[0m  0.4414\n",
      "      9        \u001B[36m1.0394\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m0.9901\u001B[0m  0.4478\n",
      "     10        \u001B[36m1.0080\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9595\u001B[0m  0.4290\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4162\u001B[0m       \u001B[32m0.3223\u001B[0m        \u001B[35m1.7399\u001B[0m  0.4421\n",
      "      2        \u001B[36m1.8073\u001B[0m       \u001B[32m0.4860\u001B[0m        \u001B[35m1.4818\u001B[0m  0.4384\n",
      "      3        \u001B[36m1.6027\u001B[0m       \u001B[32m0.5339\u001B[0m        \u001B[35m1.3541\u001B[0m  0.4368\n",
      "      4        \u001B[36m1.4458\u001B[0m       \u001B[32m0.5835\u001B[0m        \u001B[35m1.2682\u001B[0m  0.4527\n",
      "      5        \u001B[36m1.2974\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.1966\u001B[0m  0.4413\n",
      "      6        \u001B[36m1.2122\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.1461\u001B[0m  0.4443\n",
      "      7        \u001B[36m1.1390\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.0951\u001B[0m  0.4445\n",
      "      8        \u001B[36m1.0837\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.0597\u001B[0m  0.4458\n",
      "      9        \u001B[36m1.0459\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0261\u001B[0m  0.4298\n",
      "     10        \u001B[36m1.0119\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m0.9943\u001B[0m  0.4465\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1935\u001B[0m       \u001B[32m0.4364\u001B[0m        \u001B[35m1.5821\u001B[0m  0.4302\n",
      "      2        \u001B[36m1.7738\u001B[0m       \u001B[32m0.5091\u001B[0m        \u001B[35m1.3810\u001B[0m  0.4469\n",
      "      3        \u001B[36m1.5796\u001B[0m       \u001B[32m0.5488\u001B[0m        \u001B[35m1.2744\u001B[0m  0.4538\n",
      "      4        \u001B[36m1.4108\u001B[0m       \u001B[32m0.5917\u001B[0m        \u001B[35m1.1947\u001B[0m  0.4571\n",
      "      5        \u001B[36m1.2898\u001B[0m       \u001B[32m0.6182\u001B[0m        \u001B[35m1.1292\u001B[0m  0.4482\n",
      "      6        \u001B[36m1.2305\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.0786\u001B[0m  0.4469\n",
      "      7        \u001B[36m1.1369\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.0382\u001B[0m  0.4471\n",
      "      8        \u001B[36m1.0824\u001B[0m       \u001B[32m0.6744\u001B[0m        \u001B[35m1.0060\u001B[0m  0.4423\n",
      "      9        \u001B[36m1.0470\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m0.9745\u001B[0m  0.4411\n",
      "     10        \u001B[36m0.9982\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m0.9459\u001B[0m  0.4473\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   4.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2605\u001B[0m       \u001B[32m0.3653\u001B[0m        \u001B[35m1.5418\u001B[0m  0.4307\n",
      "      2        \u001B[36m1.7655\u001B[0m       \u001B[32m0.4810\u001B[0m        \u001B[35m1.3541\u001B[0m  0.4469\n",
      "      3        \u001B[36m1.5570\u001B[0m       \u001B[32m0.5405\u001B[0m        \u001B[35m1.2466\u001B[0m  0.4389\n",
      "      4        \u001B[36m1.4054\u001B[0m       \u001B[32m0.5884\u001B[0m        \u001B[35m1.1622\u001B[0m  0.4300\n",
      "      5        \u001B[36m1.2944\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1056\u001B[0m  0.4478\n",
      "      6        \u001B[36m1.2221\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.0607\u001B[0m  0.4375\n",
      "      7        \u001B[36m1.1067\u001B[0m       \u001B[32m0.6678\u001B[0m        \u001B[35m1.0175\u001B[0m  0.4340\n",
      "      8        \u001B[36m1.0823\u001B[0m       \u001B[32m0.6810\u001B[0m        \u001B[35m1.0011\u001B[0m  0.4426\n",
      "      9        \u001B[36m1.0084\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m0.9647\u001B[0m  0.4262\n",
      "     10        \u001B[36m0.9889\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.9357\u001B[0m  0.4465\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1660\u001B[0m       \u001B[32m0.4165\u001B[0m        \u001B[35m1.5284\u001B[0m  0.4311\n",
      "      2        \u001B[36m1.7393\u001B[0m       \u001B[32m0.4893\u001B[0m        \u001B[35m1.3492\u001B[0m  0.4418\n",
      "      3        \u001B[36m1.5479\u001B[0m       \u001B[32m0.5636\u001B[0m        \u001B[35m1.2471\u001B[0m  0.4442\n",
      "      4        \u001B[36m1.3991\u001B[0m       \u001B[32m0.6066\u001B[0m        \u001B[35m1.1705\u001B[0m  0.4293\n",
      "      5        \u001B[36m1.3037\u001B[0m       \u001B[32m0.6397\u001B[0m        \u001B[35m1.1155\u001B[0m  0.4469\n",
      "      6        \u001B[36m1.1728\u001B[0m       \u001B[32m0.6678\u001B[0m        \u001B[35m1.0700\u001B[0m  0.4486\n",
      "      7        \u001B[36m1.1254\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m1.0351\u001B[0m  0.4336\n",
      "      8        \u001B[36m1.0847\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m1.0035\u001B[0m  0.4346\n",
      "      9        \u001B[36m1.0183\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9860\u001B[0m  0.4511\n",
      "     10        \u001B[36m0.9547\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.9679\u001B[0m  0.4404\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2461\u001B[0m       \u001B[32m0.4165\u001B[0m        \u001B[35m1.5586\u001B[0m  0.4397\n",
      "      2        \u001B[36m1.7398\u001B[0m       \u001B[32m0.5091\u001B[0m        \u001B[35m1.3616\u001B[0m  0.4509\n",
      "      3        \u001B[36m1.5152\u001B[0m       \u001B[32m0.5719\u001B[0m        \u001B[35m1.2476\u001B[0m  0.4287\n",
      "      4        \u001B[36m1.4170\u001B[0m       \u001B[32m0.6215\u001B[0m        \u001B[35m1.1785\u001B[0m  0.4329\n",
      "      5        \u001B[36m1.2619\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1063\u001B[0m  0.4511\n",
      "      6        \u001B[36m1.1851\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0477\u001B[0m  0.4355\n",
      "      7        \u001B[36m1.1087\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m1.0115\u001B[0m  0.4363\n",
      "      8        \u001B[36m1.0623\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m0.9774\u001B[0m  0.4341\n",
      "      9        \u001B[36m1.0101\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9472\u001B[0m  0.4334\n",
      "     10        \u001B[36m0.9638\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.9369\u001B[0m  0.4468\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2243\u001B[0m       \u001B[32m0.4711\u001B[0m        \u001B[35m1.4970\u001B[0m  0.4371\n",
      "      2        \u001B[36m1.8041\u001B[0m       \u001B[32m0.5554\u001B[0m        \u001B[35m1.3288\u001B[0m  0.4238\n",
      "      3        \u001B[36m1.5241\u001B[0m       \u001B[32m0.5917\u001B[0m        \u001B[35m1.2352\u001B[0m  0.4428\n",
      "      4        \u001B[36m1.4387\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.1623\u001B[0m  0.4265\n",
      "      5        \u001B[36m1.2982\u001B[0m       \u001B[32m0.6430\u001B[0m        \u001B[35m1.1051\u001B[0m  0.4330\n",
      "      6        \u001B[36m1.2307\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0608\u001B[0m  0.4476\n",
      "      7        \u001B[36m1.1849\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m1.0218\u001B[0m  0.4339\n",
      "      8        \u001B[36m1.0615\u001B[0m       0.6909        \u001B[35m1.0029\u001B[0m  0.4286\n",
      "      9        \u001B[36m1.0360\u001B[0m       \u001B[32m0.7008\u001B[0m        \u001B[35m0.9741\u001B[0m  0.4398\n",
      "     10        \u001B[36m0.9936\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9469\u001B[0m  0.4342\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1697\u001B[0m       \u001B[32m0.4595\u001B[0m        \u001B[35m1.4528\u001B[0m  0.4303\n",
      "      2        \u001B[36m1.7135\u001B[0m       \u001B[32m0.5653\u001B[0m        \u001B[35m1.2631\u001B[0m  0.4448\n",
      "      3        \u001B[36m1.4849\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.1756\u001B[0m  0.4277\n",
      "      4        \u001B[36m1.3130\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1124\u001B[0m  0.4361\n",
      "      5        \u001B[36m1.2385\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0624\u001B[0m  0.4450\n",
      "      6        \u001B[36m1.1535\u001B[0m       \u001B[32m0.6744\u001B[0m        \u001B[35m1.0238\u001B[0m  0.4351\n",
      "      7        \u001B[36m1.0507\u001B[0m       \u001B[32m0.6760\u001B[0m        \u001B[35m1.0036\u001B[0m  0.4294\n",
      "      8        \u001B[36m1.0388\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9646\u001B[0m  0.4384\n",
      "      9        \u001B[36m0.9914\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9404\u001B[0m  0.4273\n",
      "     10        \u001B[36m0.9286\u001B[0m       0.7041        \u001B[35m0.9325\u001B[0m  0.4431\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2001\u001B[0m       \u001B[32m0.4397\u001B[0m        \u001B[35m1.4734\u001B[0m  0.4380\n",
      "      2        \u001B[36m1.7576\u001B[0m       \u001B[32m0.5421\u001B[0m        \u001B[35m1.2847\u001B[0m  0.4248\n",
      "      3        \u001B[36m1.4872\u001B[0m       \u001B[32m0.5884\u001B[0m        \u001B[35m1.1796\u001B[0m  0.4425\n",
      "      4        \u001B[36m1.3552\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.1194\u001B[0m  0.4266\n",
      "      5        \u001B[36m1.2650\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.0729\u001B[0m  0.4349\n",
      "      6        \u001B[36m1.1680\u001B[0m       \u001B[32m0.6744\u001B[0m        \u001B[35m1.0208\u001B[0m  0.4458\n",
      "      7        \u001B[36m1.0883\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m0.9837\u001B[0m  0.4420\n",
      "      8        \u001B[36m1.0665\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9525\u001B[0m  0.4273\n",
      "      9        \u001B[36m0.9925\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9328\u001B[0m  0.4385\n",
      "     10        \u001B[36m0.9587\u001B[0m       0.7091        \u001B[35m0.9158\u001B[0m  0.4465\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8405\u001B[0m       \u001B[32m0.5058\u001B[0m        \u001B[35m1.4054\u001B[0m  0.4399\n",
      "      2        \u001B[36m1.4271\u001B[0m       \u001B[32m0.5802\u001B[0m        \u001B[35m1.2380\u001B[0m  0.4381\n",
      "      3        \u001B[36m1.2485\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.1299\u001B[0m  0.4280\n",
      "      4        \u001B[36m1.1401\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m1.0604\u001B[0m  0.4390\n",
      "      5        \u001B[36m1.0322\u001B[0m       \u001B[32m0.7008\u001B[0m        \u001B[35m1.0017\u001B[0m  0.4458\n",
      "      6        \u001B[36m0.9389\u001B[0m       \u001B[32m0.7174\u001B[0m        \u001B[35m0.9631\u001B[0m  0.4244\n",
      "      7        \u001B[36m0.8827\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.9274\u001B[0m  0.4326\n",
      "      8        \u001B[36m0.8339\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.8973\u001B[0m  0.4444\n",
      "      9        \u001B[36m0.8063\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8769\u001B[0m  0.4294\n",
      "     10        \u001B[36m0.7464\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.8518\u001B[0m  0.4394\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0272\u001B[0m       \u001B[32m0.4909\u001B[0m        \u001B[35m1.4797\u001B[0m  0.4295\n",
      "      2        \u001B[36m1.5165\u001B[0m       \u001B[32m0.5802\u001B[0m        \u001B[35m1.2638\u001B[0m  0.4247\n",
      "      3        \u001B[36m1.2860\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.1581\u001B[0m  0.4391\n",
      "      4        \u001B[36m1.1490\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0860\u001B[0m  0.4468\n",
      "      5        \u001B[36m1.0398\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m1.0158\u001B[0m  0.4232\n",
      "      6        \u001B[36m0.9700\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.9707\u001B[0m  0.4299\n",
      "      7        \u001B[36m0.8767\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.9405\u001B[0m  0.4312\n",
      "      8        \u001B[36m0.8471\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.9154\u001B[0m  0.4253\n",
      "      9        \u001B[36m0.8069\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.8852\u001B[0m  0.4384\n",
      "     10        \u001B[36m0.7448\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.8657\u001B[0m  0.4444\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0826\u001B[0m       \u001B[32m0.4512\u001B[0m        \u001B[35m1.5138\u001B[0m  0.4209\n",
      "      2        \u001B[36m1.5189\u001B[0m       \u001B[32m0.5686\u001B[0m        \u001B[35m1.2929\u001B[0m  0.4346\n",
      "      3        \u001B[36m1.2752\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.1705\u001B[0m  0.4525\n",
      "      4        \u001B[36m1.1526\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0927\u001B[0m  0.4264\n",
      "      5        \u001B[36m1.0486\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m1.0216\u001B[0m  0.4311\n",
      "      6        \u001B[36m0.9637\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9668\u001B[0m  0.4446\n",
      "      7        \u001B[36m0.8956\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.9291\u001B[0m  0.4258\n",
      "      8        \u001B[36m0.8370\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8955\u001B[0m  0.4271\n",
      "      9        \u001B[36m0.8017\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8659\u001B[0m  0.4299\n",
      "     10        \u001B[36m0.7299\u001B[0m       0.7521        \u001B[35m0.8409\u001B[0m  0.4293\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8864\u001B[0m       \u001B[32m0.5339\u001B[0m        \u001B[35m1.3549\u001B[0m  0.4373\n",
      "      2        \u001B[36m1.4617\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.1891\u001B[0m  0.4238\n",
      "      3        \u001B[36m1.2526\u001B[0m       \u001B[32m0.6727\u001B[0m        \u001B[35m1.1011\u001B[0m  0.4464\n",
      "      4        \u001B[36m1.1329\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m1.0147\u001B[0m  0.4486\n",
      "      5        \u001B[36m1.0200\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.9847\u001B[0m  0.4332\n",
      "      6        \u001B[36m0.9392\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.9249\u001B[0m  0.4309\n",
      "      7        \u001B[36m0.8799\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.9136\u001B[0m  0.4351\n",
      "      8        \u001B[36m0.8444\u001B[0m       0.7636        \u001B[35m0.8763\u001B[0m  0.4264\n",
      "      9        \u001B[36m0.7971\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.8490\u001B[0m  0.4429\n",
      "     10        \u001B[36m0.7514\u001B[0m       0.7669        \u001B[35m0.8323\u001B[0m  0.4554\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9409\u001B[0m       \u001B[32m0.4893\u001B[0m        \u001B[35m1.3851\u001B[0m  0.4226\n",
      "      2        \u001B[36m1.4922\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.1973\u001B[0m  0.4373\n",
      "      3        \u001B[36m1.2645\u001B[0m       \u001B[32m0.6364\u001B[0m        \u001B[35m1.0978\u001B[0m  0.4484\n",
      "      4        \u001B[36m1.1410\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m1.0356\u001B[0m  0.4247\n",
      "      5        \u001B[36m1.0149\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m0.9741\u001B[0m  0.4336\n",
      "      6        \u001B[36m0.9388\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.9315\u001B[0m  0.4341\n",
      "      7        \u001B[36m0.8784\u001B[0m       0.7322        \u001B[35m0.8979\u001B[0m  0.4330\n",
      "      8        \u001B[36m0.8333\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8807\u001B[0m  0.4488\n",
      "      9        \u001B[36m0.7987\u001B[0m       0.7339        \u001B[35m0.8551\u001B[0m  0.4406\n",
      "     10        \u001B[36m0.7613\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8330\u001B[0m  0.4260\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9090\u001B[0m       \u001B[32m0.5223\u001B[0m        \u001B[35m1.3198\u001B[0m  0.4321\n",
      "      2        \u001B[36m1.4669\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.1511\u001B[0m  0.4391\n",
      "      3        \u001B[36m1.2689\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0571\u001B[0m  0.4273\n",
      "      4        \u001B[36m1.1213\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m0.9883\u001B[0m  0.4414\n",
      "      5        \u001B[36m1.0270\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.9454\u001B[0m  0.4446\n",
      "      6        \u001B[36m0.9377\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.9134\u001B[0m  0.4255\n",
      "      7        \u001B[36m0.8894\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.8729\u001B[0m  0.4424\n",
      "      8        \u001B[36m0.8285\u001B[0m       0.7570        \u001B[35m0.8469\u001B[0m  0.4265\n",
      "      9        \u001B[36m0.7610\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.8251\u001B[0m  0.4313\n",
      "     10        \u001B[36m0.7274\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.8053\u001B[0m  0.4441\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9484\u001B[0m       \u001B[32m0.5570\u001B[0m        \u001B[35m1.3394\u001B[0m  0.4323\n",
      "      2        \u001B[36m1.4670\u001B[0m       \u001B[32m0.6430\u001B[0m        \u001B[35m1.1386\u001B[0m  0.4274\n",
      "      3        \u001B[36m1.2472\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m1.0334\u001B[0m  0.4386\n",
      "      4        \u001B[36m1.1048\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m0.9887\u001B[0m  0.4209\n",
      "      5        \u001B[36m1.0199\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9306\u001B[0m  0.4374\n",
      "      6        \u001B[36m0.9238\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.8952\u001B[0m  0.4454\n",
      "      7        \u001B[36m0.8663\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.8670\u001B[0m  0.4318\n",
      "      8        \u001B[36m0.8236\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8359\u001B[0m  0.4541\n",
      "      9        \u001B[36m0.7782\u001B[0m       0.7322        0.8365  0.4344\n",
      "     10        \u001B[36m0.7413\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8075\u001B[0m  0.4222\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9243\u001B[0m       \u001B[32m0.5289\u001B[0m        \u001B[35m1.3293\u001B[0m  0.4527\n",
      "      2        \u001B[36m1.4124\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.1566\u001B[0m  0.4443\n",
      "      3        \u001B[36m1.2257\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m1.0647\u001B[0m  0.4245\n",
      "      4        \u001B[36m1.0930\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.9929\u001B[0m  0.4328\n",
      "      5        \u001B[36m1.0082\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.9332\u001B[0m  0.4442\n",
      "      6        \u001B[36m0.9058\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.9225\u001B[0m  0.4296\n",
      "      7        \u001B[36m0.8580\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.8702\u001B[0m  0.4273\n",
      "      8        \u001B[36m0.8146\u001B[0m       0.7603        \u001B[35m0.8677\u001B[0m  0.4420\n",
      "      9        \u001B[36m0.7518\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.8517\u001B[0m  0.4322\n",
      "     10        \u001B[36m0.7216\u001B[0m       0.7636        \u001B[35m0.8392\u001B[0m  0.4221\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0610\u001B[0m       \u001B[32m0.4975\u001B[0m        \u001B[35m1.3982\u001B[0m  0.4290\n",
      "      2        \u001B[36m1.5006\u001B[0m       \u001B[32m0.6099\u001B[0m        \u001B[35m1.1803\u001B[0m  0.4213\n",
      "      3        \u001B[36m1.2613\u001B[0m       \u001B[32m0.6777\u001B[0m        \u001B[35m1.0589\u001B[0m  0.4380\n",
      "      4        \u001B[36m1.1013\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m0.9912\u001B[0m  0.4300\n",
      "      5        \u001B[36m0.9947\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.9541\u001B[0m  0.4226\n",
      "      6        \u001B[36m0.9187\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.9039\u001B[0m  0.4341\n",
      "      7        \u001B[36m0.8467\u001B[0m       0.7372        \u001B[35m0.8803\u001B[0m  0.4292\n",
      "      8        \u001B[36m0.8200\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8437\u001B[0m  0.4245\n",
      "      9        \u001B[36m0.7563\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8178\u001B[0m  0.4315\n",
      "     10        \u001B[36m0.7156\u001B[0m       0.7471        \u001B[35m0.8140\u001B[0m  0.4218\n",
      "[CV] END batch_size=32, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   4.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6490\u001B[0m       \u001B[32m0.5934\u001B[0m        \u001B[35m1.1499\u001B[0m  0.4794\n",
      "      2        \u001B[36m1.0847\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m0.9358\u001B[0m  0.2234\n",
      "      3        \u001B[36m0.8964\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.8350\u001B[0m  0.2294\n",
      "      4        \u001B[36m0.7821\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7741\u001B[0m  0.2199\n",
      "      5        \u001B[36m0.6851\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7337\u001B[0m  0.2208\n",
      "      6        \u001B[36m0.6291\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6973\u001B[0m  0.2336\n",
      "      7        \u001B[36m0.5645\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.6914\u001B[0m  0.2248\n",
      "      8        \u001B[36m0.5265\u001B[0m       0.7835        0.6988  0.2199\n",
      "      9        \u001B[36m0.4879\u001B[0m       \u001B[32m0.8083\u001B[0m        \u001B[35m0.6504\u001B[0m  0.2208\n",
      "     10        \u001B[36m0.4455\u001B[0m       0.7950        0.6656  0.2199\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6064\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.1732\u001B[0m  0.3321\n",
      "      2        \u001B[36m1.0709\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m0.9488\u001B[0m  0.2293\n",
      "      3        \u001B[36m0.8875\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.8605\u001B[0m  0.2183\n",
      "      4        \u001B[36m0.7501\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.7877\u001B[0m  0.2207\n",
      "      5        \u001B[36m0.6703\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7403\u001B[0m  0.2246\n",
      "      6        \u001B[36m0.5944\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7176\u001B[0m  0.2297\n",
      "      7        \u001B[36m0.5564\u001B[0m       \u001B[32m0.7884\u001B[0m        0.7218  0.2262\n",
      "      8        \u001B[36m0.5137\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.7055\u001B[0m  0.2330\n",
      "      9        \u001B[36m0.4779\u001B[0m       \u001B[32m0.8083\u001B[0m        \u001B[35m0.6907\u001B[0m  0.2207\n",
      "     10        \u001B[36m0.4515\u001B[0m       \u001B[32m0.8132\u001B[0m        \u001B[35m0.6826\u001B[0m  0.2217\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6532\u001B[0m       \u001B[32m0.6165\u001B[0m        \u001B[35m1.1296\u001B[0m  0.2317\n",
      "      2        \u001B[36m1.1056\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m0.9274\u001B[0m  0.2287\n",
      "      3        \u001B[36m0.8704\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.8319\u001B[0m  0.2291\n",
      "      4        \u001B[36m0.7670\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.7728\u001B[0m  0.2257\n",
      "      5        \u001B[36m0.6445\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7343\u001B[0m  0.2257\n",
      "      6        \u001B[36m0.6259\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.6930\u001B[0m  0.2377\n",
      "      7        \u001B[36m0.5567\u001B[0m       0.7851        \u001B[35m0.6803\u001B[0m  0.2294\n",
      "      8        \u001B[36m0.4755\u001B[0m       0.7818        \u001B[35m0.6746\u001B[0m  0.2328\n",
      "      9        \u001B[36m0.4533\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.6663\u001B[0m  0.2288\n",
      "     10        \u001B[36m0.4289\u001B[0m       0.7818        0.6742  0.2266\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7370\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.1189\u001B[0m  0.2371\n",
      "      2        \u001B[36m1.0936\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9062\u001B[0m  0.2228\n",
      "      3        \u001B[36m0.9020\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8133\u001B[0m  0.2202\n",
      "      4        \u001B[36m0.7860\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7521\u001B[0m  0.2229\n",
      "      5        \u001B[36m0.6729\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.7201\u001B[0m  0.2169\n",
      "      6        \u001B[36m0.6165\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7099\u001B[0m  0.2171\n",
      "      7        \u001B[36m0.5598\u001B[0m       0.7802        \u001B[35m0.6835\u001B[0m  0.2211\n",
      "      8        \u001B[36m0.5172\u001B[0m       \u001B[32m0.7983\u001B[0m        0.6905  0.2185\n",
      "      9        \u001B[36m0.4767\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6694\u001B[0m  0.2204\n",
      "     10        \u001B[36m0.4325\u001B[0m       0.8000        0.6804  0.2144\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6573\u001B[0m       \u001B[32m0.6430\u001B[0m        \u001B[35m1.0864\u001B[0m  0.2255\n",
      "      2        \u001B[36m1.0546\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m0.8630\u001B[0m  0.2249\n",
      "      3        \u001B[36m0.8547\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.7692\u001B[0m  0.2239\n",
      "      4        \u001B[36m0.7213\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7155\u001B[0m  0.2206\n",
      "      5        \u001B[36m0.6688\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.6927\u001B[0m  0.2143\n",
      "      6        \u001B[36m0.6131\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.6550\u001B[0m  0.2149\n",
      "      7        \u001B[36m0.5601\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.6542\u001B[0m  0.2150\n",
      "      8        \u001B[36m0.5039\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.6389\u001B[0m  0.2279\n",
      "      9        \u001B[36m0.4657\u001B[0m       0.7950        \u001B[35m0.6335\u001B[0m  0.2185\n",
      "     10        \u001B[36m0.4305\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6327\u001B[0m  0.2179\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6281\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.1304\u001B[0m  0.2156\n",
      "      2        \u001B[36m1.0603\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m0.8878\u001B[0m  0.2127\n",
      "      3        \u001B[36m0.8527\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.8116\u001B[0m  0.2247\n",
      "      4        \u001B[36m0.7458\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7238\u001B[0m  0.2244\n",
      "      5        \u001B[36m0.6465\u001B[0m       0.7636        \u001B[35m0.6990\u001B[0m  0.2230\n",
      "      6        \u001B[36m0.5669\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.6720\u001B[0m  0.2175\n",
      "      7        \u001B[36m0.5208\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.6655\u001B[0m  0.2162\n",
      "      8        \u001B[36m0.4694\u001B[0m       0.7835        0.6777  0.2175\n",
      "      9        \u001B[36m0.4347\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6450\u001B[0m  0.2232\n",
      "     10        \u001B[36m0.4060\u001B[0m       0.7901        0.6853  0.2217\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6559\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.0730\u001B[0m  0.3072\n",
      "      2        \u001B[36m1.0717\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.8919\u001B[0m  0.2175\n",
      "      3        \u001B[36m0.8515\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8534\u001B[0m  0.2135\n",
      "      4        \u001B[36m0.7489\u001B[0m       0.7521        \u001B[35m0.7798\u001B[0m  0.2222\n",
      "      5        \u001B[36m0.6452\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.7556\u001B[0m  0.2195\n",
      "      6        \u001B[36m0.6285\u001B[0m       0.7471        \u001B[35m0.7485\u001B[0m  0.2191\n",
      "      7        \u001B[36m0.5509\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.7054\u001B[0m  0.2214\n",
      "      8        \u001B[36m0.5084\u001B[0m       0.7653        0.7085  0.2156\n",
      "      9        \u001B[36m0.4393\u001B[0m       0.7719        0.7315  0.2148\n",
      "     10        \u001B[36m0.4195\u001B[0m       0.7653        0.7219  0.2195\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6539\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.0563\u001B[0m  0.2687\n",
      "      2        \u001B[36m1.0434\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.8265\u001B[0m  0.2120\n",
      "      3        \u001B[36m0.8442\u001B[0m       0.7388        \u001B[35m0.7537\u001B[0m  0.2159\n",
      "      4        \u001B[36m0.7337\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7273\u001B[0m  0.2128\n",
      "      5        \u001B[36m0.6574\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.6968\u001B[0m  0.2227\n",
      "      6        \u001B[36m0.5856\u001B[0m       0.7719        \u001B[35m0.6748\u001B[0m  0.2186\n",
      "      7        \u001B[36m0.5404\u001B[0m       0.7669        0.6810  0.2207\n",
      "      8        \u001B[36m0.4861\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.6638\u001B[0m  0.2149\n",
      "      9        \u001B[36m0.4667\u001B[0m       \u001B[32m0.7851\u001B[0m        0.6781  0.2138\n",
      "     10        \u001B[36m0.4130\u001B[0m       \u001B[32m0.8000\u001B[0m        0.6803  0.2234\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6296\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.0570\u001B[0m  0.2192\n",
      "      2        \u001B[36m1.0174\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.8489\u001B[0m  0.2205\n",
      "      3        \u001B[36m0.8240\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.7673\u001B[0m  0.2239\n",
      "      4        \u001B[36m0.7233\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.7160\u001B[0m  0.2254\n",
      "      5        \u001B[36m0.6401\u001B[0m       0.7868        \u001B[35m0.7106\u001B[0m  0.2181\n",
      "      6        \u001B[36m0.5840\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6590\u001B[0m  0.2235\n",
      "      7        \u001B[36m0.5073\u001B[0m       \u001B[32m0.8149\u001B[0m        \u001B[35m0.6302\u001B[0m  0.2230\n",
      "      8        \u001B[36m0.4660\u001B[0m       0.8116        0.6317  0.2198\n",
      "      9        \u001B[36m0.4257\u001B[0m       0.8149        0.6459  0.2241\n",
      "     10        \u001B[36m0.4053\u001B[0m       \u001B[32m0.8165\u001B[0m        \u001B[35m0.6250\u001B[0m  0.2308\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4965\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m0.9717\u001B[0m  0.2922\n",
      "      2        \u001B[36m0.8762\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7512\u001B[0m  0.2310\n",
      "      3        \u001B[36m0.7084\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.6891\u001B[0m  0.2262\n",
      "      4        \u001B[36m0.5992\u001B[0m       \u001B[32m0.8182\u001B[0m        \u001B[35m0.6417\u001B[0m  0.2221\n",
      "      5        \u001B[36m0.5194\u001B[0m       0.8116        \u001B[35m0.6362\u001B[0m  0.2212\n",
      "      6        \u001B[36m0.4581\u001B[0m       \u001B[32m0.8364\u001B[0m        \u001B[35m0.5928\u001B[0m  0.2294\n",
      "      7        \u001B[36m0.4247\u001B[0m       0.8281        0.6204  0.2309\n",
      "      8        \u001B[36m0.3845\u001B[0m       0.8248        0.6444  0.2293\n",
      "      9        \u001B[36m0.3568\u001B[0m       0.8165        0.6089  0.2290\n",
      "     10        \u001B[36m0.3097\u001B[0m       0.8298        0.6024  0.2332\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4629\u001B[0m       \u001B[32m0.6479\u001B[0m        \u001B[35m1.0681\u001B[0m  0.2650\n",
      "      2        \u001B[36m0.8778\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8254\u001B[0m  0.2268\n",
      "      3        \u001B[36m0.7122\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7467\u001B[0m  0.2354\n",
      "      4        \u001B[36m0.5997\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.7181\u001B[0m  0.2390\n",
      "      5        \u001B[36m0.5156\u001B[0m       0.7917        \u001B[35m0.6998\u001B[0m  0.2400\n",
      "      6        \u001B[36m0.4650\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.6718\u001B[0m  0.2324\n",
      "      7        \u001B[36m0.3944\u001B[0m       \u001B[32m0.8165\u001B[0m        \u001B[35m0.6509\u001B[0m  0.2279\n",
      "      8        \u001B[36m0.3460\u001B[0m       0.8099        0.6671  0.2385\n",
      "      9        \u001B[36m0.3259\u001B[0m       0.7901        0.6950  0.2366\n",
      "     10        \u001B[36m0.3046\u001B[0m       0.8050        0.6920  0.2388\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3869\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m1.0650\u001B[0m  0.2230\n",
      "      2        \u001B[36m0.8688\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.8196\u001B[0m  0.2169\n",
      "      3        \u001B[36m0.6812\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7677\u001B[0m  0.2260\n",
      "      4        \u001B[36m0.5735\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7235\u001B[0m  0.2288\n",
      "      5        \u001B[36m0.4874\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.6958\u001B[0m  0.2197\n",
      "      6        \u001B[36m0.4215\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6713\u001B[0m  0.2204\n",
      "      7        \u001B[36m0.3912\u001B[0m       0.8017        0.6954  0.2208\n",
      "      8        \u001B[36m0.3490\u001B[0m       0.7934        0.6872  0.2314\n",
      "      9        \u001B[36m0.3230\u001B[0m       0.8033        0.6930  0.2223\n",
      "     10        \u001B[36m0.3000\u001B[0m       0.8033        0.6979  0.2280\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5728\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0001\u001B[0m  0.2185\n",
      "      2        \u001B[36m0.9242\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7985\u001B[0m  0.2190\n",
      "      3        \u001B[36m0.7222\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.7251\u001B[0m  0.2133\n",
      "      4        \u001B[36m0.6049\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.6667\u001B[0m  0.2235\n",
      "      5        \u001B[36m0.5395\u001B[0m       \u001B[32m0.8099\u001B[0m        0.6792  0.2206\n",
      "      6        \u001B[36m0.4566\u001B[0m       0.7950        0.6675  0.2239\n",
      "      7        \u001B[36m0.4009\u001B[0m       0.7884        \u001B[35m0.6433\u001B[0m  0.2183\n",
      "      8        \u001B[36m0.3471\u001B[0m       0.7917        0.6521  0.2197\n",
      "      9        0.3479       0.7983        0.6652  0.2152\n",
      "     10        \u001B[36m0.3218\u001B[0m       0.8033        0.6511  0.2189\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4901\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m0.9544\u001B[0m  0.2232\n",
      "      2        \u001B[36m0.8905\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.7554\u001B[0m  0.2233\n",
      "      3        \u001B[36m0.7117\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.7017\u001B[0m  0.2254\n",
      "      4        \u001B[36m0.6058\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6795\u001B[0m  0.2150\n",
      "      5        \u001B[36m0.5135\u001B[0m       \u001B[32m0.8198\u001B[0m        \u001B[35m0.6541\u001B[0m  0.2174\n",
      "      6        \u001B[36m0.4764\u001B[0m       0.8116        \u001B[35m0.6343\u001B[0m  0.2219\n",
      "      7        \u001B[36m0.4187\u001B[0m       \u001B[32m0.8314\u001B[0m        0.6454  0.2245\n",
      "      8        \u001B[36m0.3605\u001B[0m       0.8264        0.6602  0.2208\n",
      "      9        \u001B[36m0.3419\u001B[0m       0.8231        0.6539  0.2233\n",
      "     10        \u001B[36m0.3181\u001B[0m       0.8198        0.6439  0.2157\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4266\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m0.9549\u001B[0m  0.2165\n",
      "      2        \u001B[36m0.8329\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.7640\u001B[0m  0.2243\n",
      "      3        \u001B[36m0.6789\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.6895\u001B[0m  0.2238\n",
      "      4        \u001B[36m0.5699\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.6819\u001B[0m  0.2246\n",
      "      5        \u001B[36m0.4956\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.6462\u001B[0m  0.2167\n",
      "      6        \u001B[36m0.4235\u001B[0m       0.8000        0.6669  0.2159\n",
      "      7        \u001B[36m0.3572\u001B[0m       0.8017        0.6773  0.2221\n",
      "      8        \u001B[36m0.3441\u001B[0m       \u001B[32m0.8165\u001B[0m        0.6715  0.2240\n",
      "      9        \u001B[36m0.3038\u001B[0m       0.8099        0.6928  0.2210\n",
      "     10        \u001B[36m0.2846\u001B[0m       0.8083        0.7012  0.2283\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5191\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.9105\u001B[0m  0.2346\n",
      "      2        \u001B[36m0.8680\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.7308\u001B[0m  0.2098\n",
      "      3        \u001B[36m0.7043\u001B[0m       0.7769        \u001B[35m0.7239\u001B[0m  0.2128\n",
      "      4        \u001B[36m0.5812\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.6933\u001B[0m  0.2134\n",
      "      5        \u001B[36m0.4909\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6439\u001B[0m  0.2146\n",
      "      6        \u001B[36m0.4654\u001B[0m       0.7950        0.6585  0.2094\n",
      "      7        \u001B[36m0.4058\u001B[0m       0.8033        0.6541  0.2096\n",
      "      8        \u001B[36m0.3584\u001B[0m       0.8017        0.6680  0.2109\n",
      "      9        \u001B[36m0.3270\u001B[0m       0.7917        0.6889  0.2208\n",
      "     10        \u001B[36m0.3107\u001B[0m       0.7802        0.7458  0.2207\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4983\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m0.9026\u001B[0m  0.2239\n",
      "      2        \u001B[36m0.8596\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.7841\u001B[0m  0.2196\n",
      "      3        \u001B[36m0.6841\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.6802\u001B[0m  0.2106\n",
      "      4        \u001B[36m0.5993\u001B[0m       0.7835        \u001B[35m0.6734\u001B[0m  0.2105\n",
      "      5        \u001B[36m0.5012\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6558\u001B[0m  0.2187\n",
      "      6        \u001B[36m0.4486\u001B[0m       \u001B[32m0.8165\u001B[0m        0.6805  0.2207\n",
      "      7        \u001B[36m0.4039\u001B[0m       0.8050        0.6847  0.2175\n",
      "      8        \u001B[36m0.3737\u001B[0m       \u001B[32m0.8198\u001B[0m        0.6767  0.2216\n",
      "      9        \u001B[36m0.3263\u001B[0m       0.7917        0.7361  0.2132\n",
      "     10        \u001B[36m0.3090\u001B[0m       0.8132        0.6911  0.2112\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5081\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m0.9318\u001B[0m  0.2273\n",
      "      2        \u001B[36m0.9024\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7931\u001B[0m  0.2176\n",
      "      3        \u001B[36m0.7126\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7232\u001B[0m  0.2145\n",
      "      4        \u001B[36m0.5804\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7124\u001B[0m  0.2161\n",
      "      5        \u001B[36m0.5085\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.6983\u001B[0m  0.2187\n",
      "      6        \u001B[36m0.4635\u001B[0m       \u001B[32m0.8000\u001B[0m        0.7109  0.2089\n",
      "      7        \u001B[36m0.3976\u001B[0m       0.8000        0.7258  0.2122\n",
      "      8        \u001B[36m0.3496\u001B[0m       0.8000        0.7447  0.2214\n",
      "      9        \u001B[36m0.3276\u001B[0m       \u001B[32m0.8083\u001B[0m        0.7950  0.2165\n",
      "     10        \u001B[36m0.3110\u001B[0m       \u001B[32m0.8116\u001B[0m        0.7576  0.2139\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3301\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8446\u001B[0m  0.3777\n",
      "      2        \u001B[36m0.7322\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6963\u001B[0m  0.2110\n",
      "      3        \u001B[36m0.5669\u001B[0m       \u001B[32m0.8132\u001B[0m        \u001B[35m0.6555\u001B[0m  0.2141\n",
      "      4        \u001B[36m0.4613\u001B[0m       \u001B[32m0.8314\u001B[0m        \u001B[35m0.6175\u001B[0m  0.2181\n",
      "      5        \u001B[36m0.3992\u001B[0m       0.8248        \u001B[35m0.6093\u001B[0m  0.2201\n",
      "      6        \u001B[36m0.3241\u001B[0m       0.8165        0.6363  0.2210\n",
      "      7        \u001B[36m0.2897\u001B[0m       0.8248        0.6187  0.2181\n",
      "      8        \u001B[36m0.2520\u001B[0m       0.8017        0.6568  0.2104\n",
      "      9        \u001B[36m0.2255\u001B[0m       0.8149        0.6439  0.2109\n",
      "     10        \u001B[36m0.2112\u001B[0m       0.8033        0.6553  0.2144\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.2505\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.8883\u001B[0m  0.2947\n",
      "      2        \u001B[36m0.7013\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7113\u001B[0m  0.2320\n",
      "      3        \u001B[36m0.5247\u001B[0m       \u001B[32m0.7835\u001B[0m        \u001B[35m0.7104\u001B[0m  0.2172\n",
      "      4        \u001B[36m0.4528\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6440\u001B[0m  0.2165\n",
      "      5        \u001B[36m0.3709\u001B[0m       0.7950        \u001B[35m0.6404\u001B[0m  0.2205\n",
      "      6        \u001B[36m0.3255\u001B[0m       \u001B[32m0.8099\u001B[0m        0.6675  0.2254\n",
      "      7        \u001B[36m0.2821\u001B[0m       \u001B[32m0.8165\u001B[0m        0.6579  0.2169\n",
      "      8        \u001B[36m0.2442\u001B[0m       0.8165        0.6873  0.2196\n",
      "      9        \u001B[36m0.2168\u001B[0m       0.8066        0.7195  0.2151\n",
      "     10        \u001B[36m0.2005\u001B[0m       0.8050        0.7383  0.2268\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.2989\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9029\u001B[0m  0.2212\n",
      "      2        \u001B[36m0.6827\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.7133\u001B[0m  0.2130\n",
      "      3        \u001B[36m0.5378\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.6897\u001B[0m  0.2191\n",
      "      4        \u001B[36m0.4345\u001B[0m       \u001B[32m0.8017\u001B[0m        0.6936  0.2114\n",
      "      5        \u001B[36m0.3695\u001B[0m       \u001B[32m0.8050\u001B[0m        0.7028  0.2066\n",
      "      6        \u001B[36m0.3038\u001B[0m       \u001B[32m0.8066\u001B[0m        0.6970  0.2219\n",
      "      7        \u001B[36m0.2743\u001B[0m       0.8000        0.6919  0.2232\n",
      "      8        \u001B[36m0.2279\u001B[0m       \u001B[32m0.8116\u001B[0m        0.7246  0.2169\n",
      "      9        \u001B[36m0.2156\u001B[0m       0.8017        0.7432  0.2204\n",
      "     10        \u001B[36m0.1870\u001B[0m       0.8033        0.7523  0.2114\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3528\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.8529\u001B[0m  0.2522\n",
      "      2        \u001B[36m0.7474\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6833\u001B[0m  0.2283\n",
      "      3        \u001B[36m0.5512\u001B[0m       \u001B[32m0.8231\u001B[0m        \u001B[35m0.6259\u001B[0m  0.2319\n",
      "      4        \u001B[36m0.4616\u001B[0m       \u001B[32m0.8298\u001B[0m        \u001B[35m0.6228\u001B[0m  0.2142\n",
      "      5        \u001B[36m0.3931\u001B[0m       \u001B[32m0.8446\u001B[0m        \u001B[35m0.6072\u001B[0m  0.2147\n",
      "      6        \u001B[36m0.3290\u001B[0m       0.8248        0.6323  0.2103\n",
      "      7        \u001B[36m0.2784\u001B[0m       0.8264        \u001B[35m0.6037\u001B[0m  0.2221\n",
      "      8        \u001B[36m0.2575\u001B[0m       0.8149        0.6359  0.2289\n",
      "      9        0.2583       0.8198        0.6098  0.2258\n",
      "     10        \u001B[36m0.2071\u001B[0m       0.8215        0.6675  0.2209\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3725\u001B[0m       \u001B[32m0.6777\u001B[0m        \u001B[35m0.9026\u001B[0m  0.2364\n",
      "      2        \u001B[36m0.7564\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.7633\u001B[0m  0.2125\n",
      "      3        \u001B[36m0.5717\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7493\u001B[0m  0.2173\n",
      "      4        \u001B[36m0.4705\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.7154\u001B[0m  0.2188\n",
      "      5        \u001B[36m0.3959\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.7001\u001B[0m  0.2165\n",
      "      6        \u001B[36m0.3448\u001B[0m       \u001B[32m0.8083\u001B[0m        \u001B[35m0.6940\u001B[0m  0.2164\n",
      "      7        \u001B[36m0.3211\u001B[0m       0.7967        0.7086  0.2117\n",
      "      8        \u001B[36m0.2701\u001B[0m       0.8000        0.7127  0.2113\n",
      "      9        \u001B[36m0.2390\u001B[0m       \u001B[32m0.8165\u001B[0m        0.7079  0.2188\n",
      "     10        \u001B[36m0.2216\u001B[0m       0.7917        0.7562  0.2284\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3082\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.8472\u001B[0m  0.2221\n",
      "      2        \u001B[36m0.6959\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.6952\u001B[0m  0.2221\n",
      "      3        \u001B[36m0.5302\u001B[0m       \u001B[32m0.8215\u001B[0m        \u001B[35m0.6266\u001B[0m  0.2114\n",
      "      4        \u001B[36m0.4383\u001B[0m       0.8198        0.6510  0.2113\n",
      "      5        \u001B[36m0.3441\u001B[0m       0.8149        0.6586  0.2218\n",
      "      6        \u001B[36m0.3273\u001B[0m       0.8099        0.6422  0.2193\n",
      "      7        \u001B[36m0.2677\u001B[0m       0.8149        0.6566  0.2159\n",
      "      8        \u001B[36m0.2337\u001B[0m       0.8050        0.6935  0.2132\n",
      "      9        \u001B[36m0.2128\u001B[0m       \u001B[32m0.8231\u001B[0m        0.7371  0.2118\n",
      "     10        \u001B[36m0.1960\u001B[0m       0.8132        0.7683  0.2113\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3875\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.8775\u001B[0m  0.2750\n",
      "      2        \u001B[36m0.7524\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7544\u001B[0m  0.2216\n",
      "      3        \u001B[36m0.6208\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.7236\u001B[0m  0.2201\n",
      "      4        \u001B[36m0.4759\u001B[0m       \u001B[32m0.8017\u001B[0m        \u001B[35m0.7163\u001B[0m  0.2212\n",
      "      5        \u001B[36m0.4443\u001B[0m       0.7934        \u001B[35m0.7106\u001B[0m  0.2140\n",
      "      6        \u001B[36m0.3655\u001B[0m       0.7818        0.7918  0.2096\n",
      "      7        \u001B[36m0.3027\u001B[0m       0.7769        0.7872  0.2261\n",
      "      8        \u001B[36m0.2855\u001B[0m       0.7736        0.8114  0.2193\n",
      "      9        \u001B[36m0.2686\u001B[0m       0.7967        0.7896  0.2130\n",
      "     10        \u001B[36m0.2288\u001B[0m       0.7868        0.8335  0.2113\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4281\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.9279\u001B[0m  0.2355\n",
      "      2        \u001B[36m0.7862\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7948\u001B[0m  0.2271\n",
      "      3        \u001B[36m0.5967\u001B[0m       0.7669        0.8081  0.2222\n",
      "      4        \u001B[36m0.4948\u001B[0m       0.7752        \u001B[35m0.7271\u001B[0m  0.2296\n",
      "      5        \u001B[36m0.4078\u001B[0m       0.7752        0.8145  0.2166\n",
      "      6        \u001B[36m0.3425\u001B[0m       \u001B[32m0.8000\u001B[0m        0.7917  0.2134\n",
      "      7        \u001B[36m0.2902\u001B[0m       0.7835        0.7652  0.2131\n",
      "      8        \u001B[36m0.2688\u001B[0m       0.7917        0.7422  0.2151\n",
      "      9        \u001B[36m0.2506\u001B[0m       0.7702        0.8952  0.2053\n",
      "     10        0.2610       0.7818        0.8452  0.2111\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.2761\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.8392\u001B[0m  0.2148\n",
      "      2        \u001B[36m0.7160\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7734\u001B[0m  0.2206\n",
      "      3        \u001B[36m0.5325\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.6932\u001B[0m  0.2151\n",
      "      4        \u001B[36m0.4311\u001B[0m       \u001B[32m0.7835\u001B[0m        0.7144  0.2199\n",
      "      5        \u001B[36m0.3725\u001B[0m       \u001B[32m0.7934\u001B[0m        0.7501  0.2211\n",
      "      6        \u001B[36m0.3051\u001B[0m       \u001B[32m0.8116\u001B[0m        0.7320  0.2150\n",
      "      7        \u001B[36m0.2770\u001B[0m       0.7835        0.7929  0.2208\n",
      "      8        \u001B[36m0.2221\u001B[0m       0.7818        0.8881  0.2082\n",
      "      9        \u001B[36m0.2051\u001B[0m       0.8083        0.8066  0.2135\n",
      "     10        \u001B[36m0.1843\u001B[0m       0.8050        0.8350  0.2172\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7728\u001B[0m       \u001B[32m0.5835\u001B[0m        \u001B[35m1.1789\u001B[0m  0.2231\n",
      "      2        \u001B[36m1.1946\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m0.9998\u001B[0m  0.2220\n",
      "      3        \u001B[36m0.9706\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.8938\u001B[0m  0.2272\n",
      "      4        \u001B[36m0.8656\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.8135\u001B[0m  0.2228\n",
      "      5        \u001B[36m0.8044\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.7786\u001B[0m  0.2221\n",
      "      6        \u001B[36m0.7056\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7473\u001B[0m  0.2275\n",
      "      7        \u001B[36m0.6750\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7321\u001B[0m  0.2227\n",
      "      8        \u001B[36m0.6054\u001B[0m       \u001B[32m0.7983\u001B[0m        \u001B[35m0.6964\u001B[0m  0.2230\n",
      "      9        \u001B[36m0.5764\u001B[0m       0.7950        \u001B[35m0.6810\u001B[0m  0.2225\n",
      "     10        \u001B[36m0.5415\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6683\u001B[0m  0.2222\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8908\u001B[0m       \u001B[32m0.6116\u001B[0m        \u001B[35m1.2053\u001B[0m  0.2336\n",
      "      2        \u001B[36m1.2263\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m0.9896\u001B[0m  0.2343\n",
      "      3        \u001B[36m1.0149\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.8890\u001B[0m  0.2260\n",
      "      4        \u001B[36m0.8761\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.8060\u001B[0m  0.2268\n",
      "      5        \u001B[36m0.7769\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7621\u001B[0m  0.2209\n",
      "      6        \u001B[36m0.7308\u001B[0m       0.7554        0.7670  0.2212\n",
      "      7        \u001B[36m0.6730\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7301\u001B[0m  0.2272\n",
      "      8        \u001B[36m0.6206\u001B[0m       0.7752        \u001B[35m0.6898\u001B[0m  0.2269\n",
      "      9        \u001B[36m0.5720\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.6897\u001B[0m  0.2275\n",
      "     10        \u001B[36m0.5338\u001B[0m       0.7785        \u001B[35m0.6867\u001B[0m  0.2332\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7029\u001B[0m       \u001B[32m0.6116\u001B[0m        \u001B[35m1.2045\u001B[0m  0.2238\n",
      "      2        \u001B[36m1.2045\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0245\u001B[0m  0.2213\n",
      "      3        \u001B[36m0.9810\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.9140\u001B[0m  0.2268\n",
      "      4        \u001B[36m0.8318\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.8453\u001B[0m  0.2280\n",
      "      5        \u001B[36m0.7379\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.8018\u001B[0m  0.2277\n",
      "      6        \u001B[36m0.6902\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7934\u001B[0m  0.2289\n",
      "      7        \u001B[36m0.6458\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.7323\u001B[0m  0.2208\n",
      "      8        \u001B[36m0.5935\u001B[0m       0.7917        0.7410  0.2200\n",
      "      9        \u001B[36m0.5585\u001B[0m       0.8017        \u001B[35m0.7225\u001B[0m  0.2279\n",
      "     10        \u001B[36m0.5315\u001B[0m       \u001B[32m0.8149\u001B[0m        \u001B[35m0.7020\u001B[0m  0.2280\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7566\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.1428\u001B[0m  0.2212\n",
      "      2        \u001B[36m1.2140\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.9317\u001B[0m  0.2246\n",
      "      3        \u001B[36m1.0239\u001B[0m       0.7289        \u001B[35m0.8565\u001B[0m  0.2122\n",
      "      4        \u001B[36m0.9158\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.7924\u001B[0m  0.2164\n",
      "      5        \u001B[36m0.7761\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7607\u001B[0m  0.2205\n",
      "      6        \u001B[36m0.7232\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7296\u001B[0m  0.2244\n",
      "      7        \u001B[36m0.6701\u001B[0m       0.7686        \u001B[35m0.7165\u001B[0m  0.2217\n",
      "      8        \u001B[36m0.6612\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.6913\u001B[0m  0.2275\n",
      "      9        \u001B[36m0.6028\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.6817\u001B[0m  0.2160\n",
      "     10        \u001B[36m0.5790\u001B[0m       \u001B[32m0.7934\u001B[0m        \u001B[35m0.6652\u001B[0m  0.2153\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8415\u001B[0m       \u001B[32m0.6000\u001B[0m        \u001B[35m1.2121\u001B[0m  0.2216\n",
      "      2        \u001B[36m1.2082\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m0.9776\u001B[0m  0.2213\n",
      "      3        \u001B[36m1.0236\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.8668\u001B[0m  0.2210\n",
      "      4        \u001B[36m0.8946\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.8058\u001B[0m  0.2156\n",
      "      5        \u001B[36m0.7896\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.7719\u001B[0m  0.2157\n",
      "      6        \u001B[36m0.7313\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7574\u001B[0m  0.2193\n",
      "      7        \u001B[36m0.6550\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7269\u001B[0m  0.2248\n",
      "      8        \u001B[36m0.6196\u001B[0m       0.7769        \u001B[35m0.7049\u001B[0m  0.2228\n",
      "      9        \u001B[36m0.5769\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.6841\u001B[0m  0.2256\n",
      "     10        \u001B[36m0.5439\u001B[0m       \u001B[32m0.7917\u001B[0m        0.7036  0.2164\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8502\u001B[0m       \u001B[32m0.6000\u001B[0m        \u001B[35m1.1574\u001B[0m  0.2185\n",
      "      2        \u001B[36m1.2155\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m0.9606\u001B[0m  0.2176\n",
      "      3        \u001B[36m0.9781\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8657\u001B[0m  0.2200\n",
      "      4        \u001B[36m0.8849\u001B[0m       \u001B[32m0.7587\u001B[0m        \u001B[35m0.7987\u001B[0m  0.2226\n",
      "      5        \u001B[36m0.7695\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.7555\u001B[0m  0.2269\n",
      "      6        \u001B[36m0.6901\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7373\u001B[0m  0.2154\n",
      "      7        \u001B[36m0.6235\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.7017\u001B[0m  0.2155\n",
      "      8        \u001B[36m0.6192\u001B[0m       0.7950        \u001B[35m0.7004\u001B[0m  0.2214\n",
      "      9        \u001B[36m0.5674\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6855\u001B[0m  0.2210\n",
      "     10        \u001B[36m0.5314\u001B[0m       0.8033        0.6922  0.2225\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8794\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.1559\u001B[0m  0.2273\n",
      "      2        \u001B[36m1.2351\u001B[0m       \u001B[32m0.6810\u001B[0m        \u001B[35m0.9515\u001B[0m  0.2109\n",
      "      3        \u001B[36m1.0032\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.8742\u001B[0m  0.2180\n",
      "      4        \u001B[36m0.8874\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8077\u001B[0m  0.2131\n",
      "      5        \u001B[36m0.7904\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.7902\u001B[0m  0.2207\n",
      "      6        \u001B[36m0.7130\u001B[0m       0.7669        \u001B[35m0.7855\u001B[0m  0.2169\n",
      "      7        \u001B[36m0.6364\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7278\u001B[0m  0.2122\n",
      "      8        0.6402       0.7736        0.7335  0.2179\n",
      "      9        \u001B[36m0.5654\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.6969\u001B[0m  0.2154\n",
      "     10        \u001B[36m0.5360\u001B[0m       0.7884        \u001B[35m0.6843\u001B[0m  0.2247\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7637\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.0967\u001B[0m  0.2223\n",
      "      2        \u001B[36m1.2245\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m0.9612\u001B[0m  0.2209\n",
      "      3        \u001B[36m0.9845\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.8577\u001B[0m  0.2354\n",
      "      4        \u001B[36m0.8760\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.7938\u001B[0m  0.2234\n",
      "      5        \u001B[36m0.7960\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.7489\u001B[0m  0.2158\n",
      "      6        \u001B[36m0.7067\u001B[0m       0.7587        \u001B[35m0.7213\u001B[0m  0.2214\n",
      "      7        \u001B[36m0.6649\u001B[0m       0.7686        \u001B[35m0.6995\u001B[0m  0.2206\n",
      "      8        \u001B[36m0.6093\u001B[0m       0.7537        0.7101  0.2145\n",
      "      9        \u001B[36m0.5746\u001B[0m       0.7702        \u001B[35m0.6851\u001B[0m  0.2263\n",
      "     10        \u001B[36m0.5527\u001B[0m       \u001B[32m0.7752\u001B[0m        0.6943  0.2183\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8680\u001B[0m       \u001B[32m0.6116\u001B[0m        \u001B[35m1.1881\u001B[0m  0.2250\n",
      "      2        \u001B[36m1.2005\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m0.9353\u001B[0m  0.2225\n",
      "      3        \u001B[36m1.0057\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.8350\u001B[0m  0.2214\n",
      "      4        \u001B[36m0.8632\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.7874\u001B[0m  0.2232\n",
      "      5        \u001B[36m0.7728\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.7184\u001B[0m  0.2142\n",
      "      6        \u001B[36m0.6943\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.6832\u001B[0m  0.2133\n",
      "      7        \u001B[36m0.6324\u001B[0m       0.7686        0.6861  0.2134\n",
      "      8        \u001B[36m0.5996\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.6531\u001B[0m  0.2185\n",
      "      9        \u001B[36m0.5446\u001B[0m       0.7752        0.6858  0.2212\n",
      "     10        \u001B[36m0.4995\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.6368\u001B[0m  0.2144\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6097\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m1.0474\u001B[0m  0.2190\n",
      "      2        \u001B[36m0.9914\u001B[0m       \u001B[32m0.7570\u001B[0m        \u001B[35m0.8426\u001B[0m  0.2222\n",
      "      3        \u001B[36m0.8020\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7496\u001B[0m  0.2343\n",
      "      4        \u001B[36m0.6960\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.7133\u001B[0m  0.2223\n",
      "      5        \u001B[36m0.6175\u001B[0m       0.7884        \u001B[35m0.7071\u001B[0m  0.2227\n",
      "      6        \u001B[36m0.5690\u001B[0m       \u001B[32m0.8231\u001B[0m        \u001B[35m0.6516\u001B[0m  0.2191\n",
      "      7        \u001B[36m0.5121\u001B[0m       0.8083        0.6643  0.2187\n",
      "      8        \u001B[36m0.4676\u001B[0m       0.8083        0.6611  0.2304\n",
      "      9        \u001B[36m0.4292\u001B[0m       0.8083        0.6540  0.2259\n",
      "     10        \u001B[36m0.3956\u001B[0m       0.8215        \u001B[35m0.6368\u001B[0m  0.2223\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5581\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.0976\u001B[0m  0.2187\n",
      "      2        \u001B[36m0.9962\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.8705\u001B[0m  0.2172\n",
      "      3        \u001B[36m0.7751\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7731\u001B[0m  0.2271\n",
      "      4        \u001B[36m0.6984\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7179\u001B[0m  0.2322\n",
      "      5        \u001B[36m0.6099\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.7105\u001B[0m  0.2324\n",
      "      6        \u001B[36m0.5551\u001B[0m       0.7818        \u001B[35m0.6884\u001B[0m  0.2196\n",
      "      7        \u001B[36m0.5046\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6674\u001B[0m  0.2188\n",
      "      8        \u001B[36m0.4641\u001B[0m       \u001B[32m0.8099\u001B[0m        \u001B[35m0.6409\u001B[0m  0.2200\n",
      "      9        \u001B[36m0.4272\u001B[0m       0.7983        0.6740  0.2329\n",
      "     10        \u001B[36m0.3921\u001B[0m       \u001B[32m0.8116\u001B[0m        0.6818  0.2273\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5688\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0760\u001B[0m  0.2185\n",
      "      2        \u001B[36m0.9734\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.8701\u001B[0m  0.2179\n",
      "      3        \u001B[36m0.7836\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.7791\u001B[0m  0.2179\n",
      "      4        \u001B[36m0.6723\u001B[0m       \u001B[32m0.7868\u001B[0m        \u001B[35m0.7390\u001B[0m  0.2312\n",
      "      5        \u001B[36m0.6064\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6958\u001B[0m  0.2231\n",
      "      6        \u001B[36m0.5310\u001B[0m       0.8033        0.6962  0.2216\n",
      "      7        \u001B[36m0.4774\u001B[0m       0.7967        0.7006  0.2306\n",
      "      8        \u001B[36m0.4411\u001B[0m       0.8017        \u001B[35m0.6710\u001B[0m  0.2204\n",
      "      9        \u001B[36m0.4087\u001B[0m       \u001B[32m0.8165\u001B[0m        \u001B[35m0.6699\u001B[0m  0.2181\n",
      "     10        \u001B[36m0.3816\u001B[0m       0.8132        0.6761  0.2212\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6680\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m1.0106\u001B[0m  0.2191\n",
      "      2        \u001B[36m1.0298\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.8151\u001B[0m  0.2225\n",
      "      3        \u001B[36m0.8393\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7716\u001B[0m  0.2315\n",
      "      4        \u001B[36m0.7279\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.6950\u001B[0m  0.2169\n",
      "      5        \u001B[36m0.6357\u001B[0m       0.7950        0.7006  0.2163\n",
      "      6        \u001B[36m0.5952\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.6866\u001B[0m  0.2162\n",
      "      7        \u001B[36m0.5233\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6813\u001B[0m  0.2233\n",
      "      8        \u001B[36m0.4847\u001B[0m       0.7983        0.6853  0.2204\n",
      "      9        \u001B[36m0.4537\u001B[0m       0.7868        \u001B[35m0.6789\u001B[0m  0.2152\n",
      "     10        \u001B[36m0.4187\u001B[0m       0.7901        \u001B[35m0.6687\u001B[0m  0.2149\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5772\u001B[0m       \u001B[32m0.6777\u001B[0m        \u001B[35m1.0439\u001B[0m  0.2233\n",
      "      2        \u001B[36m0.9924\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.8367\u001B[0m  0.2223\n",
      "      3        \u001B[36m0.8121\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.7597\u001B[0m  0.2199\n",
      "      4        \u001B[36m0.6899\u001B[0m       0.7537        \u001B[35m0.7234\u001B[0m  0.2266\n",
      "      5        \u001B[36m0.6274\u001B[0m       \u001B[32m0.7769\u001B[0m        \u001B[35m0.7075\u001B[0m  0.2141\n",
      "      6        \u001B[36m0.5624\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.6975\u001B[0m  0.2143\n",
      "      7        \u001B[36m0.5222\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.6828\u001B[0m  0.2221\n",
      "      8        \u001B[36m0.4918\u001B[0m       0.7802        \u001B[35m0.6591\u001B[0m  0.2208\n",
      "      9        \u001B[36m0.4389\u001B[0m       0.7868        0.6931  0.2207\n",
      "     10        \u001B[36m0.4204\u001B[0m       0.7851        0.6811  0.2231\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6032\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0371\u001B[0m  0.2151\n",
      "      2        \u001B[36m0.9697\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.8434\u001B[0m  0.2153\n",
      "      3        \u001B[36m0.8076\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7684\u001B[0m  0.2178\n",
      "      4        \u001B[36m0.7063\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.7182\u001B[0m  0.2223\n",
      "      5        \u001B[36m0.6127\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6832\u001B[0m  0.2177\n",
      "      6        \u001B[36m0.5426\u001B[0m       \u001B[32m0.8099\u001B[0m        \u001B[35m0.6795\u001B[0m  0.2176\n",
      "      7        \u001B[36m0.5017\u001B[0m       0.7818        0.6908  0.2170\n",
      "      8        \u001B[36m0.4339\u001B[0m       \u001B[32m0.8198\u001B[0m        0.6811  0.2128\n",
      "      9        0.4377       0.8099        \u001B[35m0.6617\u001B[0m  0.2256\n",
      "     10        \u001B[36m0.3960\u001B[0m       0.7950        0.6868  0.2202\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6906\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0086\u001B[0m  0.2125\n",
      "      2        \u001B[36m1.0645\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.8463\u001B[0m  0.2096\n",
      "      3        \u001B[36m0.8598\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.8098\u001B[0m  0.2099\n",
      "      4        \u001B[36m0.7152\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7516\u001B[0m  0.2131\n",
      "      5        \u001B[36m0.6865\u001B[0m       \u001B[32m0.7736\u001B[0m        \u001B[35m0.7330\u001B[0m  0.2208\n",
      "      6        \u001B[36m0.5937\u001B[0m       0.7438        \u001B[35m0.7239\u001B[0m  0.2149\n",
      "      7        \u001B[36m0.5141\u001B[0m       0.7620        \u001B[35m0.7127\u001B[0m  0.2209\n",
      "      8        \u001B[36m0.4674\u001B[0m       0.7620        \u001B[35m0.6959\u001B[0m  0.2097\n",
      "      9        \u001B[36m0.4406\u001B[0m       \u001B[32m0.7884\u001B[0m        \u001B[35m0.6753\u001B[0m  0.2088\n",
      "     10        \u001B[36m0.4328\u001B[0m       0.7851        0.7073  0.2123\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.7071\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0107\u001B[0m  0.2149\n",
      "      2        \u001B[36m1.0054\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.8400\u001B[0m  0.2155\n",
      "      3        \u001B[36m0.8459\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7797\u001B[0m  0.2165\n",
      "      4        \u001B[36m0.7044\u001B[0m       \u001B[32m0.7818\u001B[0m        \u001B[35m0.7383\u001B[0m  0.2178\n",
      "      5        \u001B[36m0.6285\u001B[0m       0.7719        \u001B[35m0.7099\u001B[0m  0.2102\n",
      "      6        \u001B[36m0.5816\u001B[0m       0.7785        0.7151  0.2053\n",
      "      7        \u001B[36m0.5337\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.6849\u001B[0m  0.2203\n",
      "      8        \u001B[36m0.5080\u001B[0m       0.7719        0.7092  0.2149\n",
      "      9        \u001B[36m0.4584\u001B[0m       \u001B[32m0.7917\u001B[0m        0.6870  0.2116\n",
      "     10        \u001B[36m0.3915\u001B[0m       0.7917        0.7249  0.2107\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.6253\u001B[0m       \u001B[32m0.6744\u001B[0m        \u001B[35m1.0067\u001B[0m  0.2075\n",
      "      2        \u001B[36m0.9903\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.8089\u001B[0m  0.2226\n",
      "      3        \u001B[36m0.8152\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.7094\u001B[0m  0.2131\n",
      "      4        \u001B[36m0.6959\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.6788\u001B[0m  0.2099\n",
      "      5        \u001B[36m0.6333\u001B[0m       \u001B[32m0.8132\u001B[0m        \u001B[35m0.6537\u001B[0m  0.2100\n",
      "      6        \u001B[36m0.5491\u001B[0m       0.8099        \u001B[35m0.6408\u001B[0m  0.2095\n",
      "      7        \u001B[36m0.5338\u001B[0m       \u001B[32m0.8165\u001B[0m        \u001B[35m0.6365\u001B[0m  0.2151\n",
      "      8        \u001B[36m0.4566\u001B[0m       0.8099        0.6513  0.2289\n",
      "      9        \u001B[36m0.4071\u001B[0m       0.8099        0.6377  0.2114\n",
      "     10        \u001B[36m0.3753\u001B[0m       0.8083        0.6729  0.2212\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4651\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m0.9151\u001B[0m  0.2118\n",
      "      2        \u001B[36m0.8311\u001B[0m       \u001B[32m0.7785\u001B[0m        \u001B[35m0.7474\u001B[0m  0.2105\n",
      "      3        \u001B[36m0.6213\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6981\u001B[0m  0.2172\n",
      "      4        \u001B[36m0.5366\u001B[0m       \u001B[32m0.8182\u001B[0m        \u001B[35m0.6724\u001B[0m  0.2203\n",
      "      5        \u001B[36m0.4870\u001B[0m       0.8099        \u001B[35m0.6663\u001B[0m  0.2150\n",
      "      6        \u001B[36m0.4210\u001B[0m       0.8033        0.6760  0.2166\n",
      "      7        \u001B[36m0.3783\u001B[0m       0.8017        \u001B[35m0.6448\u001B[0m  0.2119\n",
      "      8        \u001B[36m0.3414\u001B[0m       0.8099        0.6513  0.2105\n",
      "      9        \u001B[36m0.3009\u001B[0m       0.8017        0.6976  0.2132\n",
      "     10        \u001B[36m0.2821\u001B[0m       0.8165        0.6511  0.2176\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3970\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9105\u001B[0m  0.2127\n",
      "      2        \u001B[36m0.7986\u001B[0m       \u001B[32m0.7603\u001B[0m        \u001B[35m0.7517\u001B[0m  0.2128\n",
      "      3        \u001B[36m0.6416\u001B[0m       \u001B[32m0.7917\u001B[0m        \u001B[35m0.6777\u001B[0m  0.2104\n",
      "      4        \u001B[36m0.5460\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6339\u001B[0m  0.2144\n",
      "      5        \u001B[36m0.4851\u001B[0m       \u001B[32m0.8248\u001B[0m        0.6388  0.2165\n",
      "      6        \u001B[36m0.4217\u001B[0m       0.8050        0.6373  0.2179\n",
      "      7        \u001B[36m0.3700\u001B[0m       \u001B[32m0.8264\u001B[0m        0.6418  0.2136\n",
      "      8        \u001B[36m0.3316\u001B[0m       0.8165        \u001B[35m0.6249\u001B[0m  0.2117\n",
      "      9        \u001B[36m0.3026\u001B[0m       0.8198        0.6519  0.2057\n",
      "     10        \u001B[36m0.2757\u001B[0m       0.8017        0.6836  0.2153\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4695\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m0.9328\u001B[0m  0.2154\n",
      "      2        \u001B[36m0.7966\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7691\u001B[0m  0.2137\n",
      "      3        \u001B[36m0.6118\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.7108\u001B[0m  0.2104\n",
      "      4        \u001B[36m0.5152\u001B[0m       0.7884        \u001B[35m0.6844\u001B[0m  0.2095\n",
      "      5        \u001B[36m0.4407\u001B[0m       \u001B[32m0.8165\u001B[0m        \u001B[35m0.6735\u001B[0m  0.2301\n",
      "      6        \u001B[36m0.3811\u001B[0m       0.8149        \u001B[35m0.6697\u001B[0m  0.2321\n",
      "      7        \u001B[36m0.3458\u001B[0m       0.8083        0.6714  0.2162\n",
      "      8        \u001B[36m0.2973\u001B[0m       0.8116        0.6884  0.2159\n",
      "      9        \u001B[36m0.2819\u001B[0m       0.8000        0.6770  0.2117\n",
      "     10        \u001B[36m0.2535\u001B[0m       0.8116        0.7049  0.2097\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4379\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.8842\u001B[0m  0.2292\n",
      "      2        \u001B[36m0.8115\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.7366\u001B[0m  0.2246\n",
      "      3        \u001B[36m0.6256\u001B[0m       \u001B[32m0.7950\u001B[0m        \u001B[35m0.6610\u001B[0m  0.2210\n",
      "      4        \u001B[36m0.5717\u001B[0m       0.7950        \u001B[35m0.6508\u001B[0m  0.2125\n",
      "      5        \u001B[36m0.4660\u001B[0m       \u001B[32m0.8000\u001B[0m        \u001B[35m0.6470\u001B[0m  0.2137\n",
      "      6        \u001B[36m0.4294\u001B[0m       \u001B[32m0.8198\u001B[0m        \u001B[35m0.5994\u001B[0m  0.2126\n",
      "      7        \u001B[36m0.3620\u001B[0m       0.8099        0.6012  0.2191\n",
      "      8        \u001B[36m0.3404\u001B[0m       \u001B[32m0.8298\u001B[0m        0.6004  0.2185\n",
      "      9        \u001B[36m0.3169\u001B[0m       0.8017        0.6242  0.2253\n",
      "     10        \u001B[36m0.2812\u001B[0m       0.8231        0.6201  0.2127\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5121\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m0.9714\u001B[0m  0.2093\n",
      "      2        \u001B[36m0.8532\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7944\u001B[0m  0.2147\n",
      "      3        \u001B[36m0.6599\u001B[0m       \u001B[32m0.7967\u001B[0m        \u001B[35m0.7263\u001B[0m  0.2189\n",
      "      4        \u001B[36m0.5810\u001B[0m       \u001B[32m0.8165\u001B[0m        \u001B[35m0.6790\u001B[0m  0.2182\n",
      "      5        \u001B[36m0.4890\u001B[0m       0.8132        \u001B[35m0.6644\u001B[0m  0.2206\n",
      "      6        \u001B[36m0.4327\u001B[0m       0.8017        0.6875  0.2162\n",
      "      7        \u001B[36m0.3696\u001B[0m       \u001B[32m0.8182\u001B[0m        \u001B[35m0.6397\u001B[0m  0.2123\n",
      "      8        \u001B[36m0.3656\u001B[0m       \u001B[32m0.8198\u001B[0m        0.6437  0.2121\n",
      "      9        \u001B[36m0.3154\u001B[0m       0.8000        0.6829  0.2174\n",
      "     10        \u001B[36m0.2936\u001B[0m       0.7983        0.7104  0.2166\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.3611\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.8847\u001B[0m  0.2191\n",
      "      2        \u001B[36m0.7763\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7241\u001B[0m  0.2186\n",
      "      3        \u001B[36m0.6152\u001B[0m       \u001B[32m0.8050\u001B[0m        \u001B[35m0.6792\u001B[0m  0.2119\n",
      "      4        \u001B[36m0.5247\u001B[0m       \u001B[32m0.8116\u001B[0m        0.6927  0.2108\n",
      "      5        \u001B[36m0.4366\u001B[0m       0.8050        \u001B[35m0.6628\u001B[0m  0.2165\n",
      "      6        \u001B[36m0.3783\u001B[0m       0.8099        \u001B[35m0.6539\u001B[0m  0.2232\n",
      "      7        \u001B[36m0.3539\u001B[0m       \u001B[32m0.8165\u001B[0m        0.6613  0.2184\n",
      "      8        \u001B[36m0.3199\u001B[0m       \u001B[32m0.8182\u001B[0m        0.6823  0.2143\n",
      "      9        \u001B[36m0.2899\u001B[0m       \u001B[32m0.8198\u001B[0m        0.6896  0.2137\n",
      "     10        \u001B[36m0.2345\u001B[0m       0.8099        0.6967  0.2086\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5679\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m0.9417\u001B[0m  0.2208\n",
      "      2        \u001B[36m0.9253\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.7414\u001B[0m  0.2127\n",
      "      3        \u001B[36m0.7275\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7174\u001B[0m  0.2172\n",
      "      4        \u001B[36m0.6004\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.6830\u001B[0m  0.2124\n",
      "      5        \u001B[36m0.5266\u001B[0m       \u001B[32m0.8083\u001B[0m        \u001B[35m0.6487\u001B[0m  0.2136\n",
      "      6        \u001B[36m0.4844\u001B[0m       0.7851        0.6928  0.2209\n",
      "      7        \u001B[36m0.4128\u001B[0m       0.7884        0.6947  0.2160\n",
      "      8        \u001B[36m0.3894\u001B[0m       0.7934        0.6859  0.2214\n",
      "      9        \u001B[36m0.3512\u001B[0m       0.7851        0.7164  0.2132\n",
      "     10        \u001B[36m0.3263\u001B[0m       0.7769        0.7799  0.2125\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.5156\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m0.8957\u001B[0m  0.2642\n",
      "      2        \u001B[36m0.8612\u001B[0m       \u001B[32m0.7190\u001B[0m        0.9444  0.2556\n",
      "      3        \u001B[36m0.7227\u001B[0m       \u001B[32m0.7653\u001B[0m        \u001B[35m0.7543\u001B[0m  0.2389\n",
      "      4        \u001B[36m0.5826\u001B[0m       \u001B[32m0.7802\u001B[0m        \u001B[35m0.7121\u001B[0m  0.2399\n",
      "      5        \u001B[36m0.5191\u001B[0m       \u001B[32m0.7901\u001B[0m        \u001B[35m0.7029\u001B[0m  0.2501\n",
      "      6        \u001B[36m0.4830\u001B[0m       0.7818        0.7258  0.2471\n",
      "      7        \u001B[36m0.3884\u001B[0m       0.7851        0.7127  0.2536\n",
      "      8        \u001B[36m0.3811\u001B[0m       0.7818        0.7318  0.2452\n",
      "      9        \u001B[36m0.3308\u001B[0m       \u001B[32m0.7917\u001B[0m        0.7177  0.2443\n",
      "     10        \u001B[36m0.3205\u001B[0m       \u001B[32m0.7934\u001B[0m        0.7316  0.2367\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.4342\u001B[0m       \u001B[32m0.7471\u001B[0m        \u001B[35m0.8499\u001B[0m  0.2384\n",
      "      2        \u001B[36m0.8345\u001B[0m       \u001B[32m0.7620\u001B[0m        \u001B[35m0.7066\u001B[0m  0.2443\n",
      "      3        \u001B[36m0.6217\u001B[0m       0.7620        \u001B[35m0.6502\u001B[0m  0.2423\n",
      "      4        \u001B[36m0.5662\u001B[0m       \u001B[32m0.8000\u001B[0m        0.6620  0.2455\n",
      "      5        \u001B[36m0.5208\u001B[0m       0.7818        0.6526  0.2392\n",
      "      6        \u001B[36m0.4422\u001B[0m       \u001B[32m0.8033\u001B[0m        \u001B[35m0.6385\u001B[0m  0.2408\n",
      "      7        \u001B[36m0.3681\u001B[0m       \u001B[32m0.8066\u001B[0m        \u001B[35m0.6292\u001B[0m  0.2469\n",
      "      8        \u001B[36m0.3353\u001B[0m       \u001B[32m0.8099\u001B[0m        0.6441  0.2451\n",
      "      9        0.3407       0.7950        0.6851  0.2402\n",
      "     10        \u001B[36m0.3008\u001B[0m       0.7868        0.6914  0.2438\n",
      "[CV] END batch_size=64, lr=0.001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3469\u001B[0m       \u001B[32m0.2645\u001B[0m        \u001B[35m1.7985\u001B[0m  0.2778\n",
      "      2        \u001B[36m1.9691\u001B[0m       \u001B[32m0.3669\u001B[0m        \u001B[35m1.6111\u001B[0m  0.2618\n",
      "      3        \u001B[36m1.7652\u001B[0m       \u001B[32m0.4446\u001B[0m        \u001B[35m1.4896\u001B[0m  0.2601\n",
      "      4        \u001B[36m1.6317\u001B[0m       \u001B[32m0.4909\u001B[0m        \u001B[35m1.4009\u001B[0m  0.2754\n",
      "      5        \u001B[36m1.5238\u001B[0m       \u001B[32m0.5306\u001B[0m        \u001B[35m1.3389\u001B[0m  0.2401\n",
      "      6        \u001B[36m1.4768\u001B[0m       \u001B[32m0.5438\u001B[0m        \u001B[35m1.2863\u001B[0m  0.2826\n",
      "      7        \u001B[36m1.4107\u001B[0m       \u001B[32m0.5653\u001B[0m        \u001B[35m1.2429\u001B[0m  0.2444\n",
      "      8        \u001B[36m1.3473\u001B[0m       \u001B[32m0.5835\u001B[0m        \u001B[35m1.2040\u001B[0m  0.2712\n",
      "      9        \u001B[36m1.2643\u001B[0m       \u001B[32m0.6000\u001B[0m        \u001B[35m1.1616\u001B[0m  0.2617\n",
      "     10        \u001B[36m1.2241\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.1335\u001B[0m  0.3016\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.8s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3560\u001B[0m       \u001B[32m0.2876\u001B[0m        \u001B[35m1.8398\u001B[0m  0.2983\n",
      "      2        \u001B[36m2.0323\u001B[0m       \u001B[32m0.4000\u001B[0m        \u001B[35m1.6704\u001B[0m  0.2873\n",
      "      3        \u001B[36m1.7967\u001B[0m       \u001B[32m0.4529\u001B[0m        \u001B[35m1.5254\u001B[0m  0.2466\n",
      "      4        \u001B[36m1.6637\u001B[0m       \u001B[32m0.4992\u001B[0m        \u001B[35m1.4243\u001B[0m  0.2325\n",
      "      5        \u001B[36m1.5138\u001B[0m       \u001B[32m0.5240\u001B[0m        \u001B[35m1.3502\u001B[0m  0.2322\n",
      "      6        \u001B[36m1.4600\u001B[0m       \u001B[32m0.5504\u001B[0m        \u001B[35m1.2960\u001B[0m  0.2434\n",
      "      7        \u001B[36m1.3853\u001B[0m       \u001B[32m0.5636\u001B[0m        \u001B[35m1.2545\u001B[0m  0.2392\n",
      "      8        \u001B[36m1.3428\u001B[0m       \u001B[32m0.5686\u001B[0m        \u001B[35m1.2173\u001B[0m  0.2417\n",
      "      9        \u001B[36m1.2938\u001B[0m       \u001B[32m0.5868\u001B[0m        \u001B[35m1.1895\u001B[0m  0.2395\n",
      "     10        \u001B[36m1.2270\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.1525\u001B[0m  0.2321\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.5606\u001B[0m       \u001B[32m0.1587\u001B[0m        \u001B[35m1.9552\u001B[0m  0.2432\n",
      "      2        \u001B[36m2.1570\u001B[0m       \u001B[32m0.2727\u001B[0m        \u001B[35m1.7627\u001B[0m  0.2402\n",
      "      3        \u001B[36m1.8525\u001B[0m       \u001B[32m0.3868\u001B[0m        \u001B[35m1.6043\u001B[0m  0.2388\n",
      "      4        \u001B[36m1.6974\u001B[0m       \u001B[32m0.4529\u001B[0m        \u001B[35m1.4967\u001B[0m  0.2330\n",
      "      5        \u001B[36m1.5700\u001B[0m       \u001B[32m0.4992\u001B[0m        \u001B[35m1.4178\u001B[0m  0.2329\n",
      "      6        \u001B[36m1.4690\u001B[0m       \u001B[32m0.5273\u001B[0m        \u001B[35m1.3596\u001B[0m  0.2510\n",
      "      7        \u001B[36m1.3980\u001B[0m       \u001B[32m0.5504\u001B[0m        \u001B[35m1.3077\u001B[0m  0.2418\n",
      "      8        \u001B[36m1.3648\u001B[0m       \u001B[32m0.5603\u001B[0m        \u001B[35m1.2681\u001B[0m  0.2458\n",
      "      9        \u001B[36m1.2943\u001B[0m       \u001B[32m0.5752\u001B[0m        \u001B[35m1.2261\u001B[0m  0.2453\n",
      "     10        \u001B[36m1.2629\u001B[0m       \u001B[32m0.5884\u001B[0m        \u001B[35m1.1884\u001B[0m  0.2340\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3446\u001B[0m       \u001B[32m0.2628\u001B[0m        \u001B[35m1.7973\u001B[0m  0.2261\n",
      "      2        \u001B[36m2.0043\u001B[0m       \u001B[32m0.4281\u001B[0m        \u001B[35m1.5695\u001B[0m  0.2410\n",
      "      3        \u001B[36m1.7138\u001B[0m       \u001B[32m0.4661\u001B[0m        \u001B[35m1.4552\u001B[0m  0.2325\n",
      "      4        \u001B[36m1.6035\u001B[0m       \u001B[32m0.5008\u001B[0m        \u001B[35m1.3696\u001B[0m  0.2377\n",
      "      5        \u001B[36m1.5165\u001B[0m       \u001B[32m0.5091\u001B[0m        \u001B[35m1.3122\u001B[0m  0.2327\n",
      "      6        \u001B[36m1.3932\u001B[0m       \u001B[32m0.5256\u001B[0m        \u001B[35m1.2582\u001B[0m  0.2246\n",
      "      7        \u001B[36m1.3596\u001B[0m       \u001B[32m0.5636\u001B[0m        \u001B[35m1.2163\u001B[0m  0.2284\n",
      "      8        \u001B[36m1.3288\u001B[0m       \u001B[32m0.5835\u001B[0m        \u001B[35m1.1811\u001B[0m  0.2377\n",
      "      9        \u001B[36m1.2450\u001B[0m       \u001B[32m0.5934\u001B[0m        \u001B[35m1.1514\u001B[0m  0.2345\n",
      "     10        \u001B[36m1.1922\u001B[0m       \u001B[32m0.6165\u001B[0m        \u001B[35m1.1231\u001B[0m  0.2430\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3753\u001B[0m       \u001B[32m0.2975\u001B[0m        \u001B[35m1.7741\u001B[0m  0.2269\n",
      "      2        \u001B[36m1.9524\u001B[0m       \u001B[32m0.4231\u001B[0m        \u001B[35m1.6006\u001B[0m  0.2300\n",
      "      3        \u001B[36m1.7514\u001B[0m       \u001B[32m0.4711\u001B[0m        \u001B[35m1.4844\u001B[0m  0.2335\n",
      "      4        \u001B[36m1.5911\u001B[0m       \u001B[32m0.5306\u001B[0m        \u001B[35m1.3920\u001B[0m  0.2374\n",
      "      5        \u001B[36m1.5282\u001B[0m       \u001B[32m0.5603\u001B[0m        \u001B[35m1.3182\u001B[0m  0.2344\n",
      "      6        \u001B[36m1.4278\u001B[0m       \u001B[32m0.5917\u001B[0m        \u001B[35m1.2629\u001B[0m  0.2248\n",
      "      7        \u001B[36m1.3218\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.2178\u001B[0m  0.2361\n",
      "      8        \u001B[36m1.2920\u001B[0m       \u001B[32m0.6215\u001B[0m        \u001B[35m1.1746\u001B[0m  0.2239\n",
      "      9        \u001B[36m1.2282\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.1360\u001B[0m  0.2235\n",
      "     10        \u001B[36m1.1996\u001B[0m       0.6331        \u001B[35m1.1069\u001B[0m  0.2249\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.6369\u001B[0m       \u001B[32m0.2430\u001B[0m        \u001B[35m1.9521\u001B[0m  0.2198\n",
      "      2        \u001B[36m2.0491\u001B[0m       \u001B[32m0.3504\u001B[0m        \u001B[35m1.7322\u001B[0m  0.2333\n",
      "      3        \u001B[36m1.8863\u001B[0m       \u001B[32m0.4298\u001B[0m        \u001B[35m1.5641\u001B[0m  0.2271\n",
      "      4        \u001B[36m1.6595\u001B[0m       \u001B[32m0.4876\u001B[0m        \u001B[35m1.4566\u001B[0m  0.2264\n",
      "      5        \u001B[36m1.5649\u001B[0m       \u001B[32m0.5107\u001B[0m        \u001B[35m1.3875\u001B[0m  0.2305\n",
      "      6        \u001B[36m1.4865\u001B[0m       \u001B[32m0.5455\u001B[0m        \u001B[35m1.3287\u001B[0m  0.2266\n",
      "      7        \u001B[36m1.3987\u001B[0m       \u001B[32m0.5653\u001B[0m        \u001B[35m1.2764\u001B[0m  0.2302\n",
      "      8        \u001B[36m1.3527\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.2359\u001B[0m  0.2239\n",
      "      9        \u001B[36m1.3008\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.1964\u001B[0m  0.2397\n",
      "     10        \u001B[36m1.2387\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.1662\u001B[0m  0.2477\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0820\u001B[0m       \u001B[32m0.4512\u001B[0m        \u001B[35m1.4239\u001B[0m  0.2278\n",
      "      2        \u001B[36m1.7472\u001B[0m       \u001B[32m0.5207\u001B[0m        \u001B[35m1.2880\u001B[0m  0.2273\n",
      "      3        \u001B[36m1.5582\u001B[0m       \u001B[32m0.5736\u001B[0m        \u001B[35m1.2095\u001B[0m  0.2311\n",
      "      4        \u001B[36m1.4782\u001B[0m       \u001B[32m0.5950\u001B[0m        \u001B[35m1.1481\u001B[0m  0.2307\n",
      "      5        \u001B[36m1.3772\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.1042\u001B[0m  0.2328\n",
      "      6        \u001B[36m1.2930\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0584\u001B[0m  0.2335\n",
      "      7        \u001B[36m1.2231\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m1.0218\u001B[0m  0.2302\n",
      "      8        \u001B[36m1.1780\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m1.0051\u001B[0m  0.2224\n",
      "      9        \u001B[36m1.1311\u001B[0m       0.7074        \u001B[35m0.9624\u001B[0m  0.2297\n",
      "     10        \u001B[36m1.0900\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.9414\u001B[0m  0.2334\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4018\u001B[0m       \u001B[32m0.3504\u001B[0m        \u001B[35m1.7022\u001B[0m  0.2392\n",
      "      2        \u001B[36m1.9488\u001B[0m       \u001B[32m0.4182\u001B[0m        \u001B[35m1.5250\u001B[0m  0.2304\n",
      "      3        \u001B[36m1.7170\u001B[0m       \u001B[32m0.4777\u001B[0m        \u001B[35m1.4218\u001B[0m  0.2273\n",
      "      4        \u001B[36m1.6004\u001B[0m       \u001B[32m0.5306\u001B[0m        \u001B[35m1.3247\u001B[0m  0.2224\n",
      "      5        \u001B[36m1.4848\u001B[0m       \u001B[32m0.5868\u001B[0m        \u001B[35m1.2595\u001B[0m  0.2408\n",
      "      6        \u001B[36m1.4100\u001B[0m       \u001B[32m0.6099\u001B[0m        \u001B[35m1.2019\u001B[0m  0.2375\n",
      "      7        \u001B[36m1.3117\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.1511\u001B[0m  0.2333\n",
      "      8        \u001B[36m1.2690\u001B[0m       \u001B[32m0.6397\u001B[0m        \u001B[35m1.1195\u001B[0m  0.2257\n",
      "      9        \u001B[36m1.2228\u001B[0m       \u001B[32m0.6545\u001B[0m        \u001B[35m1.0806\u001B[0m  0.2253\n",
      "     10        \u001B[36m1.1763\u001B[0m       0.6529        \u001B[35m1.0536\u001B[0m  0.2389\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3196\u001B[0m       \u001B[32m0.3653\u001B[0m        \u001B[35m1.6763\u001B[0m  0.2392\n",
      "      2        \u001B[36m1.8682\u001B[0m       \u001B[32m0.4446\u001B[0m        \u001B[35m1.5056\u001B[0m  0.2321\n",
      "      3        \u001B[36m1.6496\u001B[0m       \u001B[32m0.4893\u001B[0m        \u001B[35m1.3981\u001B[0m  0.2359\n",
      "      4        \u001B[36m1.5728\u001B[0m       \u001B[32m0.5256\u001B[0m        \u001B[35m1.3069\u001B[0m  0.2235\n",
      "      5        \u001B[36m1.4730\u001B[0m       \u001B[32m0.5504\u001B[0m        \u001B[35m1.2505\u001B[0m  0.2290\n",
      "      6        \u001B[36m1.3509\u001B[0m       \u001B[32m0.5752\u001B[0m        \u001B[35m1.1965\u001B[0m  0.2292\n",
      "      7        \u001B[36m1.2864\u001B[0m       \u001B[32m0.6099\u001B[0m        \u001B[35m1.1562\u001B[0m  0.2470\n",
      "      8        \u001B[36m1.2090\u001B[0m       \u001B[32m0.6116\u001B[0m        \u001B[35m1.1159\u001B[0m  0.2463\n",
      "      9        \u001B[36m1.1819\u001B[0m       \u001B[32m0.6215\u001B[0m        \u001B[35m1.0781\u001B[0m  0.2292\n",
      "     10        \u001B[36m1.1265\u001B[0m       \u001B[32m0.6347\u001B[0m        \u001B[35m1.0506\u001B[0m  0.2311\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1140\u001B[0m       \u001B[32m0.3603\u001B[0m        \u001B[35m1.6776\u001B[0m  0.2362\n",
      "      2        \u001B[36m1.7195\u001B[0m       \u001B[32m0.4579\u001B[0m        \u001B[35m1.4846\u001B[0m  0.2367\n",
      "      3        \u001B[36m1.5136\u001B[0m       \u001B[32m0.5107\u001B[0m        \u001B[35m1.3585\u001B[0m  0.2442\n",
      "      4        \u001B[36m1.4049\u001B[0m       \u001B[32m0.5438\u001B[0m        \u001B[35m1.2723\u001B[0m  0.2444\n",
      "      5        \u001B[36m1.3256\u001B[0m       \u001B[32m0.5802\u001B[0m        \u001B[35m1.2092\u001B[0m  0.2273\n",
      "      6        \u001B[36m1.2315\u001B[0m       \u001B[32m0.5950\u001B[0m        \u001B[35m1.1567\u001B[0m  0.2346\n",
      "      7        \u001B[36m1.1622\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1075\u001B[0m  0.2356\n",
      "      8        \u001B[36m1.1029\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.0673\u001B[0m  0.2388\n",
      "      9        \u001B[36m1.0556\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.0329\u001B[0m  0.2321\n",
      "     10        \u001B[36m0.9975\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m1.0042\u001B[0m  0.2350\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9514\u001B[0m       \u001B[32m0.3785\u001B[0m        \u001B[35m1.6845\u001B[0m  0.2422\n",
      "      2        \u001B[36m1.6493\u001B[0m       \u001B[32m0.4612\u001B[0m        \u001B[35m1.5458\u001B[0m  0.2407\n",
      "      3        \u001B[36m1.5160\u001B[0m       \u001B[32m0.5140\u001B[0m        \u001B[35m1.4283\u001B[0m  0.2387\n",
      "      4        \u001B[36m1.3767\u001B[0m       \u001B[32m0.5570\u001B[0m        \u001B[35m1.3463\u001B[0m  0.2449\n",
      "      5        \u001B[36m1.2768\u001B[0m       \u001B[32m0.5785\u001B[0m        \u001B[35m1.2806\u001B[0m  0.2274\n",
      "      6        \u001B[36m1.2015\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.2274\u001B[0m  0.2334\n",
      "      7        \u001B[36m1.1408\u001B[0m       \u001B[32m0.6165\u001B[0m        \u001B[35m1.1856\u001B[0m  0.2374\n",
      "      8        \u001B[36m1.0863\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1444\u001B[0m  0.2418\n",
      "      9        \u001B[36m1.0447\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.1038\u001B[0m  0.2280\n",
      "     10        \u001B[36m0.9830\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0734\u001B[0m  0.2325\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2253\u001B[0m       \u001B[32m0.3570\u001B[0m        \u001B[35m1.6821\u001B[0m  0.2455\n",
      "      2        \u001B[36m1.8071\u001B[0m       \u001B[32m0.4826\u001B[0m        \u001B[35m1.4780\u001B[0m  0.2432\n",
      "      3        \u001B[36m1.5975\u001B[0m       \u001B[32m0.5554\u001B[0m        \u001B[35m1.3592\u001B[0m  0.2427\n",
      "      4        \u001B[36m1.4299\u001B[0m       \u001B[32m0.5884\u001B[0m        \u001B[35m1.2757\u001B[0m  0.2374\n",
      "      5        \u001B[36m1.3096\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.2069\u001B[0m  0.2278\n",
      "      6        \u001B[36m1.2440\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1524\u001B[0m  0.2300\n",
      "      7        \u001B[36m1.1631\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.1146\u001B[0m  0.2419\n",
      "      8        \u001B[36m1.0912\u001B[0m       \u001B[32m0.6661\u001B[0m        \u001B[35m1.0834\u001B[0m  0.2362\n",
      "      9        \u001B[36m1.0335\u001B[0m       \u001B[32m0.6777\u001B[0m        \u001B[35m1.0461\u001B[0m  0.2502\n",
      "     10        \u001B[36m1.0081\u001B[0m       0.6760        \u001B[35m1.0209\u001B[0m  0.2330\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2091\u001B[0m       \u001B[32m0.3818\u001B[0m        \u001B[35m1.5871\u001B[0m  0.2305\n",
      "      2        \u001B[36m1.7350\u001B[0m       \u001B[32m0.4876\u001B[0m        \u001B[35m1.3892\u001B[0m  0.2306\n",
      "      3        \u001B[36m1.5491\u001B[0m       \u001B[32m0.5405\u001B[0m        \u001B[35m1.2770\u001B[0m  0.2369\n",
      "      4        \u001B[36m1.4113\u001B[0m       \u001B[32m0.5802\u001B[0m        \u001B[35m1.1909\u001B[0m  0.2399\n",
      "      5        \u001B[36m1.3216\u001B[0m       \u001B[32m0.6132\u001B[0m        \u001B[35m1.1357\u001B[0m  0.2339\n",
      "      6        \u001B[36m1.2341\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.0825\u001B[0m  0.2280\n",
      "      7        \u001B[36m1.1530\u001B[0m       \u001B[32m0.6562\u001B[0m        \u001B[35m1.0430\u001B[0m  0.2289\n",
      "      8        \u001B[36m1.0886\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0033\u001B[0m  0.2359\n",
      "      9        \u001B[36m1.0443\u001B[0m       \u001B[32m0.6777\u001B[0m        \u001B[35m0.9708\u001B[0m  0.2309\n",
      "     10        \u001B[36m0.9975\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m0.9403\u001B[0m  0.2270\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1558\u001B[0m       \u001B[32m0.3983\u001B[0m        \u001B[35m1.6784\u001B[0m  0.2322\n",
      "      2        \u001B[36m1.6959\u001B[0m       \u001B[32m0.4826\u001B[0m        \u001B[35m1.4811\u001B[0m  0.2400\n",
      "      3        \u001B[36m1.5609\u001B[0m       \u001B[32m0.5256\u001B[0m        \u001B[35m1.3597\u001B[0m  0.2428\n",
      "      4        \u001B[36m1.4042\u001B[0m       \u001B[32m0.5719\u001B[0m        \u001B[35m1.2793\u001B[0m  0.2329\n",
      "      5        \u001B[36m1.2915\u001B[0m       \u001B[32m0.6066\u001B[0m        \u001B[35m1.2142\u001B[0m  0.2279\n",
      "      6        \u001B[36m1.1952\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.1714\u001B[0m  0.2239\n",
      "      7        \u001B[36m1.1319\u001B[0m       \u001B[32m0.6512\u001B[0m        \u001B[35m1.1130\u001B[0m  0.2429\n",
      "      8        \u001B[36m1.0827\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0734\u001B[0m  0.2356\n",
      "      9        \u001B[36m1.0241\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m1.0336\u001B[0m  0.2408\n",
      "     10        \u001B[36m0.9899\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m1.0080\u001B[0m  0.2330\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0403\u001B[0m       \u001B[32m0.3917\u001B[0m        \u001B[35m1.5732\u001B[0m  0.2293\n",
      "      2        \u001B[36m1.6791\u001B[0m       \u001B[32m0.4628\u001B[0m        \u001B[35m1.4123\u001B[0m  0.2383\n",
      "      3        \u001B[36m1.4878\u001B[0m       \u001B[32m0.5273\u001B[0m        \u001B[35m1.3009\u001B[0m  0.2270\n",
      "      4        \u001B[36m1.3761\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.2111\u001B[0m  0.2413\n",
      "      5        \u001B[36m1.2370\u001B[0m       \u001B[32m0.6264\u001B[0m        \u001B[35m1.1493\u001B[0m  0.2319\n",
      "      6        \u001B[36m1.1493\u001B[0m       \u001B[32m0.6364\u001B[0m        \u001B[35m1.0990\u001B[0m  0.2305\n",
      "      7        \u001B[36m1.0600\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.0698\u001B[0m  0.2260\n",
      "      8        \u001B[36m1.0474\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0230\u001B[0m  0.2375\n",
      "      9        \u001B[36m1.0007\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m0.9825\u001B[0m  0.2345\n",
      "     10        \u001B[36m0.9462\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m0.9564\u001B[0m  0.2295\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2743\u001B[0m       \u001B[32m0.4198\u001B[0m        \u001B[35m1.4731\u001B[0m  0.2210\n",
      "      2        \u001B[36m1.7118\u001B[0m       \u001B[32m0.4860\u001B[0m        \u001B[35m1.3121\u001B[0m  0.2291\n",
      "      3        \u001B[36m1.5141\u001B[0m       \u001B[32m0.5537\u001B[0m        \u001B[35m1.2163\u001B[0m  0.2338\n",
      "      4        \u001B[36m1.3632\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.1479\u001B[0m  0.2307\n",
      "      5        \u001B[36m1.2506\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.0954\u001B[0m  0.2334\n",
      "      6        \u001B[36m1.2009\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.0583\u001B[0m  0.2172\n",
      "      7        \u001B[36m1.1080\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m1.0194\u001B[0m  0.2237\n",
      "      8        \u001B[36m1.0635\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m0.9873\u001B[0m  0.2232\n",
      "      9        \u001B[36m0.9803\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m0.9656\u001B[0m  0.2288\n",
      "     10        \u001B[36m0.9633\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9360\u001B[0m  0.2351\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1376\u001B[0m       \u001B[32m0.4463\u001B[0m        \u001B[35m1.5901\u001B[0m  0.2262\n",
      "      2        \u001B[36m1.6923\u001B[0m       \u001B[32m0.5124\u001B[0m        \u001B[35m1.4240\u001B[0m  0.2241\n",
      "      3        \u001B[36m1.5115\u001B[0m       \u001B[32m0.5736\u001B[0m        \u001B[35m1.3045\u001B[0m  0.2251\n",
      "      4        \u001B[36m1.3606\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.2002\u001B[0m  0.2269\n",
      "      5        \u001B[36m1.2496\u001B[0m       \u001B[32m0.6446\u001B[0m        \u001B[35m1.1415\u001B[0m  0.2326\n",
      "      6        \u001B[36m1.1710\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.1119\u001B[0m  0.2181\n",
      "      7        \u001B[36m1.0990\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m1.0568\u001B[0m  0.2248\n",
      "      8        \u001B[36m1.0284\u001B[0m       \u001B[32m0.6959\u001B[0m        \u001B[35m1.0297\u001B[0m  0.2322\n",
      "      9        \u001B[36m1.0073\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9690\u001B[0m  0.2351\n",
      "     10        \u001B[36m0.9391\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9345\u001B[0m  0.2294\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0803\u001B[0m       \u001B[32m0.4545\u001B[0m        \u001B[35m1.5101\u001B[0m  0.2386\n",
      "      2        \u001B[36m1.5720\u001B[0m       \u001B[32m0.5537\u001B[0m        \u001B[35m1.3129\u001B[0m  0.2220\n",
      "      3        \u001B[36m1.3975\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.1999\u001B[0m  0.2226\n",
      "      4        \u001B[36m1.2644\u001B[0m       \u001B[32m0.6446\u001B[0m        \u001B[35m1.1271\u001B[0m  0.2273\n",
      "      5        \u001B[36m1.1448\u001B[0m       \u001B[32m0.6727\u001B[0m        \u001B[35m1.0648\u001B[0m  0.2281\n",
      "      6        \u001B[36m1.0934\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m1.0252\u001B[0m  0.2263\n",
      "      7        \u001B[36m1.0349\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m0.9844\u001B[0m  0.2223\n",
      "      8        \u001B[36m0.9590\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9592\u001B[0m  0.2234\n",
      "      9        \u001B[36m0.9341\u001B[0m       0.7207        \u001B[35m0.9301\u001B[0m  0.2338\n",
      "     10        \u001B[36m0.8857\u001B[0m       0.7190        \u001B[35m0.9025\u001B[0m  0.2317\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0326\u001B[0m       \u001B[32m0.4595\u001B[0m        \u001B[35m1.5326\u001B[0m  0.2264\n",
      "      2        \u001B[36m1.5168\u001B[0m       \u001B[32m0.5256\u001B[0m        \u001B[35m1.3043\u001B[0m  0.2283\n",
      "      3        \u001B[36m1.2830\u001B[0m       \u001B[32m0.6000\u001B[0m        \u001B[35m1.1940\u001B[0m  0.2272\n",
      "      4        \u001B[36m1.1841\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.1107\u001B[0m  0.2427\n",
      "      5        \u001B[36m1.0812\u001B[0m       \u001B[32m0.6678\u001B[0m        \u001B[35m1.0521\u001B[0m  0.2289\n",
      "      6        \u001B[36m0.9905\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m1.0002\u001B[0m  0.2344\n",
      "      7        \u001B[36m0.9337\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.9582\u001B[0m  0.2316\n",
      "      8        \u001B[36m0.8561\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.9236\u001B[0m  0.2240\n",
      "      9        \u001B[36m0.8098\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.8952\u001B[0m  0.2297\n",
      "     10        \u001B[36m0.7797\u001B[0m       \u001B[32m0.7537\u001B[0m        \u001B[35m0.8673\u001B[0m  0.2317\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8925\u001B[0m       \u001B[32m0.4711\u001B[0m        \u001B[35m1.5045\u001B[0m  0.2299\n",
      "      2        \u001B[36m1.5202\u001B[0m       \u001B[32m0.5471\u001B[0m        \u001B[35m1.3164\u001B[0m  0.2430\n",
      "      3        \u001B[36m1.2746\u001B[0m       \u001B[32m0.6066\u001B[0m        \u001B[35m1.2031\u001B[0m  0.2232\n",
      "      4        \u001B[36m1.1885\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.1181\u001B[0m  0.2210\n",
      "      5        \u001B[36m1.0565\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0517\u001B[0m  0.2256\n",
      "      6        \u001B[36m0.9525\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m1.0012\u001B[0m  0.2294\n",
      "      7        \u001B[36m0.9102\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m0.9674\u001B[0m  0.2386\n",
      "      8        \u001B[36m0.8568\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.9407\u001B[0m  0.2315\n",
      "      9        \u001B[36m0.8004\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.9169\u001B[0m  0.2252\n",
      "     10        \u001B[36m0.7692\u001B[0m       \u001B[32m0.7388\u001B[0m        \u001B[35m0.8937\u001B[0m  0.2190\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0472\u001B[0m       \u001B[32m0.4876\u001B[0m        \u001B[35m1.5520\u001B[0m  0.2305\n",
      "      2        \u001B[36m1.4651\u001B[0m       \u001B[32m0.5769\u001B[0m        \u001B[35m1.2856\u001B[0m  0.2296\n",
      "      3        \u001B[36m1.2922\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.1727\u001B[0m  0.2246\n",
      "      4        \u001B[36m1.1618\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.1052\u001B[0m  0.2218\n",
      "      5        \u001B[36m1.0541\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m1.0492\u001B[0m  0.2226\n",
      "      6        \u001B[36m0.9688\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m0.9941\u001B[0m  0.2396\n",
      "      7        \u001B[36m0.9087\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.9558\u001B[0m  0.2312\n",
      "      8        \u001B[36m0.8707\u001B[0m       \u001B[32m0.7372\u001B[0m        \u001B[35m0.9230\u001B[0m  0.2395\n",
      "      9        \u001B[36m0.7944\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.8928\u001B[0m  0.2314\n",
      "     10        \u001B[36m0.7523\u001B[0m       0.7421        \u001B[35m0.8724\u001B[0m  0.2215\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8405\u001B[0m       \u001B[32m0.4678\u001B[0m        \u001B[35m1.4580\u001B[0m  0.2252\n",
      "      2        \u001B[36m1.4247\u001B[0m       \u001B[32m0.5802\u001B[0m        \u001B[35m1.2618\u001B[0m  0.2327\n",
      "      3        \u001B[36m1.2539\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.1445\u001B[0m  0.2343\n",
      "      4        \u001B[36m1.1114\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0645\u001B[0m  0.2249\n",
      "      5        \u001B[36m1.0372\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m1.0055\u001B[0m  0.2216\n",
      "      6        \u001B[36m0.9569\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9502\u001B[0m  0.2295\n",
      "      7        \u001B[36m0.8686\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.9110\u001B[0m  0.2439\n",
      "      8        \u001B[36m0.8262\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8746\u001B[0m  0.2287\n",
      "      9        \u001B[36m0.7693\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8546\u001B[0m  0.2273\n",
      "     10        \u001B[36m0.7375\u001B[0m       \u001B[32m0.7669\u001B[0m        \u001B[35m0.8317\u001B[0m  0.2259\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8932\u001B[0m       \u001B[32m0.5074\u001B[0m        \u001B[35m1.4600\u001B[0m  0.2317\n",
      "      2        \u001B[36m1.4450\u001B[0m       \u001B[32m0.6017\u001B[0m        \u001B[35m1.2715\u001B[0m  0.2358\n",
      "      3        \u001B[36m1.2564\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.1596\u001B[0m  0.2315\n",
      "      4        \u001B[36m1.1111\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.0841\u001B[0m  0.2436\n",
      "      5        \u001B[36m1.0263\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m1.0234\u001B[0m  0.2335\n",
      "      6        \u001B[36m0.9577\u001B[0m       \u001B[32m0.6975\u001B[0m        \u001B[35m0.9762\u001B[0m  0.2216\n",
      "      7        \u001B[36m0.8803\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.9342\u001B[0m  0.2313\n",
      "      8        \u001B[36m0.8428\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.9081\u001B[0m  0.2273\n",
      "      9        \u001B[36m0.7923\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.8825\u001B[0m  0.2328\n",
      "     10        \u001B[36m0.7598\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.8594\u001B[0m  0.2254\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9321\u001B[0m       \u001B[32m0.4876\u001B[0m        \u001B[35m1.4299\u001B[0m  0.2269\n",
      "      2        \u001B[36m1.4651\u001B[0m       \u001B[32m0.5521\u001B[0m        \u001B[35m1.2393\u001B[0m  0.2275\n",
      "      3        \u001B[36m1.2652\u001B[0m       \u001B[32m0.6066\u001B[0m        \u001B[35m1.1319\u001B[0m  0.2415\n",
      "      4        \u001B[36m1.1394\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.0480\u001B[0m  0.2348\n",
      "      5        \u001B[36m1.0292\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m0.9947\u001B[0m  0.2385\n",
      "      6        \u001B[36m0.9253\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9425\u001B[0m  0.2322\n",
      "      7        \u001B[36m0.8793\u001B[0m       \u001B[32m0.7240\u001B[0m        \u001B[35m0.9006\u001B[0m  0.2216\n",
      "      8        \u001B[36m0.8458\u001B[0m       0.7223        \u001B[35m0.8728\u001B[0m  0.2213\n",
      "      9        \u001B[36m0.7811\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.8467\u001B[0m  0.2293\n",
      "     10        \u001B[36m0.7318\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8275\u001B[0m  0.2337\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9968\u001B[0m       \u001B[32m0.4678\u001B[0m        \u001B[35m1.4058\u001B[0m  0.2430\n",
      "      2        \u001B[36m1.4899\u001B[0m       \u001B[32m0.5669\u001B[0m        \u001B[35m1.2011\u001B[0m  0.2273\n",
      "      3        \u001B[36m1.2881\u001B[0m       \u001B[32m0.6182\u001B[0m        \u001B[35m1.0837\u001B[0m  0.2238\n",
      "      4        \u001B[36m1.1134\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m0.9994\u001B[0m  0.2329\n",
      "      5        \u001B[36m1.0147\u001B[0m       \u001B[32m0.6826\u001B[0m        \u001B[35m0.9472\u001B[0m  0.2550\n",
      "      6        \u001B[36m0.9203\u001B[0m       \u001B[32m0.7041\u001B[0m        \u001B[35m0.8932\u001B[0m  0.2528\n",
      "      7        \u001B[36m0.8575\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8556\u001B[0m  0.2441\n",
      "      8        \u001B[36m0.8369\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8255\u001B[0m  0.2454\n",
      "      9        \u001B[36m0.7493\u001B[0m       \u001B[32m0.7686\u001B[0m        \u001B[35m0.7895\u001B[0m  0.2434\n",
      "     10        \u001B[36m0.7246\u001B[0m       \u001B[32m0.7851\u001B[0m        \u001B[35m0.7699\u001B[0m  0.2370\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.8192\u001B[0m       \u001B[32m0.4909\u001B[0m        \u001B[35m1.3488\u001B[0m  0.2388\n",
      "      2        \u001B[36m1.4023\u001B[0m       \u001B[32m0.6066\u001B[0m        \u001B[35m1.1653\u001B[0m  0.2358\n",
      "      3        \u001B[36m1.1872\u001B[0m       \u001B[32m0.6545\u001B[0m        \u001B[35m1.0635\u001B[0m  0.2260\n",
      "      4        \u001B[36m1.0795\u001B[0m       \u001B[32m0.6793\u001B[0m        \u001B[35m0.9859\u001B[0m  0.2285\n",
      "      5        \u001B[36m0.9698\u001B[0m       \u001B[32m0.7025\u001B[0m        \u001B[35m0.9303\u001B[0m  0.2362\n",
      "      6        \u001B[36m0.9282\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m0.8861\u001B[0m  0.2337\n",
      "      7        \u001B[36m0.8521\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.8598\u001B[0m  0.2237\n",
      "      8        \u001B[36m0.8194\u001B[0m       \u001B[32m0.7256\u001B[0m        \u001B[35m0.8355\u001B[0m  0.2296\n",
      "      9        \u001B[36m0.7420\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.8169\u001B[0m  0.2265\n",
      "     10        \u001B[36m0.6885\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.7979\u001B[0m  0.2419\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9857\u001B[0m       \u001B[32m0.4826\u001B[0m        \u001B[35m1.4133\u001B[0m  0.2386\n",
      "      2        \u001B[36m1.4325\u001B[0m       \u001B[32m0.5818\u001B[0m        \u001B[35m1.2587\u001B[0m  0.2300\n",
      "      3        \u001B[36m1.2549\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.1484\u001B[0m  0.2264\n",
      "      4        \u001B[36m1.0879\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m1.0632\u001B[0m  0.2226\n",
      "      5        \u001B[36m0.9985\u001B[0m       \u001B[32m0.7157\u001B[0m        \u001B[35m1.0136\u001B[0m  0.2443\n",
      "      6        \u001B[36m0.9408\u001B[0m       \u001B[32m0.7339\u001B[0m        \u001B[35m0.9568\u001B[0m  0.2371\n",
      "      7        \u001B[36m0.8494\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.9156\u001B[0m  0.2266\n",
      "      8        \u001B[36m0.7815\u001B[0m       \u001B[32m0.7636\u001B[0m        \u001B[35m0.8872\u001B[0m  0.2280\n",
      "      9        \u001B[36m0.7393\u001B[0m       \u001B[32m0.7702\u001B[0m        \u001B[35m0.8574\u001B[0m  0.2256\n",
      "     10        \u001B[36m0.7036\u001B[0m       \u001B[32m0.7719\u001B[0m        \u001B[35m0.8390\u001B[0m  0.2389\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.4, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.6354\u001B[0m       \u001B[32m0.1835\u001B[0m        \u001B[35m2.0327\u001B[0m  0.2459\n",
      "      2        \u001B[36m2.2399\u001B[0m       \u001B[32m0.2744\u001B[0m        \u001B[35m1.8377\u001B[0m  0.2396\n",
      "      3        \u001B[36m2.0024\u001B[0m       \u001B[32m0.3438\u001B[0m        \u001B[35m1.6632\u001B[0m  0.2337\n",
      "      4        \u001B[36m1.8235\u001B[0m       \u001B[32m0.4165\u001B[0m        \u001B[35m1.5489\u001B[0m  0.2291\n",
      "      5        \u001B[36m1.7381\u001B[0m       \u001B[32m0.4512\u001B[0m        \u001B[35m1.4602\u001B[0m  0.2508\n",
      "      6        \u001B[36m1.6386\u001B[0m       \u001B[32m0.4777\u001B[0m        \u001B[35m1.3966\u001B[0m  0.2479\n",
      "      7        \u001B[36m1.5470\u001B[0m       \u001B[32m0.5008\u001B[0m        \u001B[35m1.3445\u001B[0m  0.2381\n",
      "      8        \u001B[36m1.5175\u001B[0m       \u001B[32m0.5207\u001B[0m        \u001B[35m1.2974\u001B[0m  0.2313\n",
      "      9        \u001B[36m1.4283\u001B[0m       \u001B[32m0.5355\u001B[0m        \u001B[35m1.2593\u001B[0m  0.2365\n",
      "     10        \u001B[36m1.4110\u001B[0m       \u001B[32m0.5570\u001B[0m        \u001B[35m1.2262\u001B[0m  0.2490\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.5686\u001B[0m       \u001B[32m0.2182\u001B[0m        \u001B[35m1.9472\u001B[0m  0.2422\n",
      "      2        \u001B[36m2.2279\u001B[0m       \u001B[32m0.2893\u001B[0m        \u001B[35m1.8168\u001B[0m  0.2484\n",
      "      3        \u001B[36m2.0599\u001B[0m       \u001B[32m0.3554\u001B[0m        \u001B[35m1.6858\u001B[0m  0.2398\n",
      "      4        \u001B[36m1.9034\u001B[0m       \u001B[32m0.4099\u001B[0m        \u001B[35m1.5869\u001B[0m  0.2343\n",
      "      5        \u001B[36m1.7427\u001B[0m       \u001B[32m0.4430\u001B[0m        \u001B[35m1.5123\u001B[0m  0.2359\n",
      "      6        \u001B[36m1.6321\u001B[0m       \u001B[32m0.4793\u001B[0m        \u001B[35m1.4487\u001B[0m  0.2385\n",
      "      7        \u001B[36m1.5940\u001B[0m       \u001B[32m0.5041\u001B[0m        \u001B[35m1.3976\u001B[0m  0.2376\n",
      "      8        \u001B[36m1.5340\u001B[0m       \u001B[32m0.5405\u001B[0m        \u001B[35m1.3597\u001B[0m  0.2328\n",
      "      9        \u001B[36m1.4988\u001B[0m       \u001B[32m0.5603\u001B[0m        \u001B[35m1.3194\u001B[0m  0.2354\n",
      "     10        \u001B[36m1.4100\u001B[0m       \u001B[32m0.5686\u001B[0m        \u001B[35m1.2916\u001B[0m  0.2438\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1599\u001B[0m       \u001B[32m0.3620\u001B[0m        \u001B[35m1.6787\u001B[0m  0.2442\n",
      "      2        \u001B[36m1.9212\u001B[0m       \u001B[32m0.4149\u001B[0m        \u001B[35m1.5734\u001B[0m  0.2408\n",
      "      3        \u001B[36m1.7920\u001B[0m       \u001B[32m0.4512\u001B[0m        \u001B[35m1.4907\u001B[0m  0.2670\n",
      "      4        \u001B[36m1.6330\u001B[0m       \u001B[32m0.4628\u001B[0m        \u001B[35m1.4256\u001B[0m  0.2549\n",
      "      5        \u001B[36m1.6042\u001B[0m       \u001B[32m0.4975\u001B[0m        \u001B[35m1.3706\u001B[0m  0.2745\n",
      "      6        \u001B[36m1.5411\u001B[0m       \u001B[32m0.5273\u001B[0m        \u001B[35m1.3204\u001B[0m  0.2562\n",
      "      7        \u001B[36m1.4826\u001B[0m       \u001B[32m0.5471\u001B[0m        \u001B[35m1.2801\u001B[0m  0.2575\n",
      "      8        \u001B[36m1.3997\u001B[0m       \u001B[32m0.5769\u001B[0m        \u001B[35m1.2545\u001B[0m  0.2493\n",
      "      9        \u001B[36m1.3279\u001B[0m       \u001B[32m0.5835\u001B[0m        \u001B[35m1.2227\u001B[0m  0.2553\n",
      "     10        \u001B[36m1.3041\u001B[0m       \u001B[32m0.5934\u001B[0m        \u001B[35m1.1917\u001B[0m  0.2506\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=64; total time=   2.6s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.5304\u001B[0m       \u001B[32m0.2198\u001B[0m        \u001B[35m1.7934\u001B[0m  0.2481\n",
      "      2        \u001B[36m2.0916\u001B[0m       \u001B[32m0.3537\u001B[0m        \u001B[35m1.6164\u001B[0m  0.2331\n",
      "      3        \u001B[36m1.9012\u001B[0m       \u001B[32m0.4298\u001B[0m        \u001B[35m1.4977\u001B[0m  0.2439\n",
      "      4        \u001B[36m1.7740\u001B[0m       \u001B[32m0.4595\u001B[0m        \u001B[35m1.4257\u001B[0m  0.2437\n",
      "      5        \u001B[36m1.7195\u001B[0m       \u001B[32m0.4777\u001B[0m        \u001B[35m1.3628\u001B[0m  0.2447\n",
      "      6        \u001B[36m1.6146\u001B[0m       \u001B[32m0.5140\u001B[0m        \u001B[35m1.3085\u001B[0m  0.2512\n",
      "      7        \u001B[36m1.5286\u001B[0m       \u001B[32m0.5504\u001B[0m        \u001B[35m1.2622\u001B[0m  0.2506\n",
      "      8        \u001B[36m1.4795\u001B[0m       \u001B[32m0.5686\u001B[0m        \u001B[35m1.2283\u001B[0m  0.2376\n",
      "      9        \u001B[36m1.3918\u001B[0m       \u001B[32m0.5785\u001B[0m        \u001B[35m1.1917\u001B[0m  0.2349\n",
      "     10        1.4058       \u001B[32m0.6000\u001B[0m        \u001B[35m1.1654\u001B[0m  0.2414\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.6526\u001B[0m       \u001B[32m0.2579\u001B[0m        \u001B[35m1.8772\u001B[0m  0.2386\n",
      "      2        \u001B[36m2.2360\u001B[0m       \u001B[32m0.3488\u001B[0m        \u001B[35m1.6717\u001B[0m  0.2434\n",
      "      3        \u001B[36m1.8682\u001B[0m       \u001B[32m0.4314\u001B[0m        \u001B[35m1.5547\u001B[0m  0.2265\n",
      "      4        \u001B[36m1.7631\u001B[0m       \u001B[32m0.4760\u001B[0m        \u001B[35m1.4711\u001B[0m  0.2327\n",
      "      5        \u001B[36m1.6740\u001B[0m       \u001B[32m0.5240\u001B[0m        \u001B[35m1.4072\u001B[0m  0.2369\n",
      "      6        \u001B[36m1.5752\u001B[0m       \u001B[32m0.5504\u001B[0m        \u001B[35m1.3516\u001B[0m  0.2390\n",
      "      7        \u001B[36m1.5466\u001B[0m       \u001B[32m0.5669\u001B[0m        \u001B[35m1.3040\u001B[0m  0.2321\n",
      "      8        \u001B[36m1.4878\u001B[0m       \u001B[32m0.5835\u001B[0m        \u001B[35m1.2610\u001B[0m  0.2238\n",
      "      9        \u001B[36m1.4215\u001B[0m       \u001B[32m0.6149\u001B[0m        \u001B[35m1.2275\u001B[0m  0.2363\n",
      "     10        \u001B[36m1.3894\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.1950\u001B[0m  0.2482\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.8556\u001B[0m       \u001B[32m0.2165\u001B[0m        \u001B[35m1.9866\u001B[0m  0.2366\n",
      "      2        \u001B[36m2.2860\u001B[0m       \u001B[32m0.3736\u001B[0m        \u001B[35m1.7318\u001B[0m  0.2388\n",
      "      3        \u001B[36m1.9942\u001B[0m       \u001B[32m0.4380\u001B[0m        \u001B[35m1.5613\u001B[0m  0.2342\n",
      "      4        \u001B[36m1.8863\u001B[0m       \u001B[32m0.4909\u001B[0m        \u001B[35m1.4435\u001B[0m  0.2291\n",
      "      5        \u001B[36m1.7404\u001B[0m       \u001B[32m0.5322\u001B[0m        \u001B[35m1.3647\u001B[0m  0.2463\n",
      "      6        \u001B[36m1.6032\u001B[0m       \u001B[32m0.5554\u001B[0m        \u001B[35m1.3122\u001B[0m  0.2322\n",
      "      7        \u001B[36m1.5392\u001B[0m       \u001B[32m0.5686\u001B[0m        \u001B[35m1.2506\u001B[0m  0.2324\n",
      "      8        \u001B[36m1.4753\u001B[0m       \u001B[32m0.5934\u001B[0m        \u001B[35m1.2096\u001B[0m  0.2234\n",
      "      9        \u001B[36m1.4565\u001B[0m       \u001B[32m0.6083\u001B[0m        \u001B[35m1.1720\u001B[0m  0.2293\n",
      "     10        \u001B[36m1.3727\u001B[0m       \u001B[32m0.6215\u001B[0m        \u001B[35m1.1416\u001B[0m  0.2268\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.6024\u001B[0m       \u001B[32m0.3207\u001B[0m        \u001B[35m1.7477\u001B[0m  0.2386\n",
      "      2        \u001B[36m2.1412\u001B[0m       \u001B[32m0.3802\u001B[0m        \u001B[35m1.5577\u001B[0m  0.2377\n",
      "      3        \u001B[36m2.0035\u001B[0m       \u001B[32m0.4397\u001B[0m        \u001B[35m1.4231\u001B[0m  0.2404\n",
      "      4        \u001B[36m1.8172\u001B[0m       \u001B[32m0.4975\u001B[0m        \u001B[35m1.3279\u001B[0m  0.2279\n",
      "      5        \u001B[36m1.7142\u001B[0m       \u001B[32m0.5223\u001B[0m        \u001B[35m1.2632\u001B[0m  0.2223\n",
      "      6        \u001B[36m1.5776\u001B[0m       \u001B[32m0.5570\u001B[0m        \u001B[35m1.2180\u001B[0m  0.2442\n",
      "      7        \u001B[36m1.5150\u001B[0m       \u001B[32m0.5884\u001B[0m        \u001B[35m1.1789\u001B[0m  0.2346\n",
      "      8        \u001B[36m1.4722\u001B[0m       \u001B[32m0.6215\u001B[0m        \u001B[35m1.1436\u001B[0m  0.2306\n",
      "      9        \u001B[36m1.4426\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1204\u001B[0m  0.2254\n",
      "     10        \u001B[36m1.3863\u001B[0m       \u001B[32m0.6479\u001B[0m        \u001B[35m1.0894\u001B[0m  0.2361\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.5691\u001B[0m       \u001B[32m0.2975\u001B[0m        \u001B[35m1.7625\u001B[0m  0.2315\n",
      "      2        \u001B[36m2.0692\u001B[0m       \u001B[32m0.3835\u001B[0m        \u001B[35m1.6150\u001B[0m  0.2386\n",
      "      3        \u001B[36m1.9459\u001B[0m       \u001B[32m0.4281\u001B[0m        \u001B[35m1.5033\u001B[0m  0.2379\n",
      "      4        \u001B[36m1.8334\u001B[0m       \u001B[32m0.4860\u001B[0m        \u001B[35m1.4218\u001B[0m  0.2541\n",
      "      5        \u001B[36m1.6705\u001B[0m       \u001B[32m0.5174\u001B[0m        \u001B[35m1.3604\u001B[0m  0.2299\n",
      "      6        \u001B[36m1.5072\u001B[0m       \u001B[32m0.5570\u001B[0m        \u001B[35m1.3164\u001B[0m  0.2218\n",
      "      7        1.5083       \u001B[32m0.5917\u001B[0m        \u001B[35m1.2580\u001B[0m  0.2387\n",
      "      8        \u001B[36m1.4555\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.2262\u001B[0m  0.2456\n",
      "      9        \u001B[36m1.3735\u001B[0m       \u001B[32m0.6099\u001B[0m        \u001B[35m1.2014\u001B[0m  0.2347\n",
      "     10        \u001B[36m1.3157\u001B[0m       \u001B[32m0.6198\u001B[0m        \u001B[35m1.1683\u001B[0m  0.2322\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.5341\u001B[0m       \u001B[32m0.3504\u001B[0m        \u001B[35m1.6884\u001B[0m  0.2533\n",
      "      2        \u001B[36m2.0635\u001B[0m       \u001B[32m0.4562\u001B[0m        \u001B[35m1.4955\u001B[0m  0.2378\n",
      "      3        \u001B[36m1.8839\u001B[0m       \u001B[32m0.4810\u001B[0m        \u001B[35m1.3808\u001B[0m  0.2463\n",
      "      4        \u001B[36m1.7627\u001B[0m       \u001B[32m0.5355\u001B[0m        \u001B[35m1.3026\u001B[0m  0.2337\n",
      "      5        \u001B[36m1.6046\u001B[0m       \u001B[32m0.5702\u001B[0m        \u001B[35m1.2460\u001B[0m  0.2373\n",
      "      6        \u001B[36m1.4957\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.1973\u001B[0m  0.2311\n",
      "      7        \u001B[36m1.4694\u001B[0m       \u001B[32m0.6116\u001B[0m        \u001B[35m1.1592\u001B[0m  0.2258\n",
      "      8        \u001B[36m1.3855\u001B[0m       \u001B[32m0.6264\u001B[0m        \u001B[35m1.1271\u001B[0m  0.2271\n",
      "      9        \u001B[36m1.3698\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.1018\u001B[0m  0.2287\n",
      "     10        \u001B[36m1.2742\u001B[0m       \u001B[32m0.6512\u001B[0m        \u001B[35m1.0739\u001B[0m  0.2323\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=128, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3134\u001B[0m       \u001B[32m0.3521\u001B[0m        \u001B[35m1.6852\u001B[0m  0.2325\n",
      "      2        \u001B[36m1.9016\u001B[0m       \u001B[32m0.4595\u001B[0m        \u001B[35m1.5136\u001B[0m  0.2303\n",
      "      3        \u001B[36m1.7085\u001B[0m       \u001B[32m0.5008\u001B[0m        \u001B[35m1.3987\u001B[0m  0.2279\n",
      "      4        \u001B[36m1.5542\u001B[0m       \u001B[32m0.5421\u001B[0m        \u001B[35m1.3091\u001B[0m  0.2462\n",
      "      5        \u001B[36m1.4445\u001B[0m       \u001B[32m0.5851\u001B[0m        \u001B[35m1.2458\u001B[0m  0.2347\n",
      "      6        \u001B[36m1.3541\u001B[0m       \u001B[32m0.6017\u001B[0m        \u001B[35m1.1978\u001B[0m  0.2311\n",
      "      7        \u001B[36m1.2744\u001B[0m       \u001B[32m0.6215\u001B[0m        \u001B[35m1.1542\u001B[0m  0.2496\n",
      "      8        \u001B[36m1.2379\u001B[0m       \u001B[32m0.6446\u001B[0m        \u001B[35m1.1173\u001B[0m  0.2345\n",
      "      9        \u001B[36m1.2022\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0839\u001B[0m  0.2421\n",
      "     10        \u001B[36m1.1182\u001B[0m       \u001B[32m0.6760\u001B[0m        \u001B[35m1.0542\u001B[0m  0.2364\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2522\u001B[0m       \u001B[32m0.3174\u001B[0m        \u001B[35m1.6802\u001B[0m  0.2427\n",
      "      2        \u001B[36m1.8133\u001B[0m       \u001B[32m0.4231\u001B[0m        \u001B[35m1.5010\u001B[0m  0.2322\n",
      "      3        \u001B[36m1.6957\u001B[0m       \u001B[32m0.4793\u001B[0m        \u001B[35m1.3787\u001B[0m  0.2267\n",
      "      4        \u001B[36m1.5548\u001B[0m       \u001B[32m0.5388\u001B[0m        \u001B[35m1.2900\u001B[0m  0.2364\n",
      "      5        \u001B[36m1.4351\u001B[0m       \u001B[32m0.5686\u001B[0m        \u001B[35m1.2291\u001B[0m  0.2369\n",
      "      6        \u001B[36m1.3727\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.1766\u001B[0m  0.2471\n",
      "      7        \u001B[36m1.2980\u001B[0m       \u001B[32m0.6215\u001B[0m        \u001B[35m1.1359\u001B[0m  0.2278\n",
      "      8        \u001B[36m1.2067\u001B[0m       \u001B[32m0.6380\u001B[0m        \u001B[35m1.0947\u001B[0m  0.2270\n",
      "      9        \u001B[36m1.1596\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.0593\u001B[0m  0.2328\n",
      "     10        \u001B[36m1.1044\u001B[0m       \u001B[32m0.6628\u001B[0m        \u001B[35m1.0344\u001B[0m  0.2377\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4335\u001B[0m       \u001B[32m0.2694\u001B[0m        \u001B[35m1.8054\u001B[0m  0.2310\n",
      "      2        \u001B[36m1.9632\u001B[0m       \u001B[32m0.3901\u001B[0m        \u001B[35m1.5943\u001B[0m  0.2288\n",
      "      3        \u001B[36m1.7015\u001B[0m       \u001B[32m0.4727\u001B[0m        \u001B[35m1.4474\u001B[0m  0.2347\n",
      "      4        \u001B[36m1.5845\u001B[0m       \u001B[32m0.5273\u001B[0m        \u001B[35m1.3509\u001B[0m  0.2402\n",
      "      5        \u001B[36m1.4767\u001B[0m       \u001B[32m0.5620\u001B[0m        \u001B[35m1.2767\u001B[0m  0.2383\n",
      "      6        \u001B[36m1.3679\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.2164\u001B[0m  0.2427\n",
      "      7        \u001B[36m1.2792\u001B[0m       \u001B[32m0.6050\u001B[0m        \u001B[35m1.1633\u001B[0m  0.2286\n",
      "      8        \u001B[36m1.1997\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.1169\u001B[0m  0.2287\n",
      "      9        \u001B[36m1.1884\u001B[0m       \u001B[32m0.6463\u001B[0m        \u001B[35m1.0800\u001B[0m  0.2358\n",
      "     10        \u001B[36m1.1266\u001B[0m       \u001B[32m0.6645\u001B[0m        \u001B[35m1.0430\u001B[0m  0.2358\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2966\u001B[0m       \u001B[32m0.3603\u001B[0m        \u001B[35m1.6511\u001B[0m  0.2278\n",
      "      2        \u001B[36m1.8563\u001B[0m       \u001B[32m0.4512\u001B[0m        \u001B[35m1.4490\u001B[0m  0.2233\n",
      "      3        \u001B[36m1.6223\u001B[0m       \u001B[32m0.5124\u001B[0m        \u001B[35m1.3285\u001B[0m  0.2226\n",
      "      4        \u001B[36m1.5118\u001B[0m       \u001B[32m0.5653\u001B[0m        \u001B[35m1.2444\u001B[0m  0.2426\n",
      "      5        \u001B[36m1.3918\u001B[0m       \u001B[32m0.5983\u001B[0m        \u001B[35m1.1816\u001B[0m  0.2441\n",
      "      6        \u001B[36m1.2914\u001B[0m       \u001B[32m0.6248\u001B[0m        \u001B[35m1.1379\u001B[0m  0.2362\n",
      "      7        \u001B[36m1.2318\u001B[0m       \u001B[32m0.6512\u001B[0m        \u001B[35m1.0989\u001B[0m  0.2260\n",
      "      8        \u001B[36m1.1772\u001B[0m       \u001B[32m0.6661\u001B[0m        \u001B[35m1.0545\u001B[0m  0.2256\n",
      "      9        \u001B[36m1.1304\u001B[0m       \u001B[32m0.6810\u001B[0m        \u001B[35m1.0250\u001B[0m  0.2238\n",
      "     10        \u001B[36m1.0894\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m0.9983\u001B[0m  0.2346\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3898\u001B[0m       \u001B[32m0.3917\u001B[0m        \u001B[35m1.6673\u001B[0m  0.2332\n",
      "      2        \u001B[36m1.8699\u001B[0m       \u001B[32m0.4661\u001B[0m        \u001B[35m1.4557\u001B[0m  0.2383\n",
      "      3        \u001B[36m1.6687\u001B[0m       \u001B[32m0.5306\u001B[0m        \u001B[35m1.3355\u001B[0m  0.2219\n",
      "      4        \u001B[36m1.5495\u001B[0m       \u001B[32m0.5653\u001B[0m        \u001B[35m1.2546\u001B[0m  0.2244\n",
      "      5        \u001B[36m1.4308\u001B[0m       \u001B[32m0.5934\u001B[0m        \u001B[35m1.1967\u001B[0m  0.2328\n",
      "      6        \u001B[36m1.3357\u001B[0m       \u001B[32m0.6116\u001B[0m        \u001B[35m1.1485\u001B[0m  0.2313\n",
      "      7        \u001B[36m1.2695\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.1108\u001B[0m  0.2229\n",
      "      8        \u001B[36m1.1902\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.0703\u001B[0m  0.2237\n",
      "      9        \u001B[36m1.1588\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0426\u001B[0m  0.2281\n",
      "     10        \u001B[36m1.1287\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0104\u001B[0m  0.2359\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.3237\u001B[0m       \u001B[32m0.3521\u001B[0m        \u001B[35m1.6786\u001B[0m  0.2344\n",
      "      2        \u001B[36m1.8833\u001B[0m       \u001B[32m0.4512\u001B[0m        \u001B[35m1.4769\u001B[0m  0.2368\n",
      "      3        \u001B[36m1.7106\u001B[0m       \u001B[32m0.5074\u001B[0m        \u001B[35m1.3566\u001B[0m  0.2272\n",
      "      4        \u001B[36m1.5564\u001B[0m       \u001B[32m0.5554\u001B[0m        \u001B[35m1.2649\u001B[0m  0.2213\n",
      "      5        \u001B[36m1.4215\u001B[0m       \u001B[32m0.5769\u001B[0m        \u001B[35m1.2003\u001B[0m  0.2307\n",
      "      6        \u001B[36m1.3645\u001B[0m       \u001B[32m0.6264\u001B[0m        \u001B[35m1.1457\u001B[0m  0.2330\n",
      "      7        \u001B[36m1.2703\u001B[0m       \u001B[32m0.6579\u001B[0m        \u001B[35m1.1083\u001B[0m  0.2260\n",
      "      8        \u001B[36m1.2419\u001B[0m       \u001B[32m0.6860\u001B[0m        \u001B[35m1.0684\u001B[0m  0.2288\n",
      "      9        \u001B[36m1.1572\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m1.0377\u001B[0m  0.2264\n",
      "     10        \u001B[36m1.0962\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m1.0099\u001B[0m  0.2313\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=128; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4698\u001B[0m       \u001B[32m0.3884\u001B[0m        \u001B[35m1.6160\u001B[0m  0.2279\n",
      "      2        \u001B[36m1.8979\u001B[0m       \u001B[32m0.4942\u001B[0m        \u001B[35m1.4303\u001B[0m  0.2368\n",
      "      3        \u001B[36m1.6809\u001B[0m       \u001B[32m0.5686\u001B[0m        \u001B[35m1.3213\u001B[0m  0.2281\n",
      "      4        \u001B[36m1.5806\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.2379\u001B[0m  0.2175\n",
      "      5        \u001B[36m1.4221\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.1769\u001B[0m  0.2173\n",
      "      6        \u001B[36m1.3498\u001B[0m       \u001B[32m0.6446\u001B[0m        \u001B[35m1.1253\u001B[0m  0.2269\n",
      "      7        \u001B[36m1.2734\u001B[0m       \u001B[32m0.6496\u001B[0m        \u001B[35m1.0941\u001B[0m  0.2230\n",
      "      8        \u001B[36m1.2343\u001B[0m       \u001B[32m0.6694\u001B[0m        \u001B[35m1.0683\u001B[0m  0.2359\n",
      "      9        \u001B[36m1.1573\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m1.0370\u001B[0m  0.2243\n",
      "     10        \u001B[36m1.1025\u001B[0m       \u001B[32m0.6893\u001B[0m        \u001B[35m1.0236\u001B[0m  0.2293\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.4259\u001B[0m       \u001B[32m0.3802\u001B[0m        \u001B[35m1.6235\u001B[0m  0.2263\n",
      "      2        \u001B[36m1.8494\u001B[0m       \u001B[32m0.4678\u001B[0m        \u001B[35m1.4327\u001B[0m  0.2282\n",
      "      3        \u001B[36m1.6721\u001B[0m       \u001B[32m0.5174\u001B[0m        \u001B[35m1.3013\u001B[0m  0.2265\n",
      "      4        \u001B[36m1.5357\u001B[0m       \u001B[32m0.5653\u001B[0m        \u001B[35m1.2206\u001B[0m  0.2168\n",
      "      5        \u001B[36m1.3973\u001B[0m       \u001B[32m0.5967\u001B[0m        \u001B[35m1.1653\u001B[0m  0.2225\n",
      "      6        \u001B[36m1.3391\u001B[0m       \u001B[32m0.6231\u001B[0m        \u001B[35m1.1065\u001B[0m  0.2301\n",
      "      7        \u001B[36m1.2811\u001B[0m       \u001B[32m0.6446\u001B[0m        \u001B[35m1.0610\u001B[0m  0.2376\n",
      "      8        \u001B[36m1.1744\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0237\u001B[0m  0.2251\n",
      "      9        \u001B[36m1.1282\u001B[0m       \u001B[32m0.6727\u001B[0m        \u001B[35m0.9909\u001B[0m  0.2344\n",
      "     10        \u001B[36m1.0623\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m0.9603\u001B[0m  0.2171\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.2594\u001B[0m       \u001B[32m0.3686\u001B[0m        \u001B[35m1.5856\u001B[0m  0.2218\n",
      "      2        \u001B[36m1.8255\u001B[0m       \u001B[32m0.4793\u001B[0m        \u001B[35m1.3942\u001B[0m  0.2250\n",
      "      3        \u001B[36m1.6230\u001B[0m       \u001B[32m0.5306\u001B[0m        \u001B[35m1.2734\u001B[0m  0.2290\n",
      "      4        \u001B[36m1.5065\u001B[0m       \u001B[32m0.6066\u001B[0m        \u001B[35m1.1904\u001B[0m  0.2231\n",
      "      5        \u001B[36m1.3257\u001B[0m       \u001B[32m0.6413\u001B[0m        \u001B[35m1.1252\u001B[0m  0.2179\n",
      "      6        \u001B[36m1.3190\u001B[0m       \u001B[32m0.6612\u001B[0m        \u001B[35m1.0818\u001B[0m  0.2162\n",
      "      7        \u001B[36m1.2066\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m1.0338\u001B[0m  0.2281\n",
      "      8        \u001B[36m1.1639\u001B[0m       0.6843        \u001B[35m0.9958\u001B[0m  0.2300\n",
      "      9        \u001B[36m1.0789\u001B[0m       \u001B[32m0.6942\u001B[0m        \u001B[35m0.9674\u001B[0m  0.2239\n",
      "     10        \u001B[36m1.0386\u001B[0m       \u001B[32m0.7091\u001B[0m        \u001B[35m0.9457\u001B[0m  0.2346\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=256, module__hidden_dim2=256; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0198\u001B[0m       \u001B[32m0.3917\u001B[0m        \u001B[35m1.5464\u001B[0m  0.2194\n",
      "      2        \u001B[36m1.5896\u001B[0m       \u001B[32m0.5157\u001B[0m        \u001B[35m1.3232\u001B[0m  0.2238\n",
      "      3        \u001B[36m1.4233\u001B[0m       \u001B[32m0.5802\u001B[0m        \u001B[35m1.2123\u001B[0m  0.2291\n",
      "      4        \u001B[36m1.2735\u001B[0m       \u001B[32m0.6314\u001B[0m        \u001B[35m1.1228\u001B[0m  0.2294\n",
      "      5        \u001B[36m1.1877\u001B[0m       \u001B[32m0.6595\u001B[0m        \u001B[35m1.0667\u001B[0m  0.2229\n",
      "      6        \u001B[36m1.1080\u001B[0m       \u001B[32m0.6843\u001B[0m        \u001B[35m1.0195\u001B[0m  0.2175\n",
      "      7        \u001B[36m1.0326\u001B[0m       \u001B[32m0.7124\u001B[0m        \u001B[35m0.9745\u001B[0m  0.2183\n",
      "      8        \u001B[36m0.9659\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.9499\u001B[0m  0.2335\n",
      "      9        \u001B[36m0.9130\u001B[0m       \u001B[32m0.7455\u001B[0m        \u001B[35m0.9253\u001B[0m  0.2316\n",
      "     10        \u001B[36m0.8979\u001B[0m       \u001B[32m0.7504\u001B[0m        \u001B[35m0.8930\u001B[0m  0.2278\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9560\u001B[0m       \u001B[32m0.4661\u001B[0m        \u001B[35m1.5193\u001B[0m  0.2315\n",
      "      2        \u001B[36m1.6208\u001B[0m       \u001B[32m0.5306\u001B[0m        \u001B[35m1.3160\u001B[0m  0.2211\n",
      "      3        \u001B[36m1.4087\u001B[0m       \u001B[32m0.5950\u001B[0m        \u001B[35m1.2087\u001B[0m  0.2215\n",
      "      4        \u001B[36m1.2388\u001B[0m       \u001B[32m0.6364\u001B[0m        \u001B[35m1.1255\u001B[0m  0.2269\n",
      "      5        \u001B[36m1.1417\u001B[0m       \u001B[32m0.6760\u001B[0m        \u001B[35m1.0723\u001B[0m  0.2266\n",
      "      6        \u001B[36m1.0570\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m1.0189\u001B[0m  0.2378\n",
      "      7        \u001B[36m1.0044\u001B[0m       \u001B[32m0.6909\u001B[0m        \u001B[35m0.9797\u001B[0m  0.2490\n",
      "      8        \u001B[36m0.9457\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9440\u001B[0m  0.2418\n",
      "      9        \u001B[36m0.9005\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.9157\u001B[0m  0.2413\n",
      "     10        \u001B[36m0.8528\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8854\u001B[0m  0.2402\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.9229\u001B[0m       \u001B[32m0.4463\u001B[0m        \u001B[35m1.4950\u001B[0m  0.2277\n",
      "      2        \u001B[36m1.5254\u001B[0m       \u001B[32m0.5190\u001B[0m        \u001B[35m1.3230\u001B[0m  0.2208\n",
      "      3        \u001B[36m1.3752\u001B[0m       \u001B[32m0.5884\u001B[0m        \u001B[35m1.2218\u001B[0m  0.2179\n",
      "      4        \u001B[36m1.2290\u001B[0m       \u001B[32m0.6281\u001B[0m        \u001B[35m1.1476\u001B[0m  0.2267\n",
      "      5        \u001B[36m1.1226\u001B[0m       \u001B[32m0.6529\u001B[0m        \u001B[35m1.0891\u001B[0m  0.2340\n",
      "      6        \u001B[36m1.0584\u001B[0m       \u001B[32m0.6727\u001B[0m        \u001B[35m1.0411\u001B[0m  0.2265\n",
      "      7        \u001B[36m0.9765\u001B[0m       \u001B[32m0.6926\u001B[0m        \u001B[35m1.0000\u001B[0m  0.2237\n",
      "      8        \u001B[36m0.9472\u001B[0m       \u001B[32m0.7107\u001B[0m        \u001B[35m0.9639\u001B[0m  0.2202\n",
      "      9        \u001B[36m0.8922\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.9363\u001B[0m  0.2300\n",
      "     10        \u001B[36m0.8193\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.9102\u001B[0m  0.2343\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=64; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1346\u001B[0m       \u001B[32m0.4479\u001B[0m        \u001B[35m1.5207\u001B[0m  0.2176\n",
      "      2        \u001B[36m1.6067\u001B[0m       \u001B[32m0.5421\u001B[0m        \u001B[35m1.2877\u001B[0m  0.2137\n",
      "      3        \u001B[36m1.3932\u001B[0m       \u001B[32m0.6033\u001B[0m        \u001B[35m1.1723\u001B[0m  0.2085\n",
      "      4        \u001B[36m1.2586\u001B[0m       \u001B[32m0.6562\u001B[0m        \u001B[35m1.0957\u001B[0m  0.2116\n",
      "      5        \u001B[36m1.1791\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0378\u001B[0m  0.2215\n",
      "      6        \u001B[36m1.1067\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m0.9912\u001B[0m  0.2183\n",
      "      7        \u001B[36m0.9958\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9553\u001B[0m  0.2135\n",
      "      8        \u001B[36m0.9499\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.9248\u001B[0m  0.2131\n",
      "      9        \u001B[36m0.9040\u001B[0m       \u001B[32m0.7322\u001B[0m        \u001B[35m0.8895\u001B[0m  0.2127\n",
      "     10        \u001B[36m0.8438\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.8621\u001B[0m  0.2197\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0198\u001B[0m       \u001B[32m0.4430\u001B[0m        \u001B[35m1.5208\u001B[0m  0.2203\n",
      "      2        \u001B[36m1.6085\u001B[0m       \u001B[32m0.5421\u001B[0m        \u001B[35m1.3372\u001B[0m  0.2140\n",
      "      3        \u001B[36m1.4326\u001B[0m       \u001B[32m0.5983\u001B[0m        \u001B[35m1.2314\u001B[0m  0.2094\n",
      "      4        \u001B[36m1.2460\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.1411\u001B[0m  0.2115\n",
      "      5        \u001B[36m1.1912\u001B[0m       \u001B[32m0.6446\u001B[0m        \u001B[35m1.0729\u001B[0m  0.2220\n",
      "      6        \u001B[36m1.0626\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m1.0233\u001B[0m  0.2191\n",
      "      7        \u001B[36m1.0198\u001B[0m       \u001B[32m0.6992\u001B[0m        \u001B[35m0.9838\u001B[0m  0.2129\n",
      "      8        \u001B[36m0.9741\u001B[0m       0.6992        \u001B[35m0.9432\u001B[0m  0.2123\n",
      "      9        \u001B[36m0.8950\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9153\u001B[0m  0.2229\n",
      "     10        \u001B[36m0.8563\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.8902\u001B[0m  0.2330\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.3s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.1161\u001B[0m       \u001B[32m0.4182\u001B[0m        \u001B[35m1.5083\u001B[0m  0.2491\n",
      "      2        \u001B[36m1.6155\u001B[0m       \u001B[32m0.5488\u001B[0m        \u001B[35m1.2965\u001B[0m  0.2342\n",
      "      3        \u001B[36m1.4064\u001B[0m       \u001B[32m0.6066\u001B[0m        \u001B[35m1.1822\u001B[0m  0.2365\n",
      "      4        \u001B[36m1.2542\u001B[0m       \u001B[32m0.6562\u001B[0m        \u001B[35m1.0959\u001B[0m  0.2421\n",
      "      5        \u001B[36m1.1509\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m1.0335\u001B[0m  0.2412\n",
      "      6        \u001B[36m1.0776\u001B[0m       \u001B[32m0.7140\u001B[0m        \u001B[35m0.9956\u001B[0m  0.2529\n",
      "      7        \u001B[36m1.0055\u001B[0m       \u001B[32m0.7207\u001B[0m        \u001B[35m0.9567\u001B[0m  0.2437\n",
      "      8        \u001B[36m0.9486\u001B[0m       \u001B[32m0.7405\u001B[0m        \u001B[35m0.9180\u001B[0m  0.2365\n",
      "      9        \u001B[36m0.8798\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8949\u001B[0m  0.2286\n",
      "     10        \u001B[36m0.8595\u001B[0m       \u001B[32m0.7521\u001B[0m        \u001B[35m0.8724\u001B[0m  0.2248\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=128; total time=   2.5s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0500\u001B[0m       \u001B[32m0.4942\u001B[0m        \u001B[35m1.3559\u001B[0m  0.2502\n",
      "      2        \u001B[36m1.5866\u001B[0m       \u001B[32m0.5785\u001B[0m        \u001B[35m1.1735\u001B[0m  0.2417\n",
      "      3        \u001B[36m1.3770\u001B[0m       \u001B[32m0.6430\u001B[0m        \u001B[35m1.0705\u001B[0m  0.2450\n",
      "      4        \u001B[36m1.2705\u001B[0m       \u001B[32m0.6810\u001B[0m        \u001B[35m0.9991\u001B[0m  0.2333\n",
      "      5        \u001B[36m1.1526\u001B[0m       \u001B[32m0.7058\u001B[0m        \u001B[35m0.9537\u001B[0m  0.2520\n",
      "      6        \u001B[36m1.0717\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.9111\u001B[0m  0.2540\n",
      "      7        \u001B[36m0.9830\u001B[0m       \u001B[32m0.7488\u001B[0m        \u001B[35m0.8734\u001B[0m  0.2259\n",
      "      8        \u001B[36m0.9487\u001B[0m       \u001B[32m0.7554\u001B[0m        \u001B[35m0.8452\u001B[0m  0.2122\n",
      "      9        \u001B[36m0.8762\u001B[0m       \u001B[32m0.7587\u001B[0m        \u001B[35m0.8267\u001B[0m  0.2133\n",
      "     10        \u001B[36m0.8259\u001B[0m       \u001B[32m0.7752\u001B[0m        \u001B[35m0.8033\u001B[0m  0.2212\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.4s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0613\u001B[0m       \u001B[32m0.4562\u001B[0m        \u001B[35m1.4625\u001B[0m  0.2176\n",
      "      2        \u001B[36m1.6133\u001B[0m       \u001B[32m0.5802\u001B[0m        \u001B[35m1.2556\u001B[0m  0.2250\n",
      "      3        \u001B[36m1.3889\u001B[0m       \u001B[32m0.6347\u001B[0m        \u001B[35m1.1371\u001B[0m  0.2133\n",
      "      4        \u001B[36m1.2028\u001B[0m       \u001B[32m0.6661\u001B[0m        \u001B[35m1.0575\u001B[0m  0.2111\n",
      "      5        \u001B[36m1.0861\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m0.9993\u001B[0m  0.2184\n",
      "      6        \u001B[36m1.0175\u001B[0m       \u001B[32m0.7074\u001B[0m        \u001B[35m0.9485\u001B[0m  0.2183\n",
      "      7        \u001B[36m0.9431\u001B[0m       \u001B[32m0.7190\u001B[0m        \u001B[35m0.9150\u001B[0m  0.2114\n",
      "      8        \u001B[36m0.9009\u001B[0m       \u001B[32m0.7289\u001B[0m        \u001B[35m0.8892\u001B[0m  0.2109\n",
      "      9        \u001B[36m0.8606\u001B[0m       \u001B[32m0.7306\u001B[0m        \u001B[35m0.8688\u001B[0m  0.2130\n",
      "     10        \u001B[36m0.7890\u001B[0m       \u001B[32m0.7355\u001B[0m        \u001B[35m0.8518\u001B[0m  0.2144\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m2.0457\u001B[0m       \u001B[32m0.5008\u001B[0m        \u001B[35m1.4180\u001B[0m  0.2212\n",
      "      2        \u001B[36m1.5930\u001B[0m       \u001B[32m0.5901\u001B[0m        \u001B[35m1.2104\u001B[0m  0.2135\n",
      "      3        \u001B[36m1.3901\u001B[0m       \u001B[32m0.6331\u001B[0m        \u001B[35m1.0989\u001B[0m  0.2114\n",
      "      4        \u001B[36m1.2656\u001B[0m       \u001B[32m0.6711\u001B[0m        \u001B[35m1.0276\u001B[0m  0.2123\n",
      "      5        \u001B[36m1.1274\u001B[0m       \u001B[32m0.6876\u001B[0m        \u001B[35m0.9645\u001B[0m  0.2228\n",
      "      6        \u001B[36m1.0280\u001B[0m       \u001B[32m0.7008\u001B[0m        \u001B[35m0.9211\u001B[0m  0.2172\n",
      "      7        \u001B[36m0.9852\u001B[0m       \u001B[32m0.7223\u001B[0m        \u001B[35m0.8930\u001B[0m  0.2138\n",
      "      8        \u001B[36m0.8907\u001B[0m       \u001B[32m0.7273\u001B[0m        \u001B[35m0.8640\u001B[0m  0.2117\n",
      "      9        \u001B[36m0.8571\u001B[0m       \u001B[32m0.7421\u001B[0m        \u001B[35m0.8393\u001B[0m  0.2119\n",
      "     10        \u001B[36m0.8351\u001B[0m       \u001B[32m0.7438\u001B[0m        \u001B[35m0.8167\u001B[0m  0.2125\n",
      "[CV] END batch_size=64, lr=0.0001, module__dropout_rate=0.5, module__hidden_dim1=512, module__hidden_dim2=256; total time=   2.2s\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m1.2684\u001B[0m       \u001B[32m0.7280\u001B[0m        \u001B[35m0.8204\u001B[0m  0.5265\n",
      "      2        \u001B[36m0.7445\u001B[0m       \u001B[32m0.7885\u001B[0m        \u001B[35m0.7053\u001B[0m  0.3307\n",
      "      3        \u001B[36m0.5892\u001B[0m       \u001B[32m0.8051\u001B[0m        \u001B[35m0.6935\u001B[0m  0.3269\n",
      "      4        \u001B[36m0.5128\u001B[0m       \u001B[32m0.8205\u001B[0m        \u001B[35m0.6576\u001B[0m  0.3260\n",
      "      5        \u001B[36m0.4565\u001B[0m       0.8139        0.6592  0.3174\n",
      "      6        \u001B[36m0.4000\u001B[0m       0.8183        \u001B[35m0.6264\u001B[0m  0.3159\n",
      "      7        \u001B[36m0.3359\u001B[0m       \u001B[32m0.8216\u001B[0m        0.6471  0.3150\n",
      "      8        \u001B[36m0.3154\u001B[0m       0.8084        0.6525  0.3285\n",
      "      9        \u001B[36m0.2925\u001B[0m       0.8106        0.6523  0.3320\n",
      "     10        \u001B[36m0.2765\u001B[0m       0.8117        0.7021  0.3228\n",
      "Best parameters: {'batch_size': 64, 'lr': 0.001, 'module__dropout_rate': 0.5, 'module__hidden_dim1': 512, 'module__hidden_dim2': 64}\n",
      "Best cross-validation accuracy: 0.8123\n",
      "Validation accuracy: 0.8018\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "ea0a1190-2e88-45ab-9db1-f2a29d6794b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea0a1190-2e88-45ab-9db1-f2a29d6794b4",
    "outputId": "41b85032-e91d-440f-a64b-b46ea007dde6",
    "ExecuteTime": {
     "end_time": "2024-10-21T13:06:28.290389Z",
     "start_time": "2024-10-21T13:06:23.087733Z"
    }
   },
   "source": [
    "##########\n",
    "# Training\n",
    "##########\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim1 = 512\n",
    "hidden_dim2 = 64\n",
    "output_dim = 6\n",
    "drop_out = 0.5\n",
    "\n",
    "model = Classifier(input_dim, hidden_dim1, hidden_dim2, output_dim, drop_out)\n",
    "\n",
    "device = get_device()\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "max_grad_norm = 1.0\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in range(0, len(X_train), batch_size):\n",
    "        inputs = X_train[batch:batch + batch_size]\n",
    "        labels = y_train[batch:batch + batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f'Epoch: {epoch+1}, Loss: {epoch_loss/len(X_train):.4f}, Learning Rate: {scheduler.get_last_lr()[0]:.6f}')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fh/yf32rrls0pjbtmy317lvgthh0000gn/T/ipykernel_92320/3581891304.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32)\n",
      "/var/folders/fh/yf32rrls0pjbtmy317lvgthh0000gn/T/ipykernel_92320/3581891304.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device found, using MPS backend.\n",
      "\n",
      "Epoch: 1, Loss: 0.0184, Learning Rate: 0.001000\n",
      "Epoch: 2, Loss: 0.0104, Learning Rate: 0.001000\n",
      "Epoch: 3, Loss: 0.0086, Learning Rate: 0.001000\n",
      "Epoch: 4, Loss: 0.0075, Learning Rate: 0.001000\n",
      "Epoch: 5, Loss: 0.0063, Learning Rate: 0.000500\n",
      "Epoch: 6, Loss: 0.0058, Learning Rate: 0.000500\n",
      "Epoch: 7, Loss: 0.0049, Learning Rate: 0.000500\n",
      "Epoch: 8, Loss: 0.0046, Learning Rate: 0.000500\n",
      "Epoch: 9, Loss: 0.0041, Learning Rate: 0.000500\n",
      "Epoch: 10, Loss: 0.0040, Learning Rate: 0.000250\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "335503be-ea74-42b8-ab51-d4d80bc5f77b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "id": "335503be-ea74-42b8-ab51-d4d80bc5f77b",
    "outputId": "68db4758-095a-4cae-e74e-c1d1ab814a0b",
    "ExecuteTime": {
     "end_time": "2024-10-21T13:06:30.013282Z",
     "start_time": "2024-10-21T13:06:29.690518Z"
    }
   },
   "source": [
    "############\n",
    "# Evaluation\n",
    "############\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "y_test = y_test.squeeze()\n",
    "\n",
    "device = get_device()\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in range(0, len(X_test), batch_size):\n",
    "        inputs = X_test[batch:batch + batch_size]\n",
    "        labels = y_test[batch:batch + batch_size]\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / y_test.shape[0]\n",
    "print(f'Accuracy on test data: {accuracy:.2f}%')\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[f'Class {i}' for i in range(output_dim)],\n",
    "            yticklabels=[f'Class {i}' for i in range(output_dim)])\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "print(f'Weighted F1-Score: {f1*100:.2f}%')\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(all_labels, all_predictions, target_names=[f'Class {i}' for i in range(output_dim)])\n",
    "print(report)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device found, using MPS backend.\n",
      "\n",
      "Accuracy on test data: 84.07%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1-Score: 84.09%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.78      0.90      0.84       169\n",
      "     Class 1       0.80      0.85      0.83       345\n",
      "     Class 2       0.86      0.77      0.82       151\n",
      "     Class 3       0.91      0.86      0.89       131\n",
      "     Class 4       0.87      0.83      0.85        82\n",
      "     Class 5       0.86      0.83      0.85       541\n",
      "\n",
      "    accuracy                           0.84      1419\n",
      "   macro avg       0.85      0.84      0.84      1419\n",
      "weighted avg       0.84      0.84      0.84      1419\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1caff7de8524ad7a"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
